[ { "title": "Zookeeper 学习", "url": "/posts/zookeeper/", "categories": "Backend, Zookeeper", "tags": "zookeeper", "date": "2024-08-11 09:56:08 +0800", "snippet": "Zookeeper 是什么Zookeeper 是一个分布式的协调服务，可以实现 统一配置管理。比如现在有A.yml，B.yml，C.yml配置文件，里面有一些公共的配置。将这些公共配置信息放到ZK中，修改ZK的信息，会通知A，B，C配置文件。 统一命名服务。节点存储ip地址，只需要访问Znode节点就可以获取这些ip地址。 统一集群管理。Kafka 的集群管理基于Zookeeper。 ...", "content": "Zookeeper 是什么Zookeeper 是一个分布式的协调服务，可以实现 统一配置管理。比如现在有A.yml，B.yml，C.yml配置文件，里面有一些公共的配置。将这些公共配置信息放到ZK中，修改ZK的信息，会通知A，B，C配置文件。 统一命名服务。节点存储ip地址，只需要访问Znode节点就可以获取这些ip地址。 统一集群管理。Kafka 的集群管理基于Zookeeper。 统一服务管理。Dubbo 的服务发现基于Zookeeper。 分布式锁。通过在持久节点下建立临时顺序节点，可以保证锁的有序，监听机制保障锁传递的高效。原理文件系统数据结构文件系统类似的，整体上可以看成一棵树，每个节点称作一个 ZNode，每个 ZNode 都可以通过其路径得到唯一标识。默认只能最多存储 1MB 的数据但与文件系统不同，每一个 ZNode 节点都可以存储数据，但文件系统的目录不可以存储数据。ZNode 类型三大类： 持久节点，除非客户端主动执行删除操作，否则 ZooKeeper 不会删除持久的 znode 临时节点，客户端断开连接后，ZooKeeper会自动删除临时节点 顺序节点，每次创建顺序节点时，ZooKeeper都会在路径后面自动添加上10位的数字，从1开始，最大是2147483647 （2^32-1）四种形式： 持久节点 持久顺序节点 临时节点 临时顺序节点唯一事务id每次的变化都会产生一个集群全局的唯一的事务id， Zxid（ZooKeeper Transaction Id），由Zookeeper的 Leader 实例维护。变化包括 任何的客户端连接到Server 任何的客户端断开与Server连接 任何的Znode节点被创建create、修改set、删除delete通知机制（监听机制）具体是基于观察者模式实现的。在ZooKeeper中，客户端是观察者，服务端是被观察者。 客户端通过注册Watch来监听服务端节点的数据变化。ZooKeeper 的观察机制允许用户在指定节点上针对感兴趣的事件注册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。监听两方面的内容： 监听 Znode 的数据变化 监听子节点的数量变化角色一主多从的结构 Leader，同一时间只会有一个Leader，负责发起和提交写请求。接收到写请求后同时发送给Follower，统计Follower写入成功的数量，超过一半则认为成功。 Follower，处理读请求，Leader宕机后使用 Paxos 一致性算法的 Zab 协议负责选举新的Leader。 Observer，处理读请求，但没有选举权会话（Session）client与ZooKeeper集群中的某一台server保持连接，发送读/写请求，读请求直接由当前连接的server处理，写请求由于是事务请求，由当前server转发给leader进行处理。同时，client还能接收来自server端的watcher通知。所有的这些交互，都是基于client和ZooKeeper的server之间的TCP长连接，也称之为Session会话。有了会话之后，后续的请求发送，回应，心跳检测等机制都是基于会话来实现的。ZAB 算法与 Raft 算法的选举过程ZAB 算法 所有节点第一票先选举自己当leader，将投票信息广播出去； 按照规则（epoch 是否比自己的 epoch 大，以及 counter 是否比自己的 counter 大，总之选择zxid最大的投票信息，说明该节点的数据最全）判断是否需要更改投票信息，将更改后的投票信息再次广播出去； 判断是否有超过一半的投票选举同一个节点，如果是选举结束根据投票结果设置自己的服务状态，选举结束，否则继续进入投票流程。Raft每个节点都有一个定时器，最先结束倒计时的节点最先发送选举的信号（基本也会是被选举为 leader）" }, { "title": "Go 语言学习", "url": "/posts/go/", "categories": "Backend, Go", "tags": "go", "date": "2024-02-27 14:25:08 +0800", "snippet": "基本语法变量初始化var s string = \"string\"var s = \"string\"s := \"string\"二维切片初始化slice1 := make([][]bool, m)for i := range slice1 { slice1[i] = make([]bool, n)}变量自增只有后缀自增或自减，并且必须单独一行（除了在range语句中）。条件判断语句中的初始变...", "content": "基本语法变量初始化var s string = \"string\"var s = \"string\"s := \"string\"二维切片初始化slice1 := make([][]bool, m)for i := range slice1 { slice1[i] = make([]bool, n)}变量自增只有后缀自增或自减，并且必须单独一行（除了在range语句中）。条件判断语句中的初始变量可以在布尔表达式里，并且不能使用0/1作为判断条件。if cond := true; cond { fmt.Println()}随机数生成 [0, 99] 的随机数rand.Seed(time.Now().UnixNano())r := rand.Intn(100)fmt.Println(r)栈/队列Go 语言中的栈和队列都是基于切片实现的。stack := make([]int, 0) //创建切片stack = append(stack, 10) //push压入栈value := stack[len(stack)-1] // 取栈顶的值stack = stack[:len(stack)-1] //pop弹出len(stack) == 0 //检查栈空queue := make([]int, 0) //创建切片queue = append(queue, 10) //enqueue入队v := queue[0] // 取队首的值queue = queue[1:] //dequeue出队len(queue) == 0 //检查队列为空合并切片slice1 := []string{\"Moe\", \"Larry\", \"Curly\"}slice2 := []string{\"php\", \"golang\", \"java\"}slice3 = append(slice1, slice2...)fmt.Println(slice3)//[Moe Larry Curly php golang java]整数和字符串转换// string to int, \"99\" -&gt; 99int, err := strconv.Atoi(str)// asscii to string, 97 -&gt; \"a\"str := string(asscii) // asscii to string// int to string, 10 -&gt; \"10\"str := fmt.Sprintf(\"%d\", int)str := strconv.Itoa(int)str := strconv.FormatInt(int, 10)Range 用法// 数组var pow = []int{1, 2, 4, 8, 16, 32, 64, 128}for i, v := range pow { fmt.Printf(\"2**%d = %d\\n\", i, v)}// Mapfor key, value := range oldMap { newMap[key] = value}for key := range oldMap { fmt.Println(oldMap[key])}for _, value := range oldMap { fmt.Println(value)}// 字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。for i, c := range \"go\" { fmt.Println(i, c, string(c)) //0 103 g \\n 1 111 o}最值fmt.Printf(\"int min - max: %d - %d\\n\", math.MinInt, math.MaxInt) // intfmt.Printf(\"int8 min - max: %d - %d\\n\", math.MinInt8, math.MaxInt8) // int8fmt.Printf(\"int16 min - max: %d - %d\\n\", math.MinInt16, math.MaxInt16) // int16fmt.Printf(\"int32 min - max: %d - %d\\n\", math.MinInt32, math.MaxInt32) // int32fmt.Printf(\"int64 min - max: %d - %d\\n\", math.MinInt64, math.MaxInt64) // int64// unsignedfmt.Printf(\"uint min - max: %d - %d\\n\", uint(0), uint(math.MaxUint)) // uintfmt.Printf(\"uint8 min - max: %d - %d\\n\", 0, math.MaxUint8) // uint8fmt.Printf(\"uint16 min - max: %d - %d\\n\", 0, math.MaxUint16) // uint16fmt.Printf(\"uint32 min - max: %d - %d\\n\", 0, math.MaxUint32) // uint32fmt.Printf(\"uint64 min - max: %d - %d\\n\", 0, uint64(math.MaxUint64)) // uint64排序// intarray := []int{3, 1, 34, 25, 14, 5}sort.Ints(array) // 升序fmt.Println(array)sort.Sort(sort.Reverse(sort.IntSlice(array))) // 降序fmt.Println(array)// stringarray1 := []string{\"ss\", \"sa\", \"avs\", \"vs\"}sort.Strings(array1)fmt.Println(array1)sort.Sort(sort.Reverse(sort.StringSlice(array1)))fmt.Println(array1)自定义排序array := []int{3, 17, 1, 34, 25, 14, 5}sort.Slice(array, func(i, j int) bool { if abs(array[i]-9) != abs(array[j]-9) { return abs(array[i]-9) &lt; abs(array[j]-9) } return array[i] &lt; array[j]})fmt.Printf(\"%+v\", array)双向列表doubleLinkedList := list.New()doubleLinkedList.PushBack(3)var doubleLinkedListElement *list.ElementdoubleLinkedListElement = doubleLinkedList.Back()Map 用法m := make(map[string]int) // 初始化m := map[string]int{ // 使用组合字面量初始化 \"apple\": 1, \"banana\": 2, \"orange\": 3,}v1 := m[\"apple\"] // 获取键值对v2, ok := m[\"pear\"] // 如果键不存在，ok 的值为 false，v2 的值为该类型的零值for k, v := range m { // 遍历Map，无序的 fmt.Printf(\"key=%s, value=%d\\n\", k, v)}delete(m, \"banana\") // 删除元素m := make(map[string]int) // 清空元素的方法就是重新make一个map// 基于 Map 实现 Setset := make(map[string]bool)set[\"Foo\"] = truefor k := range set { fmt.Println(k)}delete(set, \"Foo\")size := len(set)exists := set[\"Foo\"]堆的用法package mainimport (\t\"container/heap\"\t\"fmt\"\t\"sort\")type heap2 struct {\tsort.IntSlice}func (h heap2) Less(i, j int) bool { // 最小堆：h.IntSlice[i] &lt; h.IntSlice[j]；最大堆：h.IntSlice[i] &gt; h.IntSlice[j]；\treturn h.IntSlice[i] &gt; h.IntSlice[j]}func (h *heap2) Push(v interface{}) {\th.IntSlice = append(h.IntSlice, v.(int))}func (h *heap2) Pop() interface{} {\ttemp := h.IntSlice\tv := temp[len(temp)-1]\th.IntSlice = temp[:len(temp)-1]\treturn v}func (h *heap2) push(v int) {\theap.Push(h, v)}func (h *heap2) pop() int {\treturn heap.Pop(h).(int)}func main() {\tq := &amp;heap2{[]int{3, 4, 1, 2, 4, 3}}\theap.Init(q)\tq.pop()\tfmt.Println(len(q.IntSlice))\tfmt.Println(q)}知识点数组和切片 数组在内存中是一段连续的内存空间，元素的类型和长度都是固定的； 切片在内存中由一个指向底层数组的指针、长度和容量组成的，长度表示当前包含的元素个数，容量表示切片可以拓展的最大元素个数。切片 s[x: y] 表示 s 中第 x 位到第 y - 1 位元素截取。协程/线程/进程的区别 进程:是具有一定独立功能的程序，是系统资源分配和调度的最小单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。适合计算密集型的任务，考虑可以使用多核 CPU，使用多进程。 线程:是进程的一个实体，是内核态，而且是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。适合 I/O 密集型，且 I/O 请求比较快的任务。 协程:是一种用户态的轻量级线程，拥有自己的寄存器上下文和栈，协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。或者说，协程能保留上一次调用时的状态。并且协程的默认占用内存远比其他语言的线程要少。goroutine：2KB（官方），线程：8MB（参考网络）。适合 I/O 密集型，且 I/O 请求比较耗时的任务。 Q: 为什么进程切换比线程切换代价大，效率更低？A: 每次进程切换时，都会涉及页表的切换，切换页表这个操作本身是不太耗时的，但在切换之后，TLB（页表缓存/快表）就失效了，所以在进行地址转化时就需要重新去查找页表，这就造成了程序运行的效率低下。而同一个进程的线程之间是共用一个页表的，所以线程之间的切换是不需要切换页表的，因此线程切换不存在上述代价大，效率低的问题。Go 和 Java 的区别 语言特性： Java 面向对象，静态语言，有完整的继承体系，不支持多继承，值传递 Go 虽然是静态类型语言，但具有动态类型语言的鸭子类型（基于 interface 实现），支持多继承，值传递 并发模型： Java 的并发基于线程和锁 Go 的并发基于协程和通道，可以实现轻量级的并发 性能 Java 需要通过虚拟机，可跨平台，从字节码编译成机器码 Go 的效率高，因为没有虚拟机，直接编译成机器码 Byte 和 Rune 类型 byte是uint8的别称，一个值就是一个ASICII码的值，占 1 个字节的英文类字符，使用 byte rune是int32的别称，一个值就是一个Unicode字符，占 1 ~ 4 个字节的其他字符，可以使用rune（或者int32），如中文、特殊符号等。内存对齐好处 平台原因：不是所有的硬件平台都能访问任意地址上的任意数据的，某些硬件平台只能在某些地址处取某些特定类型的数据 提高访问效率：考虑到 CPU 是分块读取数据的，假设一次性读取4字节的数据，如果不进行内存对齐，则需要多次读取内存中的数据，再进行剔除等操作，极大降低CPU性能。" }, { "title": "Note from Work", "url": "/posts/note-from-work/", "categories": "", "tags": "backend", "date": "2023-09-07 10:41:22 +0800", "snippet": " Grafana 的数据显示会五分钟自动补全。当向 Prometheus 中插入某个时间戳的值时，其值会延续五分钟。 K8S 中的 Sidecar 模式：通常情况下一个 Pod 只包含一个容器，但是 Sidecar 模式是指为主容器提供额外功能（例如监控） 从而将其他容器加入到同一个 Pod 中。再例如 Istio 实现 Sidecar 自动注入。 Fe...", "content": " Grafana 的数据显示会五分钟自动补全。当向 Prometheus 中插入某个时间戳的值时，其值会延续五分钟。 K8S 中的 Sidecar 模式：通常情况下一个 Pod 只包含一个容器，但是 Sidecar 模式是指为主容器提供额外功能（例如监控） 从而将其他容器加入到同一个 Pod 中。再例如 Istio 实现 Sidecar 自动注入。 Federated cluster，联邦集群 限流算法：漏桶和令牌桶算法，漏桶算法处理请求的速度固定，突发请求过多时会丢弃；令牌桶算法除了限制数据的平均传输速率外，还要求允许某种程度的突发传输。 常见 HTTP 状态码：2XX，成功响应；3XX，重定向消息；4XX，客户端错误响应；5XX，服务端错误响应。 请求分为四部分：请求行，请求头，空行，请求正文（不一定有）。 .gitignore 是在文件从工作区被 add 到暂存区时判断是否要被忽略，对于已经在暂存区的文件，不作判断。 限流算法 固定窗口：借助 Redis 的 String 数据结构，每次请求 value 自增，并设置过期时间 滑动窗口：借助 Redis 的 Zset 数据结构，以时间戳作为 score，每次请求使用 Zcount 查找窗口内的成员数量 漏桶：记录上次请求时间戳、当前剩余水量和容量，每次请求计算当前剩余水量减去时间差乘以每秒处理数，判断是否小于容量，是则放行并增加水量，不是则限流 令牌桶：记录上次请求时间戳、当前令牌桶数量和容量，每次请求计算当前令牌数量与时间差乘以每秒放入令牌数的和，如果当前令牌数大于零，则令牌数减一并放行，否则限流Cookie 和 Session 的区别 存储位置：Cookie 存储在客户端，Session 存储在服务端 存取方式：Cookie 只能保存 ASCII，Session 可以存任意数据类型，比如 UserId 等 有效期：Cookie 可以长时间保持，Session 在客户端关闭的时候会失效 存储大小：单个 Cookie 大小不超过 4KB，Session 则没有限制数据结构红黑树特性 节点非红即黑 根节点是黑色 叶子节点是黑色的空节点 红节点的子节点是黑节点 从根节点到空节点的每条路径，包含相同数量的黑色节点常见NoSQL数据库类型 键值数据库：Redis 列式数据库：HBase, ClickHouse，适用于联机分析处理（OLAP）场景，数仓等 文档数据库：MongoDB, ElasticSearch 图数据库Clickhouse： 不支持事务：因为面向列。不存在隔离级别。ClickHouse的定位是分析性数据库，而不是严格的关系型数据库 不支持高并发 可处理大量读请求，数据压缩的特性分布式理论两阶段协议https://juejin.cn/post/6844903621495095309三阶段协议https://juejin.cn/post/6844903621495111688FLP 不可能性原理在网络可靠，存在节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性算法。对于允许节点失效情况下，纯粹异步系统无法确保一致性在有限时间内完成。举例：三个人在不同房间，进行投票（投票结果是 0 或者 1）。三个人彼此可以通过电话进行沟通，但经常会有人时不时地睡着。比如某个时候，A 投票 0，B 投票 1，C 收到了两人的投票，然后 C 睡着了。A 和 B 则永远无法在有限时间内获知最终的结果。CAP 定理分布式系统只能交付以下三个所需特性中的两个特性：一致性、可用性和分区容错性。 C（Consistency）：一致性，指的是所有客户端可以同时看到相同的数据。每当数据写入一个节点时，就必须立即将其转发或复制到系统中的所有其他节点 A（Availability）：可用性，指的是可用性表示发出数据请求的任何客户端都会得到响应，即使一个或多个节点宕机。 P（Partition tolerance）：分区容错性，指分区之间的通信可能失败。一般来说，在分布式系统中不可避免会出现分区，因此认为 P 总是成立。因此若要实现一致性（CP），那么当出现分区问题时，就需要舍弃不一致的节点，即牺牲可用性。同理，若要实现可用性（AP），那么当出现分区问题时，就无法保证一致性。Nacos集群默认是基于 Distro 协议的 AP 原则（即不支持数据一致性，支持服务注册的临时实例），但也可切换至基于 Raft 的 CP 原则（支持服务注册的永久实例）。临时实例和持久化实例的区别： 持久化实例健康检查后会被标记为不健康，而临时实例会直接从列表中删除。MongoDB 是一种 CP 数据存储——它通过牺牲可用性、保持一致性来解决网络分区问题。BASE 理论 Basically Available(基本可用)，假设系统出现了不可预知的故障，但还是能用。 Soft State（软状态），允许系统在多个不同节点的数据副本存在数据延时。 Eventually Consistent（最终一致性），在软状态的一定期限过后，应达到数据的最终一致性。核心思想是：即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。Raft 算法可视化链接三种角色： Leader，发送心跳包以维护自己的Leader状态 Follower，响应Leader发送的心跳包 Candidate，如果没有接收到Leader的心跳信号后，Follower会变成Candidate并向其他节点发送拉票信息记时器： 选举超时时间（Follower拥有）：若超时前没有收到心跳包，认为Leader下线，此时Follower会变成Candidate；但反之如果接收到心跳包，则重置计时器。 投票超时时间（Candidate拥有）：若超时前没有得到半数以上的票数，则竞选失败；反之成功。 竞选等待超时时间（竞选失败的Follower拥有）：竞选失败的Follower需要等待一段时间后才能重新竞选。脑裂由于某种原因（网络不稳定）使得主从集群一分为二，导致master或者leader节点的数量不为1（0或2）。 redis脑裂master 机器突然脱离网络，使得 sentinel 集群无法感知到 master 的存在，会重新选举一个 master 节点。网络恢复后则会存在两个 master 节点。 zookeeper脑裂脑裂可能出现平票的情况，从而无法选举出 leader。因此，zk 中建议节点数是奇数。K8sKubernetes主要由以下几个核心组件组成： etcd保存了整个集群的状态； apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制； controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上； kubelet负责维持容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理； Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）； kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；除了核心组件，还有一些推荐的add-ons（扩展）： kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询23种设计模式与六大原则23种设计模式 创建型 单例模式（Singleton） 饿汉模式：类加载的时候就创建实例 懒汉模式：只有当第一次使用的时候才创建实例 双重校验锁：线程安全，实例需要用 volatile 修饰 原型模式（Prototype），能够复制已有对象，而又无需使代码依赖它们所属的类。例如 Cloneable 接口是立即可用的原型模式。 工厂方法模式（Factory Method），在父类中提供一个创建对象的方法， 允许子类决定实例化对象 抽象工厂模式（Abstract Factory），定义了用于创建不同产品的接口， 但将实际的创建工作留给了具体工厂类。 每个工厂类型都对应一个特定的产品变体。 建造者模式（Builder），分步骤创建复杂对象。 行为型 模板方法模式（Template Method），它在基类中定义了一个算法的框架，允许子类在不修改结构的情况下重写算法的特定步骤。 责任链模式（Chain of Responsibility），它让多个处理器（对象节点）按顺序处理该请求，直到其中某个处理成功为止，例如检查商品模块，需要先检查商品合法性，再检查商品可见性等等。 命令模式（Command） 迭代器模式（Iterator），能在不暴露集合底层表现形式 （列表、 栈和树等） 的情况下遍历集合中所有的元素。 中介者模式（Mediator） 备忘录模式（Memeoto） 观察者模式（Observer） 状态模式（State） 策略模式（Strategy），规定每个策略的不同方法，只需选择不同的策略即可执行不同的方法，例如数字人项目中 Provider 的选择（1：AiLab，2：Creatify，3：IC，4：IC-NEW） 访问者模式（Visitor） 解释器模式（Interpreter） 结构型 适配器模式（Adaptor） 桥接模式（Bridge） 组合模式（Composite） 装饰模式（Decorator） 外观模式（Facade），为复杂系统、程序库或框架提供一个简单的接口。通常作用于整个对象子系统上。 享元模式（Flyweight），共享多个对象的部分状态将内存消耗最小化。 代理模式（Proxy），例如动态代理 六大原则 开闭原则，对扩展开放，对修改关闭。 单一职责原则，顾名思义，一个类的职责只有有一个。 里氏替换原则，子类可以扩展父类的功能，但不能改变父类原有的功能。 依赖倒转原则，依赖于抽象，不能依赖于具体实现（面向接口编程）。 接口隔离原则，类之间的依赖关系应该建立在最小的接口上。 迪米特原则，一个软件实体应当尽可能少的与其他实体发生相互作用。分布式事务 Seata分两阶段提交 TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器：定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。执行流程： TM 向 TC 请求发起(Begin)、提交(Commit)、回滚(Rollback)等全局事务。 TM 把代表全局事务的XID绑定到分支事务上。 RM 向 TC 注册，把分支事务关联到XID代表的全局事务中。 RM 把分支事务的执行结果上报给 TC。 TC 发送分支提交（Branch Commit）或分支回滚（Branch Rollback）命令给RM。四大模式： AT模式，能适用于大部分事务情况。 XA模式 SAGA模式，核心思想是将长事务拆分成多个本地短事务。 TCC模式，核心思想是针对每个操作都要注册一个与其对应的确认和补偿操作。其他分布式事务解决方案： 基于 RocketMQ 的消息事务 二阶段提交 三阶段提交，CanCommit、PreCommit、DoCommit三阶段ZooKeeper（CP）使用 ZAB 协议，包括两种运行模式： 消息广播（Leader 正常运行），所有事务请求由单一主进程处理，Leader 转换为事务 Proposal 并广播分发给 Follower，Leader 等待 Follower 的反馈，超过半数的 Follower 反馈消息后，Leader 再发送 Commit 消息提交事务 Proposal。 崩溃恢复（Leader 不可用时），新选举产生的 Leader 与过半的 Follower 进行同步，使数据一致，同步后进入消息广播模式。 主要服务于分布式系统，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理，用来解决分布式集群中应用系统的一致性问题，构建 ZooKeeper 集群时使用的服务器最好是奇数台。其设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。数据结构：Znode节点，与Unix文件系统类似，通过路径来标识，例如 /home/app，Znode节点又分为两种类型：临时节点、持久节点、临时顺序节点、持久顺序节点。客户端和服务端断开连接后，临时节点会自动删除但持久节点不会。分布式锁使用的是临时节点。Watcher 监听器：节点的数据发生变化后会通知到节点的监听器。基本命令： create : 在树中的某个位置创建一个节点 delete : 删除一个节点存在：测试节点是否存在于某个位置 get data : 从节点读取数据 set data： 将数据写入节点 get children : 检索节点的子节点列表 sync : 等待数据被传播实现分布式锁原理：判断能否创建临时节点，如果不能则监听父节点（非公平锁）或上一个节点（公平锁），任务执行完成后释放该节点并通知所有监听的节点。实现注册中心原理：初始化时 Provider 先向目录写入 URL 地址，Consumer 订阅相同目录的 URL 地址和自己的 URL 地址，监控中心订阅 Provider 和 Consumer 的 URL 地址；Consumer 在第一次调用服务时，会通过注册中心找到相应的服务的IP地址列表，并缓存到本地，以供后续使用；当 Provider 下线时，会在列表中移除 URL 并将新的 URL 地址发送给 Consumer 并缓存至本地，服务上线也是一样的。与 Nacos 的区别：Nacos 是 AP 的，保证可用性，每个节点都是平等的，若干个节点 crash 后不会影响正常节点，但查到的信息不一定是最新的。ZK 在 crash 后进行 leader 选举，期间是不可用的。微服务框架：Dubbo底层基于 Netty 的 NIO 框架，基于 TCP 协议传输四种负载均衡策略支持服务端服务级别、服务端方法级别、客户端服务级别、客户端方法级别的负载均衡配置。还可以拓展负载均衡算法。 随机负载均衡，默认策略 轮询负载均衡 最少活跃调用数，每个 Provider 都有一个计数器，开始调用则计数器加一，结束调用计数器减一。原则是将请求分配给处理速度快的 Provider。 一致性哈希负载均衡HTTPS 如何保证可靠传输TLS 协议： 对称加密/非对称加密 数字证书 三次握手/四次挥手TLS 的 rsa 握手过程，存在什么安全隐患，怎么解决的？ 安全隐患：不支持前向保密。如果私钥泄露了，所有密文都会被破解 解决方案：密钥协商算法HTTPS 绝对安全吗NO，可以通过中间人攻击的方式，即所有请求先发送给第三方（中间人），返回中间人的证书，后续的请求/响应都通过中间人进行转发。HTTP版本的演变HTTP/1.0 无状态：服务器不追踪不记录请求过的状态 无连接：每次请求要建立连接，无法复用连接；在前一个请求响应到达之后下一个请求才能发送，如果前一个阻塞，后面的请求也被阻塞HTTP/1.1默认浏览器对同一域名的并发请求限制为 6 - 8 个。 长连接：默认保持长连接，数据传输完成后只要不断开连接，就可以继续传输数据 管道化：基于上面长连接的基础，可以不等第一个请求响应继续发送后面的请求，但响应的顺序还是按照请求的顺序返回 缓存处理：新增字段cache-control 断点传输：在上传/下载资源时，如果资源过大，将其分割为多个部分，分别上传/下载HTTP/2 二进制分帧传输：更方便头部，只传输差异部分 多路复用：同一服务下只需要用一个连接，节省了连接 头部压缩：合并同时发出请求的相同部分 服务器推送：一次客户端请求服务端可以多次响应HTTP/3基于谷歌的QUIC，底层使用udp代码tcp协议，解决了队头阻塞问题，同样无需握手，性能大大地提升，默认使用tls加密。进程和线程进程拥有的资源 进程控制块 文件描述符 网络连接 设备区别： 进程是系统资源分配的最小单位，实现了操作系统的并发；线程是CPU调度的最小单位，实现了进程内部的并发。 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。 进程切换的开销远大于线程切换的开销。 进程之间不会相互影响，但线程挂掉会影响整个进程。进程间通信方式： 管道 信号量 消息队列 共享内存 套接字，也可以用于不同主机之间进程的通信线程间通信方式： 共享内存，比如 volatile 保证内存的可见性。 消息传递，比如 wait/notify/notifyAll 等待通知方式和 join 方式。 管道流用户态和内核态为什么要有这两个状态？保护机制，防止用户误操作或恶意破坏系统用户态 是用户进程/线程所在的区域，主要用于执行用户程序 运行的代码会受到CPU的很多检查，不能直接访问内核数据 只拥有受限的权限 只能响应部分中断请求 只能访问受限的地址空间内核态 是内核进程/线程所在的区域，主要用于执行操作系统程序，硬件交互 运行的代码不受任何限制，可以执行任意指令 拥有最高权限 可以响应所有中断请求 可以访问所有内存空间用户态切换到内核态 系统调用（主动）。操作系统在执行用户程序的时候主要工作在用户态，当执行没有权限的任务时，才切换到内核态。 异常（被动）。执行用户程序出现异常时，会从用户态切换到内核态处理异常 外围设备中断（被动）。中断发生时，如果中断之前在运行用户态的程序，那么会切换至内核态处理中断。服务注册与发现如果自己实现服务注册与发现，需要考虑以下三点： Register, 服务启动时候进行注册 Query, 查询已注册服务信息 Healthy Check, 确认服务状态是否健康实现方案： Eureka，AP ZooKeeper，CP，Paxos 算法 Consul，CP，Raft 算法 Etcd，CP，Raft 算法Paxos 和 Raft 算法都属于一致性算法，所以是保证 CP实际上，作为一个注册中心来说，保证 AP 更加重要，即可用性。两种模式 客户端发现模式，首先要进行的是到服务注册中心获取服务列表，然后再根据调用端本地的负载均衡策略，进行服务调用。 服务端发现模式，调用方直接向服务注册中心进行请求，服务注册中心再通过自身负载均衡策略，对微服务进行调用。这个模式下，调用方不需要在自身节点维护服务发现逻辑以及服务注册信息。常见的负载均衡 轮询，按照请求的顺序轮流分配到不同的服务器，循环往复。 加权轮询，给不同的服务器分配不同的权重，根据权重比例来决定分配请求的数量。 最小连接数 最短响应时间 IP哈希RPC/HTTP与 HTTP 的对比，RPC 使用二进制传输，传输效率高（HTTP额外空间开销大，包含大量元数据，头字段等），但通用性不如 HTTP 协议核心 消息协议：以何种方式打包编码和拆包解码 传输控制：主要有HTTP传输和TCP传输，鉴于TCP传输的可靠性，RPC的传输一般使用TCP作为传输协议工作流程 客户端（Client）以本地方法调用服务 客户端存根（Client Stub）收到调用后把方法、参数等内容打包成特定格式、能进行网络传输的消息体（Marshalling） 客户端存根找到服务地址，发送给服务端（这个过程可以基于TCP也可以基于HTTP） 服务端存根（Server Stub）收到消息后拆包解码（Unmarshalling） 服务端存根根据方法名和参数进行本地调用服务 服务端（Server）本地执行后把结果返回给服务端存根 服务端存根把结果打包发送给客户端存根 客户端存根接收到消息进行解码 客户端得到最终结果实现方式 基于 http 基于 tcp（常见）计算机网络最大 TCP 连接数量一台机器作为客户端和服务端时，能建立的最大 TCP 连接数量不同。客户端单个 IP 的情况下，受内核参数 net.ipv4.ip_local_port_range 的限制，范围为0 ~ 65535，但一般默认在 3w ~ 5w 之间。但多网卡的情况下可以有多个 IP，因此最大连接数的理论值以线性增长。服务端理论上连接数为 2^32 （IP数量） * 2^16（端口数量）* 2^16 （服务端口数量）。但每个 TCP 连接需要消耗内存 3.3 K 左右，因此实际上最大建立连接数为内存大小 / 3.3K，假设 4GB 内存，最大连接数为 100 万个左右。TCP/UDP 可以使用同一个端口吗可以。传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。可以在 IP 包头的协议号字段判断出 TCP 还是 UDPTCP 三次握手为什么三次握手因为三次握手才能保证双方具有接收和发送的能力，并且防止重复建立历史连接。为什么四次挥手本质原因是 TCP 是全双工通信，客户端确认没有数据发送后，发出结束报文，此时服务端返回确认后，服务端也不会接收客户端数据。但是此时服务端可能还有数据没有传输完，客户端还是可以接收数据。如果挥手过程中「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。DNS使用TCP还是UDPDNS 在进行区域传输的时候使用 TCP，其他情况使用 UDP。区域传输：是指DNS主从服务器之间的数据同步，保证数据的一致性，传送会利用DNS域，所以就称为DNS区域传送。TCP 保证可靠传输 序列号 连接建立：三次握手四次挥手 头部检验和 确认应答 超时重传 拥塞控制：四种算法 慢启动 拥塞避免 拥塞发生 快速恢复 流量控制：滑动窗口实现OSI 七层模型和 TCP/IP 四层模型 应用层：HTTP，DNS，FTP，WebSocket；网关 应用层 表示层 会话层 传输层：TCP，UDP；网关 网络层：IP（在TCP/IP模型中，ARP属于网络层）；路由器 网络接口层 数据链路层：ARP；网桥，交换机 物理层：网卡；中继器，集线器 架构在高并发环境下，服务之间的依赖关系导致调用失败，解决的方式通常是: 限流-&gt;熔断-&gt;隔离-&gt;降级, 其目的是防止雪崩效应。死锁四个条件： 互斥 请求和保持 不可剥夺 循环等待一致性哈希一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环（固定大小）上。数据存储在哈希值通过顺时针找到的第一个节点。优势一致性哈希算法是对 2^32 取模，是一个固定的值；而普通哈希表的长度是由节点数决定的。 普通哈希函数，如果节点数量发生了变化（对系统进行扩容缩容的时候），大部分改变了映射关系，因此需要迁移大量的数据。 一致性哈希算法，如果节点数量发生了变化，只影响该节点顺时针相邻的后继节点。虚拟节点的引入一致性哈希算法并不保证节点能够在哈希环上分布均匀，因此引入均匀分布的虚拟节点，建立真实节点和虚拟节点的映射关系。IO 同步 同步阻塞IO 同步非阻塞IO IO多路复用 信号驱动IO 异步 异步IO 虚拟内存虚拟内存是一种计算机技术，它允许系统将一部分硬盘空间当作RAM（随机存取存储器）使用。当物理内存不足以支持正在运行的应用程序时，系统会将不常用的数据移动至磁盘中。虚拟内存为每个进程提供了一个一致的、私有的地址空间32位/64位操作系统的区别32位/64位表示CPU可以处理最大位数，一次性的运算量不一样，寻址能力也不同。域名解析流程 检查缓存 浏览器缓存 操作系统缓存 本地 hosts 文件 主机使用递归查询向本地域名服务器查询 本地域名服务器使用迭代查询向根服务器查询 根域名服务器(.) 顶级域名服务器(.com) 二级域名服务器(google.com) 排查 CPU 占用过高和内存溢出的问题JavaCPU 占用排查：使用 top 和 top -Hp xxx 命令定位占用率最高的进程和该进程的线程内存占用排查：jstack， jmap 打印出堆栈信息， jstat 查看垃圾回收的情况 Jstat 可以查看新生代的两个S0、s1区、Eden区，以及老年代的内存使用率，还有young gc以及full gc的次数。 Jmap 可以查看当前堆中所有每个类的实例数量和内存占用，也可以 dump 内存快照，再由 VituralVM 或 MAT 软件可视化查看。Go使用 pprof 工具，可以查看 CPU 占用、排查内存泄漏、协程泄漏等。互斥锁和自旋锁 互斥锁是一种阻塞锁，获取不到锁的时候，线程会被挂起。 自旋锁是一种非阻塞锁，获取不到锁的时候，线程不会被挂起，而且不断去获取，消耗 CPU 资源。缓存 IO，直接 IO，裸 IO 缓存IO：读数据时先从内核空间的缓冲区读，如果没有则从磁盘中读并缓存到缓冲区；写数据将用户空间的数据复制到内核空间的缓冲区，并标记为脏页，操作系统后台将脏页写入磁盘中，一般用于频繁读写的小文件； 直接IO：直接读写文件，而不经过内核缓冲区，目的是减少一次内核缓冲区到用户程序缓存的数据复制，一般用于不需要频繁读写的大文件； 裸IO：绕过文件系统，直接读写磁盘块设备数据，一般用于数据库；Base64 和 Base62 的区别编码 Base64：26 个大写字母 + 26 个小写字母 + 10 个数字 + + + /；并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的「/」和「+」字符变为形如「%XX」的形式。 Base62：26 个大写字母 + 26 个小写字母 + 10 个数字。实现 Base64：将输入字符串按字节切分，取得每个字节对应的二进制值（若不足 8 比特则高位补 0），然后将这些二进制数值串联起来，再按照 6 比特一组进行切分（因为 2^6=64），最后一组若不足 6 比特则末尾补 0。若原字节序列数据长度不是 3 的倍数时且剩下 1 个输入数据，则在编码结果后加 2 个 =；若剩下 2 个输入数据，则在编码结果后加 1 个 =。将每组二进制值转换成十进制，然后找到对应的符号并串联起来就是 Base64 编码结果。 Base62：将输入字符串哈希后转成长整型，再用62进制编码成Base62格式。XXL-JOB 定时任务框架说到底，定时器还是靠线程轮询实现的。调度器负责下发任务、执行器管理、日志管理等。执行器负责执行任务、心跳检测、结果回调等。" }, { "title": "Kafka vs RocketMQ", "url": "/posts/kafka-vs-rocketmq/", "categories": "", "tags": "backend", "date": "2023-08-25 17:10:22 +0800", "snippet": "基本概念 RocketMQ 由 Producer, Brocker, Consumer 组成 Producer 负责生产消息 Consumer 负责消费消息 Broker 负责存储消息，每一个 Broker 对应一台服务器但可以存储多个 Topic 的消息，每个 Topic 的消息也分片存储在不同的 Broker 里。 Topic...", "content": "基本概念 RocketMQ 由 Producer, Brocker, Consumer 组成 Producer 负责生产消息 Consumer 负责消费消息 Broker 负责存储消息，每一个 Broker 对应一台服务器但可以存储多个 Topic 的消息，每个 Topic 的消息也分片存储在不同的 Broker 里。 Topic 是逻辑概念，队列（Kafka 中叫分区）是物理概念。每个主题包含多个消息，每条消息只属于一个主题。一个 Producer 可以同时发送多种 Topic 的消息，而一个 Consumer 只能订阅一个 Topic 的消息。Tag 类似于子主题。 MessageQueue用于存储消息的物理地址，每个Topic中的消息地址存储于多个MessageQueue，是消息的最小存储单元。 消费方式，Pull 拉取式消费，Consumer 需要主动拉取 Broker 中的消息；Push 推送式消费，Broker 一接收到消息马上发送给 Consumer，具有实时性。RocketMQ是基于 Pull 模式的长轮询策略实现消息消费的。即 Consumer 发送拉取请求到 Broker 端，如果 Broker 有数据则返回并继续发起长轮询，如果没有则 hold 请求（指的服务端暂时不回复结果，保存相关请求，不关闭请求连接），不立即返回，直到超时（默认5s）并继续发起长轮询。为什么需要设置超时？1. 无法避免服务器假死等情况以确保可用性；2. 可能修改监听的配置消息队列的三大作用 解耦 异步 削峰模式 点对点模式：基于队列，每条消息只能被一个消费者消费，RabbitMQ。 发布/订阅模式：一条消息能被多个消费者消费，RocketMQ 和 Kafka。消息发送方式 RocketMQ 同步发送(Sync) 异步发送(Async) 单向发送(One-way)其中同步发送和异步发送需要 Broker 返回确认消息，而单向发送不需要。 Kafka 发后即忘(fire-and-forget) 同步(sync) 异步(async) 消息消费方式 Kafka：从用户角度分为手动提交和自动提交；从 Consumer 的角度分为同步提交和异步提交 自动提交偏移量 手动同步提交偏移量 手动异步提交偏移量 同步异步结合提交偏移量 区别整体区别是 Kafka 的设计初衷是用于日志传输，而 RocketMQ 是用于解决各类应用可靠的消息传输，适用于业务需求。存储形式 Kafka 采用partition，每个topic的每个partition对应一个文件。顺序写入，定时刷盘。但一旦单个broker的partition过多，则顺序写将退化为随机写，Page Cache脏页过多，频繁触发缺页中断，性能大幅下降。 RocketMQ 采用CommitLog + ConsumeQueue，物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每个Topic下的每个MessageQueue都有一个对应的ConsumeQueue文件，单个broker所有topic在CommitLog中顺序写。每个CommitLog大小固定为1G。 生产消息：Producer 先向 CommitLog 顺序写，持久化后将数据 Dispatch 到 ConsumeQueue 中。消费消息：Consumer 从 ConsumeQueue 中拉取数据，但拉取到数据是指向 CommitLog 的地址，此时是随机读，但又因为 PageCache 的存在，还是整体有序的。Page Cache（页面缓存）从内存中划出一块区域缓存文件页，如果要访问外部磁盘上的文件页，首先将这些页面拷贝到内存中，再进行读写。吞吐量 Kafka 单机吞吐量 TPS 可上百万，远高于 RocketMQ的 TPS 十万级。数据可靠性RocketMQ新增同步刷盘和同步复制机制，保证可靠性。而 Kafka 倾向于牺牲部分可靠性换取更高的性能（因为 Kafka 中的 producer 将信息堆起来一起发送，以减少网络IO，但是这个时候如果 producer 宕机了，会导致信息丢失的）。 Kafka 支持异步刷盘，异步复制。 RocketMq 支持异步刷盘和同步刷盘，同步复制和异步复制。异步刷盘：返回写成功状态时，消息可能只是被写进内存，吞吐量大，当内存大消息积累到一定程度时，统一触发写磁盘操作，快速写入。同步刷盘：返回写成功状态时，消息已经被写入磁盘。流程是消息写入内存后，立刻通知刷盘线程刷盘，等待刷盘完成后再唤醒等待的线程返回消息写成功的状态。异步复制：只要写就返回写成功状态。较低的延迟和较高的吞吐量。同步复制：写成功后返回写成功状态。容易恢复故障的数据。如何保证消息不丢失两者类似，都是从 Producer -&gt; Broker -&gt; Consumer 三个阶段逐一判断，只不过设置的参数不同。 Producer: 同步发送消息；超时重试发送；消息补偿机制（Kafka，超时仍失败的情况下，会继续投递到本地消息表，定时轮询并推送到Kafka）；ACKs（Kafka中，该参数表示多少个副本收到消息，认为消息写入成功） Broker: 同步刷盘；设置主从模式，配置副本 Consumer: At least Once 的消费机制；消费重试；手动提交偏移量（Kafka） 零拷贝传统的数据传输过程通常需要经历多次内存拷贝。首先，从磁盘读取数据，然后将数据从内核空间拷贝到用户空间，再从用户空间拷贝到应用程序的内存中。这些额外的拷贝会消耗大量的CPU资源和内存带宽，降低数据传输的效率。零拷贝就是为了避免这些不必要的数据拷贝，能够将数据直接传输到目标内存区域，以提高数据传输的效率。实现方式 mmap(Memory Mapped Files) + write，作用：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。Java NIO里对应的是MappedByteBuffer类，可以用来实现内存映射。它的底层是调用了Linux内核的mmap的API。 sendfile，实现：将读到内核空间的数据，直接拷贝到socket buffer，进行网络发送。避免了数据在内核和用户空间之间的额外拷贝。FileChannel的transferTo()/transferFrom()，底层就是sendfile() 系统调用函数。零拷贝技术减少了用户进程地址空间和内核地址空间之间由于上下文切换而带来的开销。DMA (Direct Memory Access) 是零拷贝技术的基石。并不是不需要拷贝，而是减少冗余不必要的拷贝。 Kafka： Producer生产的数据持久化到 broker 采用 mmap 文件映射（在读写稀疏索引文件用到），实现顺序的快速写入；而 Customer 从 broker 读取数据采用 sendfile 进行网络发送。 RocketMQ：采用 mmap 的方法。正因为使用内存映射机制，RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存。为什么 Kafka 这么快？答：六个要点，顺序读写、零拷贝、消息压缩、分批读写/发送、基于操作系统内存PageCache的读写、分区分段 + 索引。为什么 RocketMQ 这么快？答：顺序写，零拷贝，异步刷盘（先写入操作系统的PageCache再异步刷盘到磁盘）消息失败重试 Kafka 不支持重试。 RocketMQ 支持定时重试，每次重试间隔逐渐增加。RocketMQ 的消费重试是基于延迟消息实现的，在消息消费失败的情况下，重新当作延迟消息投递到 Broker 中，并且延迟等级逐渐增加，消息重试会有 16 个级别，恰好是延迟消息的 18 个级别的后 16 个级别。Rocket延迟消息主要分为以下几步，类似于流转： 修改消息的Topic名称和队列信息（因为发送到普通的Topic会马上被消费） 转发消息到延迟Topic为SCHDULE_TOPIC_XXX的ConsumeQueue中 延迟服务（本质是Java自带的延迟队列）消费SCHDULE_TOPIC_XXX的消息 将信息重新存储到CommitLog中 将消息投递到目标Topic中 消费Topic的消息Kafka 延迟消息基于 时间轮 算法（类似于钟表）：存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表。每隔一个时间跨度，下标移动一次。事务 Kafka 支持事务（更像是原子性），可以实现对多个 Topic 、多个 Partition 的原子性的写入，即处于同一个事务内的所有消息，最终结果是要么全部写成功，要么全部写失败。这种事务机制单独使用的场景不多，更多的是配合其幂等机制来实现 Exactly Once 语义的。通常用于解决从一个 Kafka 数据源消费进行计算等操作，再输入到另一个 Kafka 数据源中的场景。 RocketMQ 支持事务，采用二阶段提交+broker定时回查。但也只能保证生产者与broker的一致性，broker与消费者之间只能单向重试。即保证的是最终一致性。Kafka 事务RocketMQ 事务对于一个大事务来说，可以划分成多个小事务异步执行。本质是两阶段协议 + 补偿机制（事务回查）实现的。 二阶段：第一阶段发送 prepared 消息，接着执行本地事务，第二阶段发送 commit 或 rollback 的消息。 定时回查：定时遍历 commitlog 中的半事务消息如果事务正常执行，则 commit 该消息，如果抛出异常，则 rollback。对于消费消息失败，RocketMQ 会尝试重新消费，直到被加入死信队列中为止。在重试的过程中有可能产生重复的消息，所以对于消费端来说要确保消费幂等！消息堆积原因可能是以下三种： 生产远超预期 消息接收和持久化出现故障 消费能力下降 程序问题处理堆积的消息：建立临时的 topic（扩容），转发堆积的消息服务发现 Kafka 使用 ZooKeeper，但新版本使用内嵌的KRaft替代了ZooKeeper RocketMQ 使用自己实现的 nameserverTopic 数量对吞吐量的影响RocketMQ：topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topicKafka：topic 从几十到几百个时候，吞吐量会大幅度下降。原理：Kafka 利用操作系统的 PageCache 先将消息持久化到内存中，并不是直接写入磁盘。Topic 增加，也就是 Partition 数量会增加，使用的 PageCache 也会大量增加，大量增加后需要使用 LRU 淘汰算法对 Page 内容刷新到磁盘中，导致性能会下降。消息顺序性分为两步：生产者有序存储，消费者有序消费。Kafka 如何保证消息的顺序性针对消息有序的业务需求，还分为全局有序和局部有序。已知，每个partition的消费是顺序性的，但每个topic可以有若干个partition。全局有序：一个Topic下的所有消息都需要按照生产顺序消费。解决方法：1个Topic只能对应1个Partition。局部有序：一个Topic下的消息，只需要满足同一业务字段的要按照生产顺序消费。例如：Topic消息是订单的流水表，包含订单orderId，业务要求同一个orderId的消息需要按照生产顺序进行消费。解决方法：要满足局部有序，只需要在发消息的时候指定Partition Key，Partition Key相同的消息会放在同一个Partition。RocketMQ 如何保证消息的顺序性全局有序：对于指定的一个 Topic，设置读写队列的数量为一。（与Kafka设置一个partition类似）局部有序：对于指定的一个 Topic，生产者根据 hashKey 将消息发送到同一个MessageQueue。 同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。实现消息有序性从三个方面： 生产者生产顺序消息：生产者将消息路由到特定分区，单线程发送消息 Broker 保存顺序消息：保证生产者顺序生产即可，保存到指定的Partition或MessageQueue中 消费者顺序消费消息：设置 consumeMode 为 ORDERLY，单线程消费消息Kafka 负载策略主写主读，不支持读写分离Producer 负载均衡当 key 不存在时，会从当前存活的分区中轮询；当 key 存在时，发送给哈希后的指定分区。Consumer 负载均衡Kafka 中主题订阅者的基本单位是消费者组，每个分区只能由消费者组中的一个消费者进行消费，多个消费者组之间对于分区的消费互不影响。共有三个分区分配器： RangeAssignor（默认） RoundRobinAssignor StickyAssignorRocketMQ 负载策略Producer 负载均衡Producer 默认采用轮询的方法，按顺序将消息发送到 MessageQueue 里。Consumer 负载均衡 平均负载策略（默认）：AllocateMessageQueueAveragely 循环分配策略：循环顺序遍历消费者：AllocateMessageQueueAveragelyByCircle 指定机房分配策略：AllocateMessageQueueByMachineRoom 机房就近分配策略：AllocateMachineRoomNearby 一致性哈希算法策略：AllocateMessageQueueConsistentHash 按照指定配置的策略：AllocateMessageQueueByConfig适用场景Kafka：适用于日志收集与分析、实时流处理、大数据集成（例如 Apache Storm 或 Flink）、用户行为追踪等场景。RocketMQ：更适合金融交易、订单处理、秒杀活动、库存同步、跨系统间的服务解耦和异步调用等场景，尤其是那些对消息顺序、事务完整性和实时性要求极高的业务。消费者消费者群组（Consumer Group）消费者组是一组共享 group.id 的消费者实例，一个消费者组可以消费多个 Topic 的消息，组内的消费者只能订阅相同的 Topic 和相同的 Tag 且 Tag 顺序相同。详见订阅关系一致。消费方式（RocketMQ） 集群模式（默认）：相同消费者群组的消费者平摊消息，便于负载均衡 广播模式：相同消费者群组的每个消费者接收全量的消息，适合并行处理的场景。在该模式下，消费者组的概念在消息划分方面并没有意义。 RocketMQ/Kafka 使用 Consumer Group 机制，实现了传统两大消息引擎。如果所有实例属于同一个Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的Group，且订阅了相同的主题，那么它就实现了发布/订阅模型；消费者和消费者组的关系 同一个消费者组内部的消费者均匀消费订阅的 Topic 的消息，负载均衡 不同消费者组全量消费订阅的 Topic 的消息，类似消费者组层面的广播模式。但 Kafka 和 RocketMQ 不同的地方在于，Kafka 所有 Partition 会均匀分配给 Consumer 消费（因此 Consumer 只消费 Topic 的部分数据），而不像 RocketMQ 那样，每个 Consumer 全量消费 Topic 里的消息。Kafka 知识点知识点 Partition 数量只能增加，不能减少。 偏移量：指Kafka主题中每个分区中消息的唯一标识符 ISR: In-Sync Replica; OSR: Out-Sync Replica索引机制基于跳表实现一个Topic分为多个Partition，一个Partition分为多个Segment。每个Segment对应三个文件：偏移量索引文件、时间戳索引文件、消息存储文件根据偏移量/时间戳查找消息偏移量文件中记录的是稀疏索引。偏移量 offset = x 根据偏移量索引文件名和 offset 的值，进行二分查找，找到小于 x 的最大 offset 文件 在该偏移量索引文件(.index)中，找到该 offset 对应的 position 位置 在消息存储文件(.log)中，找到该 position 所对应的消息内容时间戳 timestamp = t 在时间戳索引文件(.timeindex)中，找到比 t 大的最小时间戳，与其所对应的 offset 值 在偏移量索引文件(.index)中，找到该 offset 值对应的 position 位置 在消息存储文件(.log)中，找到该 position 所对应的消息内容Producer 生产消息的流程在消息发送的过程中，涉及到两个线程，main线程和sender线程，其中main线程是消息的生产线程，而sender线程是jvm单例的线程，专门用于消息的发送。在jvm的内存中开辟了一块缓存空间叫RecordAccumulator（消息累加器），用于将多条消息合并成一个批次，然后由sender线程发送给kafka集群。 创建消息以及指定 Topic 调用 Send() 方法 调用拦截器 调用序列化器，将消息序列化 使用分区器（三种分区策略）指定 Partition DefaultPartitioner 默认分区：指定分区则用该分区，没指定则使用对 key 哈希后值的分区，没有 key 则使用粘性分区策略 UniformStickyPartitioner 统一粘性分区：直接使用粘性分区策略，即逐个填满 Batch 里的消息 RoundRobinPartitioner 轮询分区：指定分区则用该分区，否则平均分配 将消息缓存到消息累加器中 压缩和批处理消息 找到相应的 Broker 并发送消息（Sender 线程触发的），可以同步发送也可以异步发送 确认（ACK）和重试 更新偏移量 错误处理，将重试仍失败的消息放入死信队列里Consumer 消费过程Kafka 采用 Pull 的方式，每个 Consumer 维护一个 HW 水位信息消费者线程模型Thread per consumer model：即每个线程都有自己的consumer实例，然后在一个线程里面完成数据的获取（pull）、处理（process）、offset提交。Leader Replica 选举策略 ISR 选举策略：在 ISR 副本集合中选举 首选副本选举策略：每个分区都有一个首选副本，通常是副本集合中的第一个副本 不干净副本选举策略：从所有副本中（包含 OSR 集合）选择一个副本选举Zookeeper 在 Kafka 的作用 Broker 注册：每个Broker服务器在启动时，都会到ZooKeeper上进行注册 Topic 注册：同一个 Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，ZK 负责维护这些分区信息及与 Broker 的对应关系 负载均衡：Consumer 消费消息时，ZK 会根据当前 Partition 数量和 Consumer 数量进行动态负载均衡消息压缩/解压Producer 发送压缩消息到 Broker 后，Broker 会保存压缩数据，由Consumer 解压数据。ControllerController 用于在 ZK 的帮助下管理和协调整个 Kafka 集群。集群内任意一台 Broker 都能充当 Controller 的角色，但在运行过程中，只有一个 Controller。Controller 职责 管理 Topic Preferred Leader 选举 集群 Broker 管理 数据服务，保存最完整的元数据信息手动/自动提交偏移量区别发生 Rebalance 时，自动提交偏移量有可能出现消息丢失/消息重复消费的问题，而手动提交偏移量则不会 消息丢失：提交的偏移量大于消费者处理的最后一个消息的偏移量 消费重复消费：提交的偏移量小于消费者处理的最后一个信息的偏移量Rebalance 触发时机总体来说是消费者和partition的对应关系发生了变化 消费者组内的消费者数量发生了变化 消费者组内的主题分区数发生了变化 消费者组订阅的主题发生了变化" }, { "title": "SpringBoot", "url": "/posts/springboot/", "categories": "", "tags": "backend", "date": "2023-08-10 15:08:32 +0800", "snippet": "Spring, SpringBoot, Spring MVC 区别： Spring框架(Framework)是最流行的Java应用程序开发框架。 Spring框架的主要功能是依赖项注入或控制反转(IoC)。 Spring MVC是Spring的一个MVC框架，包含前端视图，文件配置等。XML和config配置比较复杂。 Spring Boot 是为简化Spring配置的快速开发整合包，...", "content": "Spring, SpringBoot, Spring MVC 区别： Spring框架(Framework)是最流行的Java应用程序开发框架。 Spring框架的主要功能是依赖项注入或控制反转(IoC)。 Spring MVC是Spring的一个MVC框架，包含前端视图，文件配置等。XML和config配置比较复杂。 Spring Boot 是为简化Spring配置的快速开发整合包，允许构建具有最少配置或零配置的独立应用程序。SpringBoot项目启动流程： 总体来说分两部分，先初始化 SpringApplication，再运行 SpringApplication。运行 SpringApplication 又分为：1、获取并启动监听器2、根据监听器和参数来创建运行环境3、准备 Banner 打印器4、创建 Spring 容器5、Spring 容器前置处理（将前几步生成的监听器，Banner打印器和环境等配置到容器中）6、刷新容器7、Spring 容器后置处理（空方法）8、发出结束执行的事件通知9、返回容器Spring核心之控制反转（IOC）和依赖注入（DI）： IOC是一种设计思想，将设计好的Bean对象交给容器控制，而不是在传统的在对象内部直接控制。用@Configutation + @Bean的方式。用通俗的话解释就是在容器里创建Bean对象，在需要的时候取出使用即可。 DI是一种实现方式，将应用程序依赖的对象注入到容器中。IoCrefresh() 的作用：在创建IoC容器前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IoC容器。refresh的作用类似于对IoC容器的重启，在新建立好的容器中对容器进行初始化，对Bean定义资源进行载入。Spring创建Bean的三步（由反射创建的）： 实例化，AbstractAutowireCapableBeanFactory 的 createBeanInstance 方法 属性注入，AbstractAutowireCapableBeanFactory 的 populateBean 方法 初始化，AbstractAutowireCapableBeanFactory 的 initializeBean 方法 调用Aware接口（如果实现了Aware接口） postProcessBeforeInitialization afterPropertiesSet init-method postProcessAfterInitialization Spring启动时先扫描所有Bean信息，BeanDefinition存储日常给Spring Bean定义的元数据。然后存储BeanDefinition的BeanDefinitionMap，是根据字典序依次创建Bean对象。两种IOC容器IOC的实现原理是工厂模式加反射机制。 BeanFactory，只提供了实例化对象和获取对象的功能，使用懒加载机制，不支持国际化和基于依赖的注解 ApplicationContext，其拓展了BeanFactory接口，使用即时加载的机制，它是在Ioc启动时就一次性创建所有的Bean，支持国际化和基于依赖的注解，包括AnnotationConfigApplicationContext、ClassPathXmlApplicationContext、FileSystemXmlApplicationContext等三级缓存解决循环依赖： 前提，出现循环依赖的Bean必须是单例；依赖注入的方式不能全是构造器注入（通过setter方法进行依赖注入，全是构造器注入则无法解决循环依赖）。 getSingleton(beanName)方法三级缓存 singletonObjects，一级缓存，存储的是所有创建好了的单例Bean对象 earlySingletonObjects，二级缓存，完成实例化，但是还未进行属性注入及初始化的提前暴露的对象 singletonFactories，三级缓存，存放生产对象的工厂，并且每次从这个工厂中拿到的对象都是不一样的，二级缓存中存储的就是从这个工厂中获取到的对象，如果Bean存在AOP的话，返回的是AOP的代理对象，提前进行了代理，避免对后面重复创建代理对象。对象加入三级缓存的前提是执行了构造器，因此全是构造器注入的循环依赖无法解决。 为什么需要二级缓存：如果出现循环依赖+aop时，多个地方注入这个动态代理对象需要保证都是同一个对象。如果只使用这两层缓存，在使用三级缓存中的工厂对象生成的动态代理对象都是新创建的，循环依赖的时候，注入到别的bean里面去的那个动态代理对象和最终这个bean在初始化后自己创建的bean地址值不一样。如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。所以，Spring 选择了三级缓存。但是因为循环依赖的出现，导致了 Spring 不得不提前去创建代理，因为如果不提前创建代理对象，那么注入的就是原始对象，这样就会产生错误。Prototype（原型）对象和单例对象的区别： 单例对象在Spring加载的时候就创建，创建完毕后放入一级缓存中 而原型对象在每次在需要的时候都会创建，并且也不会存入缓存中 单例有状态（有状态指有成员变量并会进行修改操作）Bean对象的劣势：线程不安全。解决方案：考虑ThreadLocal（使用完后记得调用 ThreadLocal 的 remove 方法）或者锁机制。为什么Springboot默认创建单例Bean： 不需要多次创建实例 减少垃圾回收 缓存中可以快速获得拦截器与过滤器不同点 过滤器基于函数回调，拦截器基于 Java 的反射机制 过滤器依赖于 servlet 容器，拦截器是 spring 组件，并不依赖于 servlet，因此先执行过滤器，再执行拦截器 过滤器几乎可以对所有进行容器的请求起作用，拦截器只会对 controller 中的请求起作用使用场景 过滤器：登陆校验、权限检查、性能监控 拦截器：接口限流容器注册组件的四种方式： @Configuration + @Bean，注意，使用这种注册方法 Spring 会通过 CGLIB 来增强这个类，会判断是否实例已经存在，多次调用只会生成一个实例，意味着在@Configuration中的@Bean生成的是单例；相比之下，在@Component类中使用@Bean注解时，并不会有这种增强的行为。也就是说，当你在@Component类中调用一个@Bean方法时，实际上就是直接调用这个方法，并且每次调用都会创建一个新的 Bean，也就是说是生成多实例。 @ComponentScan + @Component @Import 新建一个实现FactoryBean接口的类@Configuration 和 @Component 的详细区别@Configuration 中所有带 @Bean 注解的方法都会被动态代理（cglib），因此调用该方法返回的都是同一个实例。而 @Conponent 修饰的类不会被代理，每实例化一次就会创建一个新的对象。面向切面编程（AOP）也是一种设计思想，本质是为了解耦。其实现方式是动态织入，在运行时动态将要增强的代码织入到目标类中，借助动态代理技术完成的。并且接口与非接口的动态代理机制并不相同，如下所示： 接口使用JDK代理，通过反射类Proxy以及拦截器的InvocationHandler回调接口实现的，使用反射，效率会低，不提供子类代理。 非接口使用CGlib代理，没有接口，只有实现类，采用底层字节码增强技术ASM在运行时使用Enhancer类创建目标的子类，提供子类代理。执行顺序： doAround(ProceedingJoinPoint pjp)的 pjp.proceed()前的内容 doBefore() doAfterReturning(String result) / doAfterThrowing(Exception e) doAfter() doAround(ProceedingJoinPoint pjp)的 pjp.proceed()后的内容（当且仅当非异常情况下才会执行）注解： @Component修饰的类为组件类并为这个对象创建Bean，@Bean修饰的方法会生成一个对象Bean。 @SpringBootApplication 包含三个注解： @SpringBootConfiguration, 继承@Configuration，标注当前类是配置类，并会将当前类内声明的一个或多个以@Bean注解标记的方法的实例注册到spring容器中，并且实例名就是方法名。 @EnableAutoConfiguration，主要由 @AutoConfigurationPackage，@Import(EnableAutoConfigurationImportSelector.class)这两个注解组成的。 @AutoConfigurationPackage 内部是 @({Registrar.class})，用于将启动类所在的包里面的所有组件注册到spring容器。扫描 @Entity, @Mapper 等第三方依赖注解。 @Import(EnableAutoConfigurationImportSelector.class) 是将特定路径（META-INF/spring.factories）中所有符合自动配置条件（@ConditionalOnClass）的类加载到Ioc容器，例如mybatis-spring-boot-starter。AutoConfigurationImportSelector.java 中可以看到所有自动配置类的名称。自动配置类原理 @ComponentScan，自动扫描并加载被@Component或@Repository修饰的组件，最终将这些组件加载到容器中，默认路径是该注解所在类的package。 事务事务的几个参数：rollbackFor，propagation，isolation传播机制共有七种传播机制，大致上分为三类： 支持当前事务 REQUIRED：如果存在当前事务，加入该事务，否则创建新事务执行 SUPPORTS：如果存在当前事务，加入该事务，否则以非事务的方式执行 MANDATORY：如果存在当前事务，加入该事务，否则抛出异常 不支持当前事务 REQUIRES_NEW：如果存在当前事务，暂时挂起该事务，并且创建新事物执行。内层事务与外层事务就像两个独立的事务一样，一旦内层事务进行了提交后，外层事务不能对其进行回滚，两个事务互不影响。 NOT_SUPPORTED：如果存在当前事务，暂时挂起该事务，否则以非事务的方式执行 NEVER：如果存在当前事务，抛出异常，否则以非事务的方式运行 嵌套事务（NESTED）：如果存在当前事务，则创建新事物作为当前事务的嵌套事务执行，否则等价于REQUIRED。外层事务的回滚可以引起内层事务的回滚。而内层事务的异常并不会导致外层事务的回滚。事务失效 数据库引擎不支持（MyIsam） 没有注册成Bean被Spring管理（没有使用@Service等注解） 方法不是public或者被final修饰（无法生成代理类） 方法内部调用(解决方法是引入自身Bean) 异常被捕捉或抛出其他类型的异常（回滚的默认异常为RuntimeException） 未开启事务方法调用的事务回滚情况前提：a方法调用b方法 a b 报错情况 同类调用的现象 不同类调用的现象 transactional注解 无注解 a方法报错，b方法不报错 均回滚 均回滚 transactional注解 无注解 a方法不报错，b方法报错 均回滚 均回滚 无注解 transactional注解 a方法报错，b方法不报错 均不回滚 均不回滚 无注解 transactional注解 a方法不报错，b方法报错 均不回滚 a不回滚，b回滚 结论： transactional注解修饰的方法会创建一个代理增强类，其他方法调用该注解修饰的方法也只是调用原类中的方法。 transactional修饰的方法内报错就一定会回滚。Spring 用到了哪些设计模式 工厂模式：通过 BeanFactory 和 ApplicationContext 容器创建 Bean 对象 代理模式：AOP 的实现 单例模式：Bean 默认是单例 模板方法：jdbcTemplate 等用到了模板方法 观察者模式：Springboot 事件驱动，监听器等" }, { "title": "ElasticSearch", "url": "/posts/elasticsearch/", "categories": "", "tags": "", "date": "2023-08-10 15:08:32 +0800", "snippet": "Elasticsearch是基于 Lucene 架构实现的分布式、海量数据的存储分析引擎，其中 Lucene 最主要的倒排索引结构，赋予了ES全文检索、模糊匹配、联合索引查询等等快速检索文档数据的能力，使得ES在这些查询的应用场景下优于数据库。适合用于搜索，不适合复杂的关系查询倒排索引：简单理解为建立关键词和文档之间的映射关系，从关键词中找出所属的文档。普通搜索则是从文档中找关键词。写数据的...", "content": "Elasticsearch是基于 Lucene 架构实现的分布式、海量数据的存储分析引擎，其中 Lucene 最主要的倒排索引结构，赋予了ES全文检索、模糊匹配、联合索引查询等等快速检索文档数据的能力，使得ES在这些查询的应用场景下优于数据库。适合用于搜索，不适合复杂的关系查询倒排索引：简单理解为建立关键词和文档之间的映射关系，从关键词中找出所属的文档。普通搜索则是从文档中找关键词。写数据的过程 客户端选择一个 node 发送请求，这个 node 就成为了 coordinate node （协调节点） 该协调节点将输入的 document 做哈希路由得到 shard id，将请求转发给 shard id 对应的 node 该 node 在 primary shard 上处理请求，并将数据同步到 replica 上 协调节点在写入完成后返回响应结果读数据的过程 客户端选择一个 node 发送请求，这个 node 就成为了 coordinate node （协调节点） 该协调节点对输入的 document id 做哈希得到 shard id，将请求转发给 shard id 对应的 node 该 node 使用 round-robin 轮询算法在 primary 和所有 replica 中选择一个，让读请求负载均衡 协调节点返回查询结果更新、删除数据的过程本质上都是写操作！磁盘上的每个段都有一个相应的 .del 文件。 删除操作（不是删除索引）是逻辑删除，document 被标记为 deleted 状态。当段合并时，在 .del 文件中被标记为删除的文档将不会被写入新段。 更新操作是把原 document 标记为删除，再写入新的 document 数据为什么近实时数据写入原理大概分为三个步骤：write -&gt; refresh -&gt; flush1、write：文档数据到内存缓存，并存到 translog2、refresh：内存缓存中的文档数据，到文件缓存中的 segment 。此时可以被搜到。3、flush： 缓存中的 segment 文档数据写入到磁盘当数据添加到索引后并不能马上被查询到，等到索引刷新后才会被查询到。refresh_interval 参数设置为正数之后，需要等一段时间后才可以在es索引中搜索到，因为已经从内存缓存刷新到文件缓存中了。详见数据写入与查询存在时间差问题 indexing Buffer 属于 ES 内存的一部分，OS 系统文件缓存属于操作系统的，不属于 ES 内存 refresh 操作：定时将 ES 缓冲区转换成 segment 并写入系统文件的过程。（近实时搜索的根本原因） translog 日志文件，不管是 ES 缓冲区还是系统缓冲区的内容，只要没写入到磁盘，就会在日志文件里记录，当 flush 到磁盘后，内存和磁盘中的文件就会清空。日志文件也是先写入 os cache，默认每隔 5 秒刷一次到磁盘，所以可能存在5秒的数据丢失 flush 操作：将 segment 持久化到磁盘，同时清理 translog。主要分为以下几步： 内存中的数据写入新的segment并放入缓存（清空内存区） 将commit point 写入磁盘，表示哪些 segment 已经写入磁盘 将 segment 写入磁盘，使用 fsync 命令 清空 translog 日志内容 为什么这么快 分布式储存：采用分布式储存技术，将数据存储于多节点，分散负载，优化整体执行效能。 索引分片：将每索引分裂为多片段，实现并行查询，提升搜索速度。 倒排索引：支持倒排索引数据结构，映射文档中每个词汇至文档出现位置，当搜索请求发生时，能快速检索包含所有搜索词的文档，迅速返回结果。 索引压缩：使用不同的压缩算法对倒排索引进行压缩，以减少存储空间占用和提高读写效率。 预存储结果：插入数据时，预处理数据，将结果预存储于索引中，查询时无需重新计算，提升查询速度。 内存存储：应用内存映射（Memory Mapped）技术来提高磁盘I/O性能。它将倒排索引缓存在内存中，同时使用内存映射技术将文件映射到虚拟地址空间中。减少磁盘访问次数，提高数据存储与查询效率。Term Index: 倒排的树状结构，存在内存里，是Term dictionary的索引。基本概念： Cluster，集群。一个集群包含多个节点，对外提供服务。 Node，节点。一个节点运行在一个独立的环境或虚拟机上，一个节点可以包含多个分片，一个索引由多个分片组成 Shard，分片。（Primary Shard 和 Replica Shard），主分片数量在创建索引的时候就需要固定，并且无法做修改。 Index，索引，相当于mysql中的库。 Type，类型，一个索引可以对应一个或者多个类型。（ES6.0后被废弃，ES7完全删除） Mapping，映射，相当于表结构。 Document，文档，相当于行。 Field，字段，相当于列。分片与副本的区别在于： 当分片设置为5，数据量为30G时，ES会将数据平均分配到5个分片上，每个分片6G数据。进行数据查询时，ES会把查询发送给每个分片，最后将结果组合在一起。目的是保障查询的高效性。 副本是对分片的数据进行复制，目的是保障数据的高可靠性，防止丢失。Filter VS Query尽可能使用过滤器上下文（Filter）替代查询上下文（Query） Query：此文档与此查询子句的匹配程度如何？ Filter：此文档和查询子句匹配吗？Elasticsearch 针对 Filter 查询只需要回答「是」或者「否」，不需要像 Query 查询一样计算相关性分数，同时Filter结果可以缓存。Reindex 重建索引的原理：Scroll Query + BulkIngest pipeline 可以在数据存入ES之前对数据进行转换，例如转小写，增加字段等。性能优化：背景：每五分钟就有6.5M条数据，直接reindex需要1000s（15分钟） 创建索引前设置主分片数量为二，副本比例为一，700s batch size = 2000（原来为默认值1000，使用堆缓存索引数据，默认最大值为100 MB）, 副本比例为零，480s，平均每个 document 30-40 kb 左右 slice = 2（其实是三个并行任务，一个父任务二个子任务），420s（甚至有一次350s）text 和 keyword 的区别 text类型： text类型是指可分词的文本，适用于长文本或短语查询。当文本被索引时，会被分成一些个别单词或词组，并且会去除停用词（如“a”、“the”、“and”等）和标点符号。这些单词或词组将被标准化并存储在倒排索引中，使得搜索时可以更快地匹配文档。适合全文搜索。 keyword类型： keyword类型是指未经过分词处理的文本，适用于精确匹配和排序。当文本被索引时，会被作为一个整体进行索引。它们通常用于搜索和排序非文本字段，例如数字或日期。适合过滤、排序、聚合。 ElasticSearch 默认为text类型，但是text类型总会有keyword的类型的字段，等价于 .keywordES 调优硬件配置优化 CPU 配置 内存配置 禁止 swap 配置 GC 磁盘索引优化 批量提交（Bulk），但不能一次性提交过多内容。 增加 refresh 时间间隔 减少副本数量查询优化 尽可能使用过滤器上下文（Filter）替代查询上下文（Query） 拆分索引 减少模糊匹配数据结构优化 减少不需要的字段 text 和 keyword 类型字段的设置集群架构设计 设置分片数量，但不宜过大。扩容 垂直扩容（纵向扩容）：替换旧的设备 水平扩容（横向扩容）：直接新增设备到集群中，会触发relocation 写入和更新的并发针对写入和更新时可能出现的并发问题，ES是通过文档版本号来解决的。当用户对文档进行操作时，并不需要对文档加锁和解锁操作，只需要带着版本号。当版本号冲突的时候，ES会提示冲突并抛出异常，并进行重试存储结构 一个集群包含1个或多个节点； 一个节点包含1个或多个索引； 一个索引，类似 Mysql 中的数据库； 每个索引又由一个或多个分片组成； 每个分片都是一个 Lucene 索引实例，您可以将其视作一个独立的搜索引擎，它能够对 Elasticsearch 集群中的数据子集进行索引并处理相关查询； 每个分片包含多个segment（段），每一个segment都是一个倒排索引。查询时，会把所有的segment查询结果汇总归并为最终的分片查询结果返回。段段是不可变的为了实现高索引速度，故使用了segment 分段架构存储。一批写入数据保存在一个段中，其中每个段是磁盘中的单个文件。由于两次写入之间的文件操作非常繁重，因此将一个段设为不可变的，以便所有后续写入都转到New段。段合并可以是内存里的段，也可以是在磁盘里的段进行段合并流程 合并候选阶段：es会选择一些相似大小的段作为合并候选，减少合并过程中的IO开销。 合并阶段：ES将合并时候选中的多个段合并成为一个新的段，同时删除旧的段（在 .del 文件里标记为删除）。在合并过程中ES会进行数据的排序和去重，并重新生成倒排索引为什么要段合并由于自动刷新流程每秒会创建一个新的段（由动态配置参数：refresh_interval 决定），这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦，导致： 消耗资源：每一个段都会消耗文件句柄、内存和cpu运行周期； 搜索变慢：每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。触发条件后台进程定期检查，可能进行 merge 操作 手动触发 段 flush 触发 由前一个成功的 merge 触发分词器 ik-analyzer 分词器，支持中文分词 pinyin 分词器，支持输入拼音查到相关关键词 pattern 分词器，支持正则表达式 whitespace 分词器，用于去除空格" }, { "title": "Redis 知识体系", "url": "/posts/redis/", "categories": "Backend, Redis", "tags": "redis", "date": "2023-07-06 19:24:40 +0800", "snippet": "单机 QPS单机 QPS 能力参考范围为 8 - 10 万。为什么 Redis 这么快 用 C 语言编写的，执行效率高 基于内存的数据库，避免磁盘IO操作 采用高效的数据结构 合理的数据编码，同样的数据结构在不同数据量的情况下采用不同的编码方式 采用单线程，避免上下文切换 多路IO复用，一个线程处理多个大量Socket请求。 虚拟内存虚拟内存Redis 的数据并不是完全在内存中...", "content": "单机 QPS单机 QPS 能力参考范围为 8 - 10 万。为什么 Redis 这么快 用 C 语言编写的，执行效率高 基于内存的数据库，避免磁盘IO操作 采用高效的数据结构 合理的数据编码，同样的数据结构在不同数据量的情况下采用不同的编码方式 采用单线程，避免上下文切换 多路IO复用，一个线程处理多个大量Socket请求。 虚拟内存虚拟内存Redis 的数据并不是完全在内存中，当 Redis 的数据量大于物理内存容量时，会通过虚拟内存的手段，将不经常使用的数据（冷数据）存储到硬盘上，以释放物理内存空间。在虚拟内存中，数据被分为多个页面，每个页面大小默认 32 字节。显然，虚拟内存可以节省内存，但也带来一定的性能损失。持久化AOF采用写后日志的方式，先执行命令，再将操作日志以文本形式追加到文件中。为什么采用写后日志？（Mysql是采用写前日志） 避免出现记录错误命令的情况，并且 AOF 写日志也是在主线程中进行的。优缺点 优点 故障不丢失，写回策略默认是每秒一次，保证故障最多丢失一秒的数据 缺点 文件体积较大 恢复速度更慢 写回（硬盘）策略 Always（总是），每次写操作命令执行完成后，同步将 AOF 日志数据写回硬盘。本质是每次写操作都执行 fsync() 函数。 EverySec（每秒），每次写操作命令执行完成后，将命令写入到 AOF 的内核缓冲区，每秒将缓冲区的内容写回到硬盘。本质是每秒创建一个异步任务执行 fsync() 函数。 No，意味着交给操作系统控制写回的时机。本质是不执行 fsync() 函数。重写（BGREWRITE）当 AOF文件太大时，Redis fork出一个子进程调用 bgrewriteaof 方法重写一个新的文件，比如increase(1)和increase(1)，会被合并成set(2)。也用到了 写时复制。RDB将某一时刻的内存数据以二进制的形式写入磁盘。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。save 和 bgsave 两条命令触发 RDB 持久化操作。save 命令在主线程中执行，会导致阻塞。而 bgsave 创建一个子线程，避免阻塞，是默认的 RDB 的默认配置。并且 bgsave 允许执行快照命令期间修改数据，因为子线程会创建一个修改后的副本再写入（写时复制）。优缺点 优点 体积更小，二进制文件 恢复更快，适合备份 性能更高，只需要fork子进程 缺点 故障丢失，每隔一段时间（最少五分钟）持久化一次，如果发生故障，意味着这段时间内的所有数据都丢失 耐久性差，数据量大的时候，fork会很耗时 Copy On Write(写时复制) 原理：fork() 后的子进程与父进程共享内存空间，如果是读取数据，相安无事；如果是写数据，会检测到内存页是只读然后触发中断最后复制一份数据再做修改。 好处：减少不必要的资源分配；减少分配和复制大量资源时带来的瞬间延时。 缺点：如果父子进程都在进行大量的写操作，会产生大量的分页错误。 混合持久化结合 AOF 和 RDB 两种持久化方式。混合持久化只发生于 AOF 重写过程。 重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。缺点：不再是 AOF 格式的文件，可读性差。数据结构Redis 7之后使用 Listpack(紧凑列表) 数据结构代替 Ziplist。 String: Simple Dynamic String（SDS） List: Quicklist（3.2之后）；LinkedList、Ziplist（3.2之前） Hash: HashTable（哈希表）、ZipList。当同时满足以下两个条件的时候，Hash 对象使用 ZipList 编码否则使用 Hashtable：a、每个Field-Value的最大长度小于等于64字节；b、Field-Value最大数量小于512个。 Set: HashTable、Intset。当同时满足以下两个条件的时候，Set 对象使用 Intset 编码否则使用 Hashtable：a、结合对象保存的所有元素都是整数值；b、集合对象保存的元素数量不超过512个。 Sorted set: ZipList（压缩列表）、SkipList（跳表）。当同时满足以下两个条件的时候，Sorted set 对象使用 ZipList 编码否则使用 SkipList：a、每个元素空间小于64字节；b、集合中元素数量小于128个。 Stream: 借鉴 Kafka 的设计，是一个支持多播且可持久化的消息队列。与 PUB/SUB 模式相比，无法持久化。与基于 List LPUSH 和 BRPOP 或 Sorted set 相比，不支持多播分组消费。 Bitmap: 位图 Hyperloglog: 基数（不重复的元素）统计，但是会存在一定误差。可用于比如注册 IP 数、每日访问 IP 数、页面实时UV、在线用户数，共同好友数等允许一定容错的业务场景。 Geospatial index: 实现两个位置距离的计算、获取指定位置附近的元素等功能。消息通信模式：pub/sub，不支持消息持久化 基于频道（channel） 基于模式（pattern）注意事项： 客户端需要及时消费，否则会自动断开连接或丢数据 连接断开后需要重新连接，否则无法收到消息 该消息模式不是一种可靠的消息系统。当出现客户端连接退出，或者极端情况下服务端发生主备切换时，未消费的消息会被丢弃。Hash 数据结构下的 rehash 过程： 为 ht[1] 分配空间，作为 rehash 后的哈希表。 构造一个索引技术器变量 rehashidx 并初始化为零，表示 rehash 正在执行，否则 rehashidx 为 -1 表示没在进行。 在 rehash 期间，删改查操作都是先在旧表上操作，并把旧表的数据迁移到新表；新增的操作直接在新表上新增，并且 rehashidx 自增。 除此之外，没有增删改查的操作时，还会有一个定时任务周期性（每100ms触发一次）的迁移数据好处：将一次性的大批量拷贝分摊到多个请求中。缓冲区共有三个缓冲区： 客户端输入/输出缓冲区为了解决客户端和服务器端的请求发送和处理速度不匹配所设置的。输入缓冲区会先暂存客户端发送过来的命令，Redis 主线程从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再从输出缓冲区返回给客户端。缓冲区溢出的可能情况：BigKey，缓冲区大小不合理。 复制缓冲区，复制积压缓冲区用于Redis主从节点之间复制时使用的。由于主从节点间的数据复制包括全量复制和增量复制两种。因此也分为复制缓冲区和复制积压缓冲区两种。 复制缓冲区是 Redis 在全量复制过程中，主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等 RDB 文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。 复制积压缓冲区是一个大小有限的环形缓冲区。当服务器断线重连后，复制积压缓冲区的内容会被发送到从节点，当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据，会造成主从节点的数据不一致。在命令传播阶段出现断网的情况，或者网络抖动时会导致连接断开，此时主节点会向复制积压缓冲区写数据。 AOF 缓冲区，AOF 重写缓冲区 AOF 缓冲区：Redis在AOF持久化的时候，会先把命令写入到AOF缓冲区，然后通过回写策略（always、everysec、no）来写入硬盘AOF文件。 AOF 重写缓冲区：当需要进行AOF重写时，主进程会fork一个子进程进行AOF重写，此时主进程还要继续接收客户端传来的指令，此时这些指令就会存放在AOF重写缓冲区中；当AOF重写完成后，将AOF重写缓冲区中的指令追加到aof文件中，并将原来的aof文件替换，来保证数据的一致性。（与主从复制中的复制缓冲区类似） 单线程与多线程为什么使用单线程？ Redis 的瓶颈是内存和带宽，而不是 CPU。为什么又引入了多线程？ redis 4.0 开始使用多线程惰性删除。 redis 6.0 中多线程的实现主要集中在网络 I/O 处理上。采用了混合多线程模型，即在网络 I/O 处理阶段使用多线程。只能执行同时读或同时写在命令执行阶段仍然采用单线程。这种设计既保留了单线程模型的简单性和一致性优势，又充分利用了多线程的并行处理能力。什么是多路IO复用：一个服务端进程可以同时处理多个客户端连接。用于AOF持久化任务和处理客户端请求。其实现函数有： select：数据结构是bitmap，采用轮询，限制连接数为1024个（最大文件描述符数量） poll：数据结构是数组，解决了select的个数限制，但依旧是轮询 epoll：数据结构是红黑树，使用回调的方式，解决了个数限制，也解决了轮询方式 边缘触发（Edge Trigger，ET），更适合高流量或发送大文件的场景，例如 nginx 水平触发（Level Trigger，LT），默认，能保证事件一定被处理。 高可用（主从，哨兵，集群）主从模式主节点可以读、写，从节点只能读 slave启动后，向master发送SYNC命令，master接收到SYNC命令后通过bgsave保存快照，并使用复制缓冲区记录保存快照这段时间内执行的写命令 master将保存的快照文件发送给slave，并继续在复制缓冲区记录执行的写命令 slave接收到快照文件后，加载快照文件，载入数据 master快照发送完后开始向slave发送缓冲区的写命令，slave接收命令并执行，完成复制初始化 此后master每次执行一个写命令都会同步发送给slave，同时也会写入复制积压缓冲区，保持master与slave之间数据的一致性，如果主从之间断开连接，那么重连后会根据该缓冲区中的偏移量将断开连接这段时间的数据修改写入从节点。主从异步复制，因此有可能存在数据不一致的情况。请求转发主从模式下，服务端并不做转发处理。而要实现读写分离的功能，需要客户端自行处理了。比如要自行定位master节点，然后将写请求发送过去，读请求则可以做负载均衡处理。哨兵模式哨兵模式基于主从复制模式，只是引入了哨兵来监控与自动处理故障。哨兵每2秒向pubsub频道接收和发送hello信息，实现哨兵之间的通信。哨兵每1秒向所有主从节点和其他哨兵发送PING命令来判断其是否正常运行。哨兵每10秒向主从节点发送INFO命令来获取节点信息（被标记为客观下线后每1秒一次）。如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「主观下线」。其他哨兵会尝试与节点建立连接，如果大于配置文件中设定的值，则认定节点「客观下线」。集群模式Redis 集群无法保证强一致性，选择了高可用和分区容忍，即AP。将不同的数据分布在不同的节点中，分布的规则采用哈希槽算法。共有 16384 (2^14)个哈希槽。不使用一致性哈希算法的原因 一致性哈希环是顺时针映射，优先考虑的是最少的节点数据发生数据迁移 哈希槽是静态映射的，优先考虑的问题是数据均匀分布，根据不同机器的性能，可以手动分配不同的哈希槽数量到不同机器上请求转发在集群模式下，对于读/写请求，并非是服务端转发请求，而是服务端返回转移指令，通知客户端数据所在节点，并让客户端重新发起请求事务Redis 有事务但没有回滚，因为Redis认为事务的失败都是使用者造成的。缓存雪崩、击穿、穿透 缓存雪崩：大量缓存失效或 Redis 宕机时，大量请求访问到数据库，导致数据库压力骤增。 解决方法： 大量失效：均匀设置过期时间或缓存预热 宕机：设置 Redis 高可用集群，熔断或限流 缓存击穿：热点数据过期，大量请求访问到数据库 解决方法：热点数据不设置过期时间 缓存穿透：访问的数据既不在缓存中也不在数据库中，被黑客攻击。 解决方法：使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。 缓存策略 Cache-Aside Pattern 旁路缓存模式；读，先从缓存读，未命中从数据库读；写，先写数据库，再写缓存 Read/Write-Through Pattern 读/写穿透模式；在旁路缓存模式的基础上封装一层缓存服务，读写操作都调用该缓存服务。读。先从缓存读，未命中数据库读并写到缓存中再返回。 Write-Behind Pattern 异步回写模式；与读/写穿透模式类似，缓存系统只同步写缓存，异步批量写数据库旁路缓存下的一致性问题不存在实时一致性，只能保证最终一致性。首选 写策略：先更新数据库，再删除缓存。 读策略：先读缓存中数据，如果缓存中没有，则读数据库的数据并且写入缓存中。如果对缓存命中率有要求，可以采用先更新数据库再更新缓存 + 分布式锁的方案。分布式锁保证同一时间只运行一个请求更新缓存。最终一致性方案：主要考虑以下两点： 第一个操作成功，但第二个失败会有什么问题 高并发场景下数据会不会不一致 如果采用先删除缓存，再更新数据库如何避免出现脏数据？延迟双删：先删除缓存，更新数据库，睡眠，再次删除缓存。睡眠的时间一般是一次查询的耗时 + 几百毫秒。第二次的删除可以清除掉因并发导致的缓存脏数据。#删除缓存redis.delKey(X)#更新数据库db.update(X)#睡眠Thread.sleep(N)#再删除缓存redis.delKey(X)缓存删除重试：为了保证缓存删除成功，需要在缓存失败时增加重试机制。可以借助消息队列，将删除失败的数据进行异步重试。BinLog缓存删除方案：BinLog存储了对数据库的更改操作日志记录，通过订阅该日志（如：canal），获取需要更新缓存的key和数据。过期删除策略和内存淘汰策略过期删除策略 定时删除策略：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。 优点：内存可以最快的被释放。 缺点：删除过期key会占用 CPU 时间，对 CPU 不友好。 惰性删除策略：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。 优点：只有在访问的时候检查是否过期，对 CPU 友好。 缺点：过期的 key 没被删除，对内存不友好。 定期删除策略：每隔一段时间随机从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。 优点：减少删除操作对 CPU 的影响，也能删除一部分过期的数据。 缺点：难以确定定期删除的频率。Redis的删除策略是惰性删除+定期删除。定期删除如果检查到过期key的数据超过一定百分比，循环再次检查并删除。内存淘汰策略 不进行数据淘汰（默认的内存淘汰策略），写入时禁止写入并报错。 进行数据淘汰 在设置了过期时间的数据中进行淘汰 volatile-random： 随机淘汰设置了过期时间的任意键值； volatile-ttl：优先淘汰离过期时间最近的键值； volatile-lru：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu：淘汰所有设置了过期时间的键值中，最少使用的键值； 在所有数据范围内进行淘汰 allkeys-random：随机淘汰任意键值； allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu：淘汰整个键值中最少使用的键值。 近似 LRU 算法出于节省内存的考虑（不需要为所有数据维护一条大链表），Redis 的 LRU 算法并非完整的实现，是一个基于哈希表的近似 LRU 算法，通过对少量键进行取样，然后回收其中的最久未被访问的键。通过调整每次回收时的采样数量 maxmemory-samples，可以实现调整算法的精度。RedLock 红锁红锁是一种分布式锁。在 Redis 单独节点的基础上，RedLock 使用了多个独立的 Redis 的 Master 实例（通常建议是奇数个，比如 5 个），共同协作来提供更强健的分布式锁服务。特点 互斥性：任意时刻，只有一个客户端能持有锁 防止死锁：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。 可重入性：一个线程如果获取了锁之后,可以再次对其请求加锁。实现思路RedLock 是对集群的每个节点进行加锁，如果大多数节点（N/2+1）加锁成功，则才会认为加锁成功。这样即使集群中有某个节点挂掉了，因为大部分集群节点都加锁成功了，所以分布式锁还是可以继续使用的。分布式锁命令：set nx expire，key 为资源唯一标识符，例如商品 id。value 为线程唯一标识符，例如 requestid。在释放锁时，判断是否与当前线程标识符匹配，再进行释放。死锁为了防止死锁的出现，需要引入超时机制，设置过期时间分布式锁获取失败了延迟一段时间后重试分布式锁超时了但任务还没执行完答：设置看门狗（定时器）大 Key/ 热 Key大 Key指 Redis 的 Key 对应的 Value 过大，并不是指 Key 过大。危害 性能问题：读取大 Key 消耗更多的网络带宽和处理时间 引发网络阻塞：如果一个 Key 的大小是 1MB，每秒访问量是 1000，那么每秒会产生 1000 MB 的流量 内存分配不均 持久化问题：持久化变得更耗时解决方案 拆分大 Key，将数据分散到多个小 Key 中 定期清理或设置过期时间 数据压缩 选取合适的数据结构如何找到大 Key 使用 redis-cli --bigkeys 命令，不建议 使用 scan 命令 使用 RdbTools 工具如何删除大 Key 系统低峰期使用 del 命令（会造成线程阻塞） 使用 scan 命令（会造成线程阻塞） 使用 unlink 异步删除热 Key指短时间内被频繁访问的数据危害 可能会缓存击穿，使存储层访问量激增 负载不均衡，热 Key 可能导致某些 Redis 节点负载过高 性能瓶颈，占用大量 CPU 资源，影响其他请求解决方案 读写分离（最重要） 对热点数据分片，分散到不同的 Redis 实例，提升吞吐量如何找到热 Key 使用 monitor 命令 使用 redis-cli --hotkeys 命令，不建议为什么100万QPS的热key请求可能会影响1000万QPS的Redis实例 100万个请求在单线程的模型下会串行处理，阻塞其他请求 热 key 的能承载的QPS是由单个 key 的处理速度决定的 1000万QPS可能是集群模式下能承载的请求量" }, { "title": "Windows修改注册表脚本", "url": "/posts/reg-scripts-in-windows/", "categories": "Tutorial, Windows 10", "tags": "skills, windows 10", "date": "2022-09-28 21:09:55 +0800", "snippet": " 鼠标右键新建菜单栏中增加 New Markdown File：Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\.md]@=\"Typora.md\"\"Content Type\"=\"text/markdown\"\"PerceivedType\"=\"text\"[HKEY_CLASSES_ROOT\\.md\\ShellNew]\"NullFil...", "content": " 鼠标右键新建菜单栏中增加 New Markdown File：Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\.md]@=\"Typora.md\"\"Content Type\"=\"text/markdown\"\"PerceivedType\"=\"text\"[HKEY_CLASSES_ROOT\\.md\\ShellNew]\"NullFile\"=\"\" 鼠标右键菜单栏新增 Open with Code，需要根据实际情况修改路径：Windows Registry Editor Version 5.00; Open files[HKEY_CLASSES_ROOT\\*\\shell\\Open with VS Code]@=\"Open with Code\"\"Icon\"=\"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe,0\"[HKEY_CLASSES_ROOT\\*\\shell\\Open with VS Code\\command]@=\"\\\"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe\\\" \\\"%1\\\"\"; This will make it appear when you right click ON a folder; The \"Icon\" line can be removed if you don't want the icon to appear[HKEY_CLASSES_ROOT\\Directory\\shell\\vscode]@=\"Open with Code\"\"Icon\"=\"\\\"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe\\\",0\"[HKEY_CLASSES_ROOT\\Directory\\shell\\vscode\\command]@=\"\\\"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe\\\" \\\"%1\\\"\"; This will make it appear when you right click INSIDE a folder; The \"Icon\" line can be removed if you don't want the icon to appear[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\vscode]@=\"Open with Code\"\"Icon\"=\"\\\"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe\\\",0\"[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\vscode\\command]@=\"\\\"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe\\\" \\\"%V\\\"\"" }, { "title": "线段树（Java实现）", "url": "/posts/segment-tree/", "categories": "Algorithm", "tags": "segment tree", "date": "2022-07-05 14:13:29 +0800", "snippet": "线段树class NumArray { int[] segmentTree; int n; public NumArray(int[] nums) { n = nums.length; segmentTree = new int [2 * n]; System.arraycopy(nums, 0, segmentTree, n, n...", "content": "线段树class NumArray { int[] segmentTree; int n; public NumArray(int[] nums) { n = nums.length; segmentTree = new int [2 * n]; System.arraycopy(nums, 0, segmentTree, n, n); for(int i = n - 1; i &gt; 0; i--){ segmentTree[i] = segmentTree[2 * i] + segmentTree[2 * i + 1]; } } public void update(int index, int val) { index += n; segmentTree[index] = val; index /= 2; while(index != 0){ segmentTree[index] = segmentTree[2 * index] + segmentTree[2 * index + 1]; index /= 2; } } public int sumRange(int left, int right) { left += n; right += n; int sum = 0; while(left &lt;= right){ if(left % 2 == 1){ sum += segmentTree[left]; left ++; } if(right % 2 == 0){ sum += segmentTree[right]; right--; } left /= 2; right /= 2; } return sum; }}" }, { "title": "MySQL知识点汇总", "url": "/posts/mysql/", "categories": "Backend, MySQL", "tags": "", "date": "2022-06-22 13:33:24 +0800", "snippet": "单机QPS单机 QPS 为 4k 左右。MySQL select语句执行 prepare 阶段，检查查询语句中的表或字段是否存在，将 * 拓展为表上的所有列。 optimize 阶段，优化器决定使用哪个索引。 execute 阶段，执行器，索引下推。表空间文件结构组成：段（默认256MB） -&gt; 区（默认1MB） -&gt; 页（默认16KB） -&gt; 行页：InnoDB的数...", "content": "单机QPS单机 QPS 为 4k 左右。MySQL select语句执行 prepare 阶段，检查查询语句中的表或字段是否存在，将 * 拓展为表上的所有列。 optimize 阶段，优化器决定使用哪个索引。 execute 阶段，执行器，索引下推。表空间文件结构组成：段（默认256MB） -&gt; 区（默认1MB） -&gt; 页（默认16KB） -&gt; 行页：InnoDB的数据按页为单位读写，默认每个页大小为16KB，意味着一次最少从磁盘读取16KB的内容到内存（Buffer Poll）中，一次最少把内存中的16KB内容刷新到磁盘中。表中的记录存储在数据页中。B+树的每个节点都是一个数据页。区：数据量大的时候，索引分配空间则是按区为单位分配，每个区的大小为1MB，对于16KB的页来说，连续（物理连续）64个页会被划分到一个区，这样，B+树中节点所构成的链表中相邻页的物理位置也相邻，便能顺序IO。段：段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在。当创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段。在段中不要求区与区之间是相邻的。 索引段：存放B+树非叶子结点的区的集合 数据段：存放B+树叶子结点的区的集合 回滚段：存放的是回滚数据的区的集合，MVCC利用回滚段实现了多版本查询数据区存在的意义数据页都是以双向链表的形式存在，如果以页分配存储空间，双向链表相邻的两个页之间的物理位置可能距离非常远，会产生随机 IO，影响性能段存在的意义对于范围查询，本质是对B+树叶子节点中的记录进行顺序扫描，但如果不区分叶子节点和非叶子节点，把节点代表的页都申请到区中，范围查找效率大打折扣。一个索引会产生两个段，一个叶子节点段（数据段）和一个非叶子节点段（索引段）。行格式 Redundant Compact，一条完整的记录分为“记录的额外信息”和“记录的真实数据”，额外信息中又分为变长字段长度列表、NULL值列表和记录头数据。变长字段长度列表和NULL值列表都是倒序保存，并且不是必须的，只要没有变长字段或NULL值字段即可。8个字段值可以为NULL，那么NULL值列表空间为1字节，9字段则2字节。 Dynamic CompressedVarchar(n) n最大取多少？MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。注意，是一行数据的最大字节数 65535，其实是包含「变长字段长度列表」和 「NULL 值列表」所占用的字节数的。行格式溢出后，数据存放到溢出页。text 各个类型对比 TINYTEXT 最大长度是 255 (2^8 – 1) 个字符。 TEXT 最大长度是 65535 (2^16 – 1) 个字符。 MEDIUMTEXT 最大长度是 16777215 (2^24 – 1) 个字符。 LONGTEXT 最大长度是 4294967295 (2^32 – 1) 个字符 Varchar 对每个英文(ASCII)字符都占用2个字节，对一个汉字也只占用两个字节 Char 对英文(ASCII)字符占用1个字节，对一个汉字占用2个字节数据的检索效率是：char&gt;varchar&gt;textchar: 定长，会用空格补齐varchar：变长B树和B+树 B树（多路的平衡搜索树），节点可以存储多个数据，并且每个节点存放索引和数据，一个节点的关键字等于该节点子节点个数减一。查询的最好情况是O（1），一般高度为3。 B+树，非叶子节点关键字个数等于子节点个数 叶子节点保存数据（数据页），非叶子节点保存索引，查询固定为O（logn），并且由于这个特点更适合外部存储。 叶子节点有指向下一个叶子节点的指针，双向链表，可顺序访问，因此区间访问的性能较好。 存在重复元素，因为非叶子结点不保存数据。 与红黑树的比较，B+树的优势： 更少的查询次数，因为B+树的树高一般小 利用计算机的预读特性，因为B+树具有类似链表的特点，因此相邻的节点也能被预先载入为什么不使用 B 树：B+ 树的非叶子节点只存储索引，单个节点可以存储更多的索引，计算机一次性加载更多的索引数据到内存中。并且B树不适合范围查找。为什么不使用跳表：MySQL 一次数据页加载都需要一次磁盘IO。并且磁盘IO的次数和树高有关系，又因为跳表的高度一般比B+树高，所以查询速度会大大降低，因此不适合。为什么 Redis 使用了跳表：因为 Redis 不存在磁盘IO。重点在于磁盘IO次数。MySQL索引给表添加索引时，是会对表加锁，因此在生产环境中不能直接添加索引。InnoDB 存储引擎默认会创建一个主键索引，也就是聚簇索引，其它索引都属于二级索引。当没有显式定义主键索引时，MySQL 会选择第一个唯一索引，并自动设置非空约束，当作聚簇索引。数据结构维度： B+树索引，适合范围查询，复杂度为O（logn）。 哈希索引，能以O（1）时间进行查找，但失去有序性，无法用于排序和分组，只支持精确查找（等值查找）。 全文索引，使用倒排索引实现，记录关键词到所在文档的映射，一般在text, varchar上创建。 R-Trees索引，MyISAM支持的索引类型，和空间地理数据有关。物理存储维度（InnoDB）： 聚簇索引，叶节点存放一整行记录。一个表只能拥有一个聚簇索引。并非完全等价于主键索引。 非聚簇索引（二级索引），叶节点只存放主键信息，所以一般需要回表查询。逻辑维度 主键索引，不允许空值 普通索引，没任何限制 联合索引，多个字段创建的索引，使用时遵循左前缀原则。 唯一索引，索引列中的值必须是唯一的，但可以为空值。 空间索引索引失效（触发全盘扫描）主要看是否回表或者是查询的数据量过大一定失效： 索引列参与运算 索引列使用函数 两列做比较 类型隐式转换可能失效： 不满足最左匹配（覆盖索引，索引下推，索引跳跃扫描） 尽可能明确查询列，而不是select *，即使不满足最左匹配（可以用于性能优化） like关键字的左模糊和左右模糊(如果覆盖索引便不失效) 错误的or使用（切记两个条件都要添加索引，否则会导致索引失效，or两边同时使用 &lt; 和 &gt;，也会失效） 错误的 &lt;&gt; 和 != 使用（查询结果集占比较大时索引会失效） is not null(is null 走索引) not in(条件列是主键时走索引) not exists orderby（部分会失效） 范围过大的 between and索引跳跃扫描最左缀原则可以通过跳跃扫描的方式打破，当第一列索引的唯一值较少时，即使where条件没有第一列索引，查询的时候也可以用到联合索引。覆盖索引指查询列被所建的索引覆盖，覆盖索引是 select 的数据列只需要从索引中就能取到，不必回表。例如对于联合索引(col1,col2,col3)，查询语句SELECT col1,col2,col3 FROM test WHERE col2=2哪些情况下不适合建索引 数据量少 更新频繁 区分度低 where, groupby, orderby 后没有使用到的字段 联合索引中的索引索引下推指将部分上层（服务层）负责index filter的事情，交给了下层（引擎层）去处理。它能减少二级索引再查询时的回表查询次数，提高查询效率。只适用于二级索引。EXPLAIN 命令的extra一栏中有Using index condition，表明使用了索引下推举例：select * from table1 where b like '3%' and c = 35.6 之前： 先通过 联合索引 查询到 开头为 3 的数据 然后拿到主键 然后通过主键去主键索引里面去回表查询 二级索引里面查询出来几个 3 开头的就回表几次5.6 之后： 先通过 二级索引 查询到开头为 3 的数据 然后 再找到 c = 3 的数据进行过滤 之后拿到主键 通过主键进行回表查询，减少了回表次数建索引的原则 选择唯一性索引 为经常需要orderby，groupby操作的字段建立索引 经常作为查询条件的字段建立索引 限制索引数量 尽量使用数据量少的索引 尽量使用最左前缀匹配原则 使用区分度高的列作为索引 扩展索引而不是新建索引强制索引深度分页有分页需求时，一般会用limit实现，但是当偏移量特别大的时候，查询效率就变得低下。select * from table limit 10 和 select * from table limit 10000, 10 的查询时间是不一样的，后者是查询出 10010 条，再取最后 10 条记录。本质原因就是：每次查询时扫描整张表（不走索引），偏移量（offset）越大，mysql就会扫描越多的行，然后再抛弃掉。这样就导致查询性能的下降。解决方案： 标签记录法，记录上一页最后一条记录的ID或时间戳，作为下一页的查询条件，使用 select * from table where id &gt; 10000 limit 10， 范围查询，使用 select * from table where id between 100000 and 100010 order by id desc; 延迟关联（子查询优化），先通过索引获取主键ID，再关联原表获取完整数据，把条件转移到主键索引树，使用 select * from table where id &gt;= (select a.id from table a where a.update_time &gt;= xxx limit 100000, 1) limit 10 尽量满足索引覆盖单表数据量大了性能为什么下降因为表的数量达到一定量级后，MySQL 内存无法存储所有的索引，使得查询语句需要产生磁盘IO，导致性能下降。ACID 原则 Atomicity（原子性），每次事务是原子的，事务包含的所有操作要么全部成功，要么全部不执行。一旦有操作失败，则需要回退状态到执行事务之前；通过 undo log 来保证。 Consistency（一致性），数据库的状态在事务执行前后的状态是一致的和完整的，无中间状态。即只能处于成功事务提交后的状态；例如转账前后，两用户的余额总和一定是不变的。通过原子性 + 隔离性 + 持久性保证的。 Isolation（隔离性），各种事务可以并发执行，但彼此之间互相不影响。按照标准 SQL 规范，从弱到强可以分为读未提交、读已提交、可重复读和串行化四种隔离等级；通过 MVCC 或锁机制保证的。 Durability（持久性），状态的改变是持久的，不会失效。一旦某个事务提交，则它造成的状态变更就是永久性的，即便系统故障也不会丢失。通过 redo log 来保证。事务的隔离MVCC 用于解决脏读和不可重复读的问题，在读已提交和可重复读两种隔离级别生效。读已提交是每次 select 都会重新生成一次 Read View，而可重复读是一次事务只会创建一次且在第一次查询时创建 Read View。MVCC: Read view + undo log + 两个隐藏字段，基于乐观锁的理论为了解决读写冲突，可以在读已提交和可重复读的隔离级别下使用。 Read View 是一个事务快照，保存当前事务开启时所有活跃的事务列表。通过与版本链的配合可以实现对数据的 “快照读”。其中也有四个字段，分别是creater_trx_id, m_ids, min_trx_id, max_trx_id。 undo log 是存放更新前的数据（快照），保存了历史快照 隐藏字段：row_trx_id 和 roll_pointer，前者表示更新行数据的事务id，后者是上一次修改之前保存在 undo log 中的记录位置（指针），使每行记录变化前后形成了一条版本链MVCC(Multiversion Concurrency Control) + 间隙锁在RR的隔离级别下能解决大部分幻读情况 仅快照读的情况下（普通 select 语句），通过 MVCC 的方式，在执行第一个查询语句后，会创建一个 Read View，后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，多次查询获取的是同一个快照数据。 仅当前读的情况下（select … for update 等语句），通过 Next-Lock Key（临键锁），其他事务的插入操作会被阻塞。 查询条件不走索引，退化成表锁。 查询条件走普通索引，锁住查询条件附近的间隙，等于间隙锁 查询条件走唯一索引，只锁一条数据，等价于记录锁 解决不了的幻读情况：快照读和当前读发生在同一个事务中（更新、删除等操作本质也需要进行当前读） 事务A快照读，事务B新增数据并提交，接着事务A修改事务B新增的数据并快照读，此时发生幻读。 事务A快照读，事务B新增数据并提交，接着事务A当前读，此时发生幻读。 若要尽可能避免幻读现象的发生，尽量在开启时候后马上执行当前读。三种问题： 脏读，指读取未提交数据，事务的数据可能回滚，导致数据不一致。 不可重复读，指在同一事务内读到的数据是不一致的 幻读，指同一事务在查询的过程中，有另外一个事务对范围内新增了记录，导致范围查询的结果条数不一致的现象。SQL的四种隔离级别： 读未提交，指一个事务还没提交时，它做的变更就能被其他事务看到。可能出现脏读 读已提交，指一个事务提交之后，它做的变更才能被其他事务看到。可能出现不可重复读 可重复读，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。可能出现幻读，但使用MVCC + 间隙锁能解决大部分幻读现象，事务开始读操作的时候，不允许其他事务对读的数据做修改 串行化，对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；WAL 机制MySQL 保证数据不丢失： 两阶段提交 + WAL(Write-ahead logging)WAL 核心：指 MySQL 在执行写操作时先记录在日志中，后更新到磁盘中。将随机写（磁盘的写操作是随机IO，耗性能）转变成顺序写和组提交机制，降低客户端延迟，提高吞吐量。三大日志binlog, redolog, undolog: Buffer Pool是MySQL进程管理的一块内存空间，有减少磁盘IO次数的作用。 redo log重做日志是InnoDB存储引擎的一种物理格式的日志，用来实现事务持久性，主要有两部分文件组成，在内存中的重做日志缓冲（redo log buffer）以及磁盘中的重做日志文件（redo log），（循环写，数据会被覆盖）。使用场景：崩溃恢复，在发生故障的时间点，尚有脏页未写入磁盘，在重启 mysql 服务的时候，根据 redo log 进行重做，从而达到事务的持久性这一特性。 undo log回滚日志是InnoDB存储引擎的一种逻辑格式的日志，记录的是数据的逻辑变化，保证的是数据库的原子性，比如一条insert语句对应的是一条delete的undo log，在发生事务错误时，就能回滚到事务之前的数据状态；MVCC，事务未提交前，undo log 保存了未提交的版本数据，作为旧版本的快照数据，类似于做备份。 binlog是MySQL Server层的一种逻辑格式的日志，用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。使用场景：主从复制 ：采用异步复制方式，在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致；数据恢复，通过使用 mysqlbinlog 工具再结合 binlog 文件，可以将数据恢复到过去的某一时刻。主从复制如果对数据一致性和可靠性要求较高，可以考虑使用半同步复制；如果对延迟和主服务器性能要求较高，可以继续使用异步复制，根据实际需求调整复制模式。异步复制 master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中； slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件 主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中， 从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。半同步复制主服务器将数据修改操作记录到二进制日志，并等待至少一个slave服务器确认已接收到并应用了这些日志后才继续执行后续操作。BinlogBinlog 有三种格式： Row，记录操作语句对具体行的操作和操作前的整行信息。缺点是占用空间大，优点是保证数据安全 Statement，记录修改的 sql 语句。缺点是在mysql集群时的一些操作会导致数据不一致（例如 Now() 的时间不同）。 Mixed写入到磁盘的操作： write：从 Buffer pool 写到 page cache。 fsync：将数据持久化到磁盘。Binlog 的持久化： sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync； sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。Redolog写入流程： 写入 redo log buffer 写入（write）到 page cache 持久化（fsync）到磁盘中刷盘时机： MySQL 正常关闭 redo log buffer 的写入量大于 redo log buffer 内存空间（默认8MB）的一半时，write 到 page cache 中。 后台线程每隔一秒调用 write 将 redo log buffer 写到 page cache，然后 fsync 持久化到磁盘。 innodb_flush_log_at_trx_commit 参数 当innodb_flush_log_at_trx_commit=0时，InnoDB会每秒钟将log buffer的数据write到文件系统缓存中，并调用fsync操作将数据缓存更新至磁盘中，与事务的执行与否无关。因此，在实例崩溃恢复场景中，可能会出现丢失1秒钟的事务。 当innodb_flush_log_at_trx_commit=1时，InnoDB将在每次事务提交时将log buffer的数据write到文件系统缓存中，并调用fsync操作将数据缓存更新至磁盘中。此种方式下，数据库完全遵守ACID特性，安全性较高。 当innodb_flush_log_at_trx_commit=2时，InnoDB将在每次事务提交时将log buffer中的数据write到文件系统缓存中，每秒钟将文件系统缓存中的数据fsync到磁盘中。不能完全保证每秒更新磁盘一次，没有被更新到磁盘中的事务可能会因宕机而丢失。Buffer Pool在 MySQL 启动时，向操作系统申请一片连续的空间，大小为 128MB。Buffer Pool中维护的数据结构是缓存页（16 KB 的数据页），而且每个缓存页都有它对应的描述信息。还有存在三个双向链表，分别是FreeList、LRUList以及FlushList。这三个双向链表中维护着缓存页的描述信息。读写数据流程：当读取数据时，先读 Buffer Pool 中的数据，再去磁盘中读；写数据时，修改 Buffer Pool 中的页，设置为脏页，最后由后台线程写入到磁盘；双向链表 FreeList，存放空闲的缓存页的描述信息 LRUList，用于提高缓存命中率 FlushList，存放脏页的描述信息为了解决预读失效（被提前加载进来的数据页并没有被访问）的问题，链表做了冷热数据分离优化，5/8的区域是热数据区域，3/8的区域算是冷数据区域为了解决 Buffer Pool 污染（扫描大量数据把热数据淘汰掉）的问题，进入热数据区域设置一个时间判断，如果数据被访问并且在冷数据区域的停留时间超过 1 秒，才会被放入热数据区域，否则仍然被放入冷数据区域。脏页刷新 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘； Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘； MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘； MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；Crash-Safe 能力，两阶段提交（崩溃恢复）前提：innodb_flush_log_at_trx_commit 设置为1，sync_binlog 设置大于0 先将数据修改写入redo log，并将其标记为 prepare 状态 将相应的 sql 语句写入 binlog commit阶段：将 redo log 标记为 commit 状态，然后根据 sync_binlog 参数的设置，决定是否将 binlog 刷盘如果发生崩溃，先检查 redo log 记录的事务操作是否为 commit 状态。 如果是 commit 状态说明没有数据丢失，判断下一个。 如果是 prepare 状态，检查 binlog 记录的对应事务操作（redo log 与 binlog 记录的事务操作有一个共同字段 XID，redo log 就是通过这个字段找到 binlog 中对应的事务的）是否完整（这点在前面 binlog 三种格式分析过，每种格式记录的事务结尾都有特定的标识），如果完整就将 redo log 设为 commit 状态，然后结束；不完整就回滚 redo log 的事务，结束。执行顺序 from on join where group by having select distinct order by limit每一步执行时都会产生一个虚拟表，都会被用作下一个步骤的输入。锁乐观锁、悲观锁 乐观锁：不能解决脏读问题 悲观锁：select … for update全局锁、表级锁、行锁 全局锁：对整个数据库实例加锁，处于只读状态，其命令是Flush tables with read lock（FTWRL），用于全库逻辑备份。 表级锁：开销小，加锁快，不会出现死锁，发生锁冲突的概率最高，并发度最低。适合以查询为主。 表锁，可以添加表级别的共享锁或排他锁，锁的粒度较粗。 元数据锁（MDL），CRUD时，数据库自动给表加上MDL读锁；变更表结构时，自动加MDL写锁。事务提交后才会释放MDL锁。 意向锁，在执行插入、更新、删除需要加独占锁之前，需要对表先加上意向独占锁，其目的是快速判断表里是否有记录被加锁。 AUTO-INC锁，自增锁，插入数据时获取该锁，插入语句完成后，释放锁。 行锁：开销大，加锁慢，会出现死锁，发生锁冲突的概率最低，并发读也高。只有InnoDB引擎支持。行锁依赖于索引，如果加锁操作没有使用到索引，那么会退化成表锁。 记录锁：锁定一条记录，存在 S 型记录锁和 X 型记录锁。加了 S 型记录锁后可以继续加 S 型记录锁，但不能加 X 型记录锁；加了 X 型记录锁后不能加 S 型或 X 型记录锁。存在于包含主键索引的唯一索引中。 间隙锁：锁定一个范围，前开后开，不包含记录本身，存在于可重复读和串行化这两种隔离级别，为了解决可重复读隔离级别下幻读的现象。插入意向锁是一种表明插入意向的间隙锁。 临键锁（next-key lock）：加锁的基本单位，锁定一个范围，前开后闭，存在于非唯一索引中。 共享锁（读锁）、排他锁（写锁） 共享锁：读锁，其他事务可以读，但不能写，select lock in share mode 排他锁：写锁，其他事务不能读，也不能写，select for updateFor update 加什么锁RC 隔离级别 唯一索引 + 有值：记录锁 主键 + 有值：记录锁 普通索引 + 有值：记录锁 无索引 + 有值：记录锁RR 隔离级别 主键查询 + 有值：记录锁 主键查询 + 空值：间隙锁 唯一索引 + 有值：记录锁 唯一索引 + 空值：间隙锁 普通索引 + 有值：间隙锁 普通索引 + 空值：间隙锁 索引 + 范围查询：间隙锁只要通过查询条件查到的数据不唯一，就加间隙锁。mysql 数据实时同步到Es常见的数据同步方案主要有以下三种： 同步调用。在实现增删改的同时，通过调用ES所在服务提供的接口。 异步调用。增删改服务和搜索服务分别通过MQ进行发送和监听消息，有效降低业务的耦合度，但较为依赖MQ的性能。 binlog监听。给MySQL开启binlog功能，搜索服务基于canal监听binlog变化，但开启binlog会增加数据库负担、同时实现复杂度较高。 Canal Flink CDC但也有异步调用和binlog监听结合在一起的例子，用canal作slave节点。分库/分表分为 水平切分（又称为 Sharding） 和 垂直切分。切分策略 范围切分，例如每一千万条数据一张表 哈希切分，对分表键进行哈希运算，主流方法 映射表，将分表键和数据库表对映射关系记录在表上分布式ID建议使用雪花算法，其中序列号一直保持递增，不会因为时间戳的不同而归零，防止被猜测上下文ID。注入攻击通过客户端向应用程序输入数据来插入或注入一个 SQL 查询/操作。防止注入攻击 参数化查询 使用正则化验证输入 最小权限原则 字符串过滤关键字MyBatis # 和 $ 的区别 # 将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。很大程度防止sql注入 $ 将传入的数据直接显示生成在sql中。无法防止Sql注入。" }, { "title": "Basics of Java", "url": "/posts/java/", "categories": "Backend, Java", "tags": "java, backend", "date": "2022-06-21 14:23:14 +0800", "snippet": "基本知识三大特点：封装继承多态。语法糖：switch支持String、泛型、自动拆装箱、变长参数、枚举、内部类、条件编译、断言、数值下划线、for-each、try-with-resources、Lambda表达式装箱：Integer i = Integer.valueOf(10)， 拆箱：int n = i.intValue()反射：指动态获取的信息以及动态调用对象的方法的功能。在运行状态...", "content": "基本知识三大特点：封装继承多态。语法糖：switch支持String、泛型、自动拆装箱、变长参数、枚举、内部类、条件编译、断言、数值下划线、for-each、try-with-resources、Lambda表达式装箱：Integer i = Integer.valueOf(10)， 拆箱：int n = i.intValue()反射：指动态获取的信息以及动态调用对象的方法的功能。在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性Object 类的方法 clone() getClass() toString() finalize() equals() hashCode() wait() notify() notifyAll()双等号和 equals() 的区别 针对 String 引用数据类型，== 是用来判断两个对象的引用是否相等，而 equals() 是判断两个对象的值是否相等。 基本数据类型没有 equals() 方法 针对自定义对象而言，如果没有重写 equals() 方法，则两者没有区别，equals() 内部是通过 == 来判断。重写 equals() 为什么一定要重写 hashCode() 对比两个对象是否相等时，先使用 hashCode() 判断，再用 equals() 判断 相同的对象一定要有相同的哈希值假设重写 equals() 但没有重写 hashCode()，并且因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行先后判断，如果没有重写 hashCode()，则直接认为两个对象不相等。为什么不直接使用 hashCode 就确定两个对象是否相等呢这是因为不同对象的 hashCode 可能相同；但 hashCode 不同的对象一定不相等，所以使用 hashCode 可以起到快速初次判断对象是否相等的作用。内存结构运行时数据区域包含线程私有的程序计数器、虚拟机栈、本地方法栈，线程共享的堆（包含字符串常量池）。直接内存（堆外内存）包含元空间（包含类常量池和运行时常量池）。 程序计数器：与操作系统中的程序计数器类似，为了线程切换后能恢复到正确的执行位置，是唯一一个不会出现 OutOfMemoryError 的内存区域。 虚拟机栈：以帧为单位，帧由局部变量表、操作数栈、动态链接、方法返回地址组成。每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。 局部变量表：主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置） 操作数栈：用于存放方法执行过程中产生的中间计算结果，也存放计算过程中产生的临时变量。 动态链接：将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。与类加载中的解析类似。 方法返回地址：顾名思义。 本地方法栈：和虚拟机栈所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法（机器码）服务。 堆：唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 字符串常量池：简单理解为用C++实现的默认固定大小为1009的HashTable。在每个VM中只有一份，存放的是字符串常量的引用值 。关于常量池中的String类型的数据，String#intern 的用法。 类常量池：每个java文件被编译成class文件后会有一项常量池，用于存放编译器生成的字面量和符号引用。在编译阶段，存放的是常量的符号引用。 运行时常量池：是在类加载完成后，将每个class常量池中的符号引用值转存到运行时常量池中，也就是说，每个class都有一个运行时常量池，类在解析阶段，将符号引用替换成直接引用，与字符串常量池中的引用值保持一致。方法区永久代和元空间的区别在 hotpot 虚拟机中，JDK7以前的方法区是用永久代实现的；在JDK8后，方法区用元空间实现的。最大的区别：元空间位于本地内存上；而永久代位于虚拟机内存中，与堆是连续的一块内存。垃圾回收只有 Full GC 时执行垃圾回收，主要回收两部分内容： 常量池中废弃的常量 不再使用的类型，类需要同时满足下面 3 个条件才能被卸载： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 class常量池、字符串常量池和运行时常量池的区别内存模型（JMM）JMM 旨在提供一个统一的可参考的规范，屏蔽平台内存访问差异性。这个规范为多线程读写共享变量时如何与内存交互提供了规则和保证。并发编程中，程序会因为 CPU 多级缓存或指令重排序等出现问题，因此需要一些规范要保证并发编程的可靠性。关键概念包括： 主内存：表示所有线程都可以访问的共享内存。线程不能直接读写主内存中的变量。 工作内存：每个线程都有自己的工作内存，线程的工作内存保存了该线程用到的变量和主内存共享变量的副本拷贝，线程对变量的操作都在工作内存中进行。当一个线程修改了自己工作内存中的变量时，它必须把这个变量的最新值写回到主内存中，以便其他线程可以看到这个最新的值。 共享变量：这些变量可以被多个线程访问。它们可以是实例变量或静态变量。必须存储在主内存中。JMM 为处理共享变量定义了三个特征（多线程中的概念）： 可见性：当一个线程修改共享变量的值，其他线程能够立即知道被修改了。当变量被 volatile 修饰时，这个变量被修改后会立刻刷新到主内存，当其它线程需要读取该变量时，会去主内存中读取新值。但普通变量读取的仍是旧值。 原子性：一个操作是不可分割，不可中断的，一个线程在执行时不会被其他线程干扰。Synchronized 块之间的操作具有原子性 顺序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般杂乱无序。volatile通过内存屏障来保证可见性的 保证可见性，但不保证原子性！只是确保将变量的更新操作通知到其他线程。不能一定能保证线程安全。 禁止指令重排，背景：为了提高性能，编译器和处理器常常会对指令重排。禁止指令重排避免了多线程环境下程序出现乱序执行的现象。happens-beforehappens-before原则定义如下： 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。重排序之后的执行结果与按照happens-before关系来执行的结果一致即可。as-if-serialAs-if-serial的意思是所有的语句都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。为保证as-if-serial语义，Java异常处理机制也会为重排序做一些特殊处理。八种内存交互操作内存屏障 LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障。在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个SotreLoad屏障。     类的生命周期 加载：通过类的全限定名（包名 + 类名）获取class文件的二进制字节流（通过类加载器来完成，其加载过程使用双亲委派模型），将其转化为方法区运行时的数据结构，最后在堆中实例化一个java.lang.Class对象，作为方法区中这个类的信息的入口。 连接 验证：确保被加载的类的正确性 准备：为类的静态变量分配内存并设为jvm的默认值（不同于下文的初值，基本类型为零，引用类型为null，final修饰的常量为设定的值），对于非静态的变量，则不会为它们分配内存。 解析：虚拟机将常量池中的符号引用替换为直接引用，主要针对类或接口，字段，类方法，方法类型等。举例：使用内存地址（直接引用）指向方法名（符号引用）代替方法名。 初始化：按照顺序自上而下运行类中的变量赋值语句和静态语句，如果有父类，则首先按照顺序运行父类中的变量赋值语句和静态语句在类的初始化阶段，只会初始化与类相关的静态赋值语句和静态语句。类变量（静态变量）在方法区分配内存，并设置初值。 使用：包括主动引用和被动引用。直接引用就会触发类的初始化，其中包括以下四种情况： 通过new关键字实例化对象、读取或设置类的静态变量、调用类的静态方法。 初始化子类的时候，会触发父类的初始化。 作为程序入口直接运行时（也就是直接调用main方法）。 通过反射方式执行以上三种行为。 卸载：需要同时满足以下三个条件：该类所有的实例都已经被回收，即Java堆中不存在该类的任何实例；加载该类的ClassLoader已经被回收；该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。单例对象不会被JVM垃圾回收，因为无法满足卸载的第一个条件，Java堆中会始终存在该单例的实例。类加载器线程上下文类加载器：破坏了“双亲委派模型”，可以在执行线程中抛弃双亲委派加载链模式，使程序可以逆向使用类加载器，例如SPI (Service Provider Interface)。SPI接口中的代码经常需要加载具体的实现类。SPI接口是Java核心库的一部分，由 启动类加载器(Bootstrap Classloader) 来加载，而实现类由 系统类加载器(AppClassLoader) 来加载。双亲委派机制概念：双亲委派机制是指当一个类加载器收到某个类加载请求时，该类加载器首先会把请求委派给父类加载器。每个类加载器都是如此，它会先委托父类加载器在自己的搜索范围内找不到对应的类时，该类加载器才会尝试自己去加载。双亲委派机制的作用：保证Java类的加载的一致性和安全性，避免了类的重复加载和恶意代码的替换。Tomcat中的类加载器： Tomcat自身所使用的类加载器，会加载jre的lib包及tomcat的lib包的类，遵循双亲委派机制。加载顺序：(1).先从缓存中加载；(2).如果没有，则从JVM的Bootstrap类加载器加载；(3).如果没有，则从父类加载器加载，加载顺序是AppClassLoader、Common、Shared。(4).如果没有，则从当前类加载器加载（按照WEB-INF/classes、WEB-INF/lib的顺序）； 每个Web应用程序用的，每个web应用程序都有自己专用的WebappClassLoader，优先加载/web-inf/lib下的jar中的class文件，这样就隔离了每个web应用程序的影响，不遵循双亲委派机制。加载顺序：(1).先从缓存中加载；(2).如果没有，则从JVM的Bootstrap类加载器加载；(3).如果没有，则从当前类加载器加载（按照WEB-INF/classes、WEB-INF/lib的顺序）；(4).如果没有，则从父类加载器加载，由于父类加载器采用默认的委派模式，所以加载顺序是AppClassLoader、Common、Shared。Java的SPI：SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。当服务的提供者提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。对象的创建过程 类加载检查 分配内存：指针碰撞或空闲列表 当多个对象并发争抢空间时，有两种解决办法：CAS 和本地线程分配缓冲（TLAB，默认方式） 初始化零值 设置对象头 执行构造方法对象的内存布局 对象头，两部分组成：存储自身运行时数据如哈希码，GC分代年龄；指向类的类型指针 实例数据，真正存储有效信息的部分 对齐填充，起占位作用对象的定位访问（针对JVM虚拟机栈中的局部变量表） 句柄，Java 堆中将会划分出一块内存来作为句柄池，局部变量表 reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。 直接指针，局部变量表里 reference 中存储的直接就是对象的地址。垃圾回收JVM触发GC时，首先会让所有的用户线程到达安全点SafePoint时阻塞，也就是STW，然后枚举根节点，即找到所有的GC Roots，通过可达性算法向下搜寻活跃对象，可达的对象就保留，不可达的对象就回收。可达性算法： 引用计数算法 可达性分析哪些对象可以作为GC Roots 虚拟机栈(栈帧中的本地变量表)中引用的对象 本地方法栈(Native 方法)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 所有被同步锁持有的对象内存分配和回收原则 对象优先在Eden区分配 大对象直接进入老年代 长期存活的进入老年代GC 分类 Partial GC Minor GC：只对新生代进行垃圾收集 Major GC：只对老年代进行垃圾收集 Mixed GC：整个新生代和部分老年代，只有G1收集器有 Full GC：整个Java堆和方法区Full GC 触发条件 老年代空间不足 创建大对象，Eden 区域放不下大对象，直接进入老年代 Minor GC 后，存活对象进入老年代 调用 system.gc()，系统会建议执行 FGC 空间分配担保机制失败，老年代连续可用空间不足空间担保策略空间担保策略是 JVM 的一种机制，发生 Minor GC 之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果小于，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的；如果小于或者HandlePromotionFailure=false，则改为进行一次Full GC。垃圾收集算法 标记——清除算法：顾名思义，标记可回收的对象并清除。 标记——复制算法：将内存分成大小相同的两份，需要垃圾收集时，将存活的对象复制到另一份内存中，缺点：内存缩小为原来的一半。 标记——整理算法：标记可回收的对象，将存活的对象向一端移动，适合老年代这种垃圾回收频率不高的场景。 分代收集算法：在新生代和老年代不同的代用不同的垃圾收集算法。垃圾收集器 Serial 收集器，单线程、复制算法的新生代收集器 ParNew 收集器，多线程、复制算法的新生代收集器，老年代采用Serial Old收集器 Parallel Scavenge 收集器，多线程、复制算法的新生代收集器，高吞吐量。 Serial Old 收集器，单线程、标记-整理算法的老年代收集器。 Parallel Old 收集器，多线程、标记-整理算法的老年代收集器。 CMS(Concurrent Mark Sweep) 收集器，标记-清除算法，以获取最短回收停顿时间为目标的收集器。JDK14正式移除。 G1(Garbage-First) 收集器，标记-整理 + 复制算法，内存碎片的产生率大大降低。JDK9-JDK17的默认垃圾收集器。G1收集器内存模型垃圾收集器发展历程： JDK8 默认 Parallel Scavenge（标记-复制） + Parallel Old（标记整理） JDK9 默认 G1 JDK11 提出 ZGC JDK14 CMS 被移除CMS（Concurrent Mark Sweep）收集器：基于标记-清除算法，在Minor GC时会暂停所有的应用线程，并以多线程的方式进行垃圾回收。在Full GC时不再暂停应用线程，而是使用若干个后台线程定期的对老年代空间进行扫描。 步骤： 初始标记（CMS initial mark）：有STW，但速度很快 并发标记（CMS concurrent mark）：从GC Roots的直接关联对象开始遍历整个对象图 重新标记（CMS remark）：STW，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录；采用三色标记算法和增量更新避免漏标 并发清除（CMS concurrent sweep）：清理删除掉标记阶段判断的已经死亡的对象 优点：并发收集，低停顿 缺点： 工作时会占用一部分CPU资源而导致用户程序变慢，降低总吞吐量 无法清除浮动垃圾 基于标记-清除算法会导致内存碎片不断增多，在分配大对象时有可能会提前触发一次Full GC。 停顿时间不可预期 Garbage First（G1）收集器： 特点：引入分区的思路，弱化了分代的概念，并合理利用垃圾收集各个周期的资源。 内存结构：堆内存被切分为多个固定大小的区域，最小为1M，最大为32M，默认2048份。 内存分配：每个区域被标记为E、S、O和H，分别表示Eden，Survivor，Old，Humongous。Humongous区域是为了那些存储超过50%标准region大小的对象而设计的，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。 执行特点： 并行与并发：使用多个CPU核缩短Stop The World停顿时间。 空间整合：从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可观测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。 步骤： 初始标记（Initial Marking），STW，标记一下 GC Roots 能直接关联到的对象。 并发标记（Concurrent Marking），从 GC Root 开始对堆中对象进行可达性分析，找到存活对象。 最终标记（Final Marking），为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，STW，但是可并行执行。 筛选回收（Live Data Counting and Evacuation），对各个Region中的回收价值和成本进行排序并制定回收计划。 优点：保持高回收率的同时，减少停顿一个线程 OOM 后，其他线程仍能正常运行，因为 OOM 之前会 GC，释放掉资源。JVM调优 选择合适的垃圾收集器：CPU单核，只能选择Serial；CPU多核，关注吞吐量 ，那么选择Parallel Scavenge（标记复制） + Paralle Old（标记整理）组合；CPU多核，关注用户停顿时间，JDK版本1.6或者1.7，内存小，那么选择CMS。CPU多核，关注用户停顿时间，JDK1.8及以上，JVM可用内存6G以上，那么选择G1。 调整内存大小，现象：垃圾收集频率非常频繁。 设置符合预期的停顿时间，现象：程序间接性的卡顿。参数：-XX:MaxGCPauseMillis 调整内存区域大小比率，现象：某一个区域的GC频繁，其他都正常。参数：-XX:SurvivorRatio=6, -XX:NewRatio=4 提升老年代年龄标准，现象：老年代频繁GC，每次回收的对象很多。参数：-XX:InitialTenuringThreshol=7 调整大对象的标准，现象：老年代频繁GC，每次回收的对象很多，而且单个对象的体积都比较大。参数：-XX:PretenureSizeThreshold=1000000//新生代可容纳的最大对象,大于则直接会分配到老年代，0代表没有限制。 调整GC的触发时机，现象：CMS收集器的情况下，G1 经常 Full GC，程序卡顿严重。 调整JVM本地内存（直接内存）大小，现象：堆内存空间充足，但是报OOM调优的一条经验总结： 将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。Java IO BIO：同步阻塞IO，使用方便，但并发处理能力低 NIO：同步非阻塞IO，适用于连接数目多且连接比较短（轻操作）的架构 AIO：异步非阻塞IO，适用于连接数目多且连接比较长（重操作）的架构 阻塞/非阻塞，是对同一个线程来说。关注的是程序在等待调用结果（消息，返回值）时的状态。阻塞调用是指调用结果返回之前，当前线程会被挂起。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 同步/异步，针对调用者与被调用者，它们是线程之间的关系。同步操作，调用者需要等待被调用者返回结果，才会进行下一步操作；异步操作，调用者不需要等待被调用者返回调用，即可进行下一步操作，被调用者通常依靠事件、回调等机制来通知调用者结果NIO vs IO: IO是面向字节流的，NIO是面向缓冲区的 IO流是阻塞的，NIO流是不阻塞的 选择器：Java NIO的选择器允许一个单独的线程来监视多个输入通道IO多路复用（事件驱动）：一个线程不断轮询多个socket的状态，只有当socket真正有读写状态时，借用当前线程或者使用线程池额外启动线程，调用实际的IO读写操作。Java NIO: 实际上也是一种多路复用的IO。 三大核心部分：Channel(通道) ，Buffer(缓冲区), Selector(选择器)，Channel 负责传输（类比成铁路）， Buffer 负责存取数据（类比成载着货物的火车） Channel是双向的，数据总是从通道读到缓冲区或者从缓冲区中写入通道内。 额外一个Selector线程，用于监听多个通道（Channel）的事件（比如：连接打开，数据到达），如果由事件发生，则获取事件并对每个事件进行相应的响应处理。并发编程一个 Java 程序的运行是 main 线程和多个其他线程同时运行。多线程CompletableFutureCompletableFuture 最大的特点是支持函数式编程，可以通过回调的方式处理计算结果、链式组合异步任务等。当异步任务完成或者发生异常时，自动调用回调对象的回调方法。wait() 和 sleep() 区别 sleep() 是 Thread 的静态方法，wait() 是 Object 的普通 final 方法 wait() 方法需要在synchronize块或者synchronize方法里调用，作用是释放锁，然而sleep不需要 sleep() 是休眠，wait() 是挂起 wait() 唤醒需要用 notify() 或者 notifyAll() ，而 sleep() 则是休眠一段时间自己就恢复 如果需要线程停顿，使用 sleep()；使用 wait() 进行线程间的通信synchronized 修饰普通方法/静态方法：通过 Access flags 的标记符实现同步 修饰代码块：通过 monitorenter 和 monitorexit 指令实现同步底层都是通过对象头里 Mark Word 指向的对象监听器（Monitor）实现的，再底层是操作系统的互斥量（mutex）实现的同一时刻只能有一个线程运行 synchronized(lock) 内的代码块，其他线程会否则阻塞。PS：获取锁（运行代码块），释放锁（阻塞代码块） wait(): 获取锁并使线程进入等待状态 notify(): 随机唤醒一个在等待锁释放（wait()）的线程 notifyAll(): 唤醒所有正在等待锁释放（wait()）的线程，注意：notify() 或 notifyAll() 必须等到退出 synchronized() 或 wait() 后才释放锁！synchronized (obj) { // 条件不满足 while (condition does not hold) { obj.wait(); } // 执行满足条件的代码 obj.notifyAll();}orsynchronized (obj) { while (true){ // 条件满足 if (condition holds){ // 执行满足条件的代码 obj.notifyAll(); } obj.wait(); }}synchronized 可以用来修饰非静态方法（普通方法）、静态方法、代码块，锁住的是 class 对象的对象头！run() 和 start() 的区别: run()，调用普通方法，并不开启新线程。 start()，启动新线程，由JVM调用线程的run()方法。Synchronized 和 Lock 的区别： Lock 是一个接口，Synchronized 是一个关键字 Lock 需要手动释放锁，Synchronized 会自动释放锁 Lock 可以是公平锁/非公平锁，Synchronized 只能是非公平锁 Lock 有多种获取锁的方式，例如一定时间内获取不到会返回，Synchronized 获取不到锁一直会阻塞 性能方面，在竞争激烈的情况下，Lock 的性能会比 Synchronized 好RenentantLock： Lock：拿不到锁会一直等待 tryLock：去尝试获取锁，获取不到返回 false守护线程（Daemon Thread）Java 中的线程分为两种： 用户线程。 守护线程，其主要作用是为用户线程服务，比如垃圾回收线程，就是最典型的守护线程。在JVM中，所有非守护线程都执行完毕后，无论有没有守护线程，虚拟机都会自动退出。也就是守护线程拥有自动结束自己生命周期的特性，而非守护线程不具备这个特点。集合框架： Collection Set List Queue Map线程安全的list： vector CopyOnWriteArrayList 读多写少的情况 Collections.synchronizedList() 读少写多的情况HashMap 知识点 HashMap（JDK8）: 乱序，数组+链表+红黑树+尾插法，链表长度大于8并且数组长度大于64时转红黑树，红黑树节点个数小于6转链表。JDK7时用数组+链表+头插法（可能造成循环链表）实现。 LinkedHashMap: 按插入顺序排序 TreeMap: 按字典序排序，因为是按字典序排序的，所以键肯定不能为null，值可以为null IdentityHashMap：利用哈希表实现Map接口，不同的是，其比较键（或值）时，使用引用相等性代替对象相等性。 ConcurrentSkipListMap：基于跳表的线程安全的，实现快速查找的链表结构。HashMap面试题为什么计算哈希值采用低十六位和高十六位异或操作：计算数组下标是与操作，只有低 n 位进行与操作，高位不参与任何操作 -&gt; 为了增大散列程度减小哈希碰撞，因此将高十六位参与进哈希值的计算。put() 的流程： hashcode的高十六位和低十六位进行异或运算 (n - 1) &amp; hash 计算数组下标，当 n 为二次幂时，等价于取余操作 (n - 1)&amp; hash = hash % n。 判断当前下标是否有元素，若有元素，使用尾插法。再根据链表长度判断是否需要转换成红黑树。第一次扩容：执行第一次 put() 操作时，如果数组为空便会执行第一次扩容操作，初始化数组容量为默认大小。扩容的过程： 将数组扩容成原数组的两倍 如果没有哈希冲突的节点，使用 e.hash&amp;(newCap - 1) 计算新的桶位置 如果是链表，使用 e.hash&amp;oldCap 并且判断是否等于零（本质上判断最高位结果是否为零） 如果最高位结果是0，桶位置不变 如果最高位结果是1，桶位置是原位置 + 扩容长度Set: HashSet: 乱序，基于HashMap实现 LinkedHashSet: 按插入的顺序排序，基于LinkedHashMap实现 TreeSet: 按字典序排序，基于红黑树NULL key AND NULL value: key HashMap、LinkedHashMap 能使用 null key ConcurrentHashMap、TreeMap、HashTable 不能使用 null key。 value HashMap、LinkedHashMap、TreeMap 能使用 null value Hashtable、ConcurrentHashMap 不能使用 null value。 为什么ConcureentHashMap的key和value都不能为null： value不能为null：多线程情况下需要杜绝二义性。二义性是指当返回null时，无法判断是存在value为null的key还是不存在key从而返回null。因为单线程中可以使用 containsKey() 解决，但是多线程下无法使用同样的方法，因为可能会有其他线程进行其他操作影响返回值。ConcurrentHashMap JDK7 vs JDK8 JDK7: 数组 + 链表。先定位 Segment，再定位桶。底层结构是继承了ReentrantLock的Segment数组。可以看成是由线程安全的HashMap组成的一个map数组，数组的长度决定了支持的最大的并发量。 JDK8: 数组 + 链表 + 红黑树。可以直接定位到桶。链表中的元素超过8并且数组长度大于64后，将链表结构转换成红黑树。 使用 volatile 修饰Node的值和Next数组以保证值变化时对于其他线程是可见的 使用 table 数组的头结点作为 synchronized 的锁来保证写操作的安全 当头结点为 null 时，使用 CAS 操作来保证数据能正确的写入。 HashTable速度慢：使用synchronized对整个对象加锁。JDK7：对整个数组进行分段(每段都是由若干个 hashEntry 对象组成的链表)，每个分段都有一个 Segment 分段锁(继承 ReentrantLock 分段锁)。与hashtable相比，加锁粒度更细，但是初始化Segment数组长度后就无法扩容。ConcurrentHashMap 是一个二级哈希表。在一个总的哈希表下面，有若干个子哈希表。JDK8：对table数组的头节点加锁（哈希桶为空时，使用CAS将新的Node写入哈希桶的首节点；哈希桶不为空时，使用synchronized对首节点加锁接着添加节点） put：分两步，计算哈希值和一个死循环，循环步骤， first节点还没有初始化，所以初始化first节点，然后进入下次循环； first节点初始化了,但是为空，采用CAS方式把当前要put的值设置进这处，设置失败则进入下次循环，成功则保存成功，退出循环； 如果判断有其他线程正在对ConcurrentHashMap扩容（hash==MOVED），获取要去获取新的tab，进入下次循环； 找到了对应哈希桶的首节点f，直接对f加synchronized同步，然后判断f节点是链表结构还是红黑树结构，链表结构则遍历链表进行设置，红黑树则采用红黑树设置进去。设置成功后判断是否需要把链表结构转红黑树； get: 大部分情况下不加锁，是通过 volatile 修饰 Node 成员 val 保证的。与 volatile 修饰桶数组无关，桶数组用 volatile 修饰主要是保证在数组扩容的时候保证可见性。仅当节点为红黑树、正在变色旋转、查询非头节点时，会加基于 CAS 实现的读写锁。ThreadLocal: 提供线程内的局部变量，在多线程的环境中保证各个线程内的变量不同。将数据封闭在线程中而避免使用同步，即线程封闭。一个ThreadLocal对象即是一个线程局部变量。jdbc连接池就是用ThreadLocal，典型例子。以下使四种方法： Object get()：获取该线程局部变量的值。 void set(Object value)：给该线程局部变量赋值。 protected Object initialValue()：返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。 public void remove()：将当前线程局部变量的值删除。底层是 ThreadLocalMap 内部静态类，由数组实现，解决 hash 冲突的方式采用的是线性探测法存在内存泄漏的原因：由于 ThreadLocalMap 的生命周期跟 Thread 一样长，如果没有手动删除对应 key 就会导致该 key 的value 永远无法被访问，造成内存泄漏正确使用方法： 每次使用完ThreadLocal都调用它的remove()方法清除数据，防止 ThreadLocalMap 中 Entry 一直保持对 value 的强引用，导致 value 不能被回收 将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉线程池线程池的七个参数： 核心线程数（corePoolSize）：核心线程数是线程池中保持活动状态的线程数。即使没有任务需要执行，核心线程也不会被回收。当有新任务提交时，如果核心线程都在忙碌，则会创建新的线程来处理任务。 最大线程数（maximumPoolSize）：最大线程数是线程池中允许的最大线程数。当工作队列满了并且活动线程数达到最大线程数时，如果还有新任务提交，线程池将创建新的线程来处理任务。但是，超过最大线程数的线程可能会导致资源消耗过大。 空闲线程存活时间（keepAliveTime）：空闲线程存活时间指的是非核心线程在没有任务执行时的最长存活时间。当线程池中的线程数超过核心线程数且空闲时间达到设定值时，多余的线程将被终止，直到线程池中的线程数不超过核心线程数。 时间单位（unit）：时间单位是用于表示核心线程数和空闲线程存活时间的单位。常见的时间单位包括秒、毫秒、分钟等。 工作队列（workQueue）：工作队列用于存储待执行的任务。当线程池中的线程都在忙碌时，新提交的任务将被添加到工作队列中等待执行。常见的工作队列类型有直接提交队列（SynchronousQueue）、任务优先队列（PriorityBlockingQueue）、有界队列（ArrayBlockingQueue）和无界队列（LinkedBlockingQueue）等。 线程工厂（threadFactory）：线程工厂用于创建新线程。线程工厂提供了创建线程的方法，可以自定义线程的名称、优先级等属性。 拒绝策略（rejectedExecutionHandler）：拒绝策略定义了当线程池无法接受新任务时的处理策略。当工作队列已满且线程池中的线程数已达到最大线程数时，新任务将被拒绝执行。常见的拒绝策略有丢弃、丢弃最旧的任务、抛出异常等。 AbortPolicy 拒绝任务并抛出一个异常 RejectedExecutionException DiscardPolicy 拒绝任务，不抛出异常。 DiscardOldestPolicy 把老的任务丢掉，执行新任务。 CallerRunsPolicy 直接调用线程处理该任务。 JDK四种线程池： newCachedThreadPool，可根据需要创建新线程的线程池 newSingleThreadExecutor，单线程池 newFixedThreadPool，创建固定大小的线程池 newScheduledThreadPool，创建一个大小无限的线程池线程池执行顺序： 首先判断 corePoolSize 是否已满，如果没有满，那么就去创建一个线程去执行该任务；否则请看下一步 如果线程池的核心线程数已满，那么就继续判断 BlockingQueue 是否已满，如果没满，那么就将任务放到任务队列中；否则请看下一步 如果任务队列已满，那么就判断线程池中的线程数量是否达到了maxumunPoolSize，如果没达到，那么就创建线程去执行该任务；否则请看下一步； 如果线程池已满，那么就根据拒绝策略来做出相应的处理；简而言之：corePool-&gt;workQueue-&gt;maxPool线程池被回收：线程池也是在堆中也是一个对象，一定要调用shutdown()线程池何时回收线程：getTask()的返回值为null时 未调用shutdown()，并且当前工作线程数过多 调用shutdown()，缓冲队列中的线程为空shutdown() 和 shutdownNow() 的区别： shutdown(): 将线程池状态置为SHUTDOWN，停止接受新的任务并且执行完所有任务后停止 shutdownNow(): 将线程池状态置为STOP，停止接受新的任务、忽略队列中等待的任务、尝试中断（interrupt）正在运行的任务、返回未执行的任务列表submit() 和 execute() 的区别：submit() 内部仍然是调用 execute() 方法，只不过 submit() 方法会获取任务返回值和异常信息。核心线程数设置： CPU密集型任务：CPU核心数 + 1：这样设置线程池的大小能实现 CPU 的最优利用率。即使当计算密集型的线程偶尔由于页缺失故障或者其他原因暂停时，这个 “额外” 的线程也能确保CPU 的时装周期不会被浪费。 IO密集型任务：CPU核心数 * 2 混合型任务：CPU核心数 * （1 + IO耗时/CPU耗时）锁 乐观锁，悲观锁： 乐观锁，修改数据前比较数据是否被修改过。CAS，原子类的递增操作，适合频繁读 悲观锁，加锁使其他线程无法修改。synchronized和lock的实现类，适合频繁写 自旋锁，非自旋锁：获取同步资源的锁失败，资源被占用（上下文切换，也就是线程的唤醒和阻塞是十分耗时的） 自旋锁，不放弃CPU时间片，通过自旋等待锁的释放，但自旋超过一定次数（默认10次）仍没有获得锁，那么线程被挂起。线程竞争不激烈并且锁持有的时间不长时，可以使用自旋锁。 非自旋锁，线程会进入阻塞状态 无锁，偏向锁，轻量级锁，重量级锁：指针对synchronized同步锁的状态，锁可以升级但不能降级。 偏向锁，通过对比Mark Word中是否存储着指向当前线程的偏向锁以解决加锁问题，避免执行CAS操作来加锁和解锁，Java15放弃偏向锁。使用背景：锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争。 轻量级锁，通过用CAS修改Mark Word操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。 重量级锁，将除了拥有锁的线程以外的线程都阻塞。 锁升级的过程：当有线程访问同步块时，无锁升级为偏向锁；当有锁竞争时，升级为轻量级锁；当自旋十次失败，升级为重量级锁。 公平锁，非公平锁： 公平锁，每个线程获取锁的顺序是按照线程访问锁的先后顺序获取的。 非公平锁，线程获取锁时并不会遵循先来先得的规则，可以插队（并不是随意的插队，而是在合适的时机插队）。当后到的线程请求锁时，该锁恰好被释放，则该锁被后到的线程拥有。 可重入锁（递归锁），非可重入锁：ReentrantLock和synchronized都是可重入锁，NonReentrantLock是非可重入锁 可重入锁，指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法可以再次获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。好处是避免死锁。 非可重入锁，如果一个方法中获取锁并调用另外方法，那么在调用另外方法前需要释放锁。 独享锁（排它锁），共享锁 独享锁，ReentrantLock、synchronized、ReentrantReadWriteLock的写锁 共享锁，ReentrantReadWriteLock的读锁，可以再加共享锁但不可以加排他锁！ Synchronized（同步锁）：属于独占锁、悲观锁、可重入锁、非公平锁。ReentrantLock：继承了Lock类，两者都是可重入锁、悲观锁、独占锁、默认非公平锁。AbstractQueuedSynchronizer（AQS）该类是一个抽象类，采用模板方法的设计模式，规定了独占和共享模式需要实现的方法。简单解释：通过 CAS 修改 volatile 修饰的int值 state（该值代表竞争资源标识） + 一个存放等待锁的线程队列。其定义了两种资源共享模式： 独占式。ReentrantLock 是独占式的锁资源。初始化 state = 0，表示资源未被锁定，调用 lock() 方法时state的值加一，并且当 state = 0 才表明其他线程有机会获取锁。 共享式。ReentrantWriteLock 和 CountDownLatch 是共享锁模式。CountDownLatch 会将任务分成 N 个子任务，初始化 state = N，每个子线程完成任务后会减一，直到为零。 锁消除指Java虚拟机在即时编译时，通过对运行上下的扫描，消除那些不可能存在共享资源竞争的锁。锁消除可以节约无意义的请求锁时间。锁粗化一直对某个对象反复加锁和解锁，频繁地进行互斥同步操作也会引起不必要的性能消耗。如果虚拟机检测到有一系列操作都是对某个对象反复加锁和解锁，会将加锁同步的范围粗化到整个操作序列的外部。//==== 粗化前 ===for(int i=0;i&lt;n;i++){ synchronized(lock){ }}//==== 粗化后 ===synchronized(lock){ for(int i=0;i&lt;n;i++){ }}接口和抽象类的区别： 相同点： 都不能被实例化 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化 不同点： 接口是对行为的抽象（强调特定功能的实现），抽象类是对物体的抽象（强调所属关系）。 接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。 实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。 接口成员变量默认为public static final，必须赋初值，不能被修改；其所有的成员方法都是public、abstract的。抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被private、static、synchronized和native等修饰，必须以分号结尾，不带花括号。 static修饰词java中静态属性和静态方法可以被继承，但是不能被重写，因此不能实现多态。静态常量/静态变量/静态方法是用static修饰的常量/变量/方法，其从属于类。另外，static是不允许用来修饰局部变量的。 静态方法可以调用静态变量，但不能调用非静态变量，因为静态方法在类加载时就分配了内存，而非静态变量是在对象实例化时才分配内存。 非静态方法可以调用静态变量，也可以调用非静态变量。 静态初始化块、初始化块和构造方法的区别执行顺序：静态初始化块 &gt; 初始化块 &gt; 构造方法非静态初始化块（构造代码块）：作用：给对象进行初始化。对象一建立就运行，且优先于构造函数的运行。与构造函数的区别：非静态初始化块给所有对象进行统一初始化，构造函数只给对应对象初始化。应用：将所有构造函数共性的东西定义在构造代码块中。静态初始化块：作用：给类进行初始化。随着类的加载而执行，且只执行一次与构造代码块的区别： 构造代码块用于初始化对象，每创建一个对象就会被执行一次；静态代码块用于初始化类，随着类的加载而执行，不管创建几个对象，都只执行一次。 静态代码块优先于构造代码块的执行 都定义在类中，一个带static关键字，一个不带static泛型和泛型擦除泛型：参数化类型，指在定义一个类、接口或者方法时可以指定类型参数。泛型擦除：是指Java中的泛型只在编译期有效，在运行期间会被删除。也就是说所有泛型参数在编译后都会被清除掉。在编译器编译后，泛型的转换规则如下： List、List 擦除后的类型为 List； List[]、List[] 擦除后的类型为 List[]； List&lt;? extends E&gt;、List&lt;? super E&gt; 擦除后的类型为 List； List&lt;T extends Serialzable &amp; Cloneable&gt; 擦除后类型为 List。JDK 设计模式 单例模式：java.lang Runtime 类使用饿汉式创建单例 工厂模式：java.util.concurrent ThreadFactory 接口使用工厂模式创建线程 代理模式：java.lang.reflect Proxy 类使用动态代理 迭代器模式：java.util Iterator 接口使用迭代器遍历集合容器 模板方法模式：java.util.concurrent.locks AQS 中的 tryAcquire, tryRelease, tryAcquireShared, tryReleaseShared 方法被公平锁和非公平锁重写 建造者模式：线程不安全的 StringBuilder 和线程安全的 StringBuffer 装饰器模式 + 适配器模式 装饰器模式：通过组合替代继承的方式在不改变原始类的情况下添加增强功能，例如 FilterInputStream 和 FilterOutputStream 用于增强 InputStream 和 OutputStream 的功能。 适配器模式：字符流对象和字节流对象的相互适配 " }, { "title": "Java知识点记录博客", "url": "/posts/java-syntax/", "categories": "Backend, Java", "tags": "java, syntax", "date": "2022-06-12 23:14:04 +0800", "snippet": "运算符优先级 优先级 运算符 1 ( )　[ ] 　. 2 ! 　~　 ++　 – 3 *　 /　 % 4 +　 - 5 « 　»　 «&lt;  »&gt; ...", "content": "运算符优先级 优先级 运算符 1 ( )　[ ] 　. 2 ! 　~　 ++　 – 3 *　 /　 % 4 +　 - 5 « 　»　 «&lt;  »&gt; 6 &lt; 　&lt;=　 &gt; 　&gt;=　 instanceof 7 == 　!= 8 &amp; 9 ^ 10 | 11 &amp;&amp; 12 || 13 ? : 14 = 　+= 　-= 　*=　 /=　 %=　 &amp;=　 |=　 ^=　 ~= 　«= 　»=　 »&gt;= 15 ， 总结：括号级别最高，逗号级别最低，单目 &gt; 算术 &gt; 位移 &gt; 关系 &gt; 逻辑 &gt; 三目 &gt; 赋值。容器(集合类)Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); // stackDeque&lt;String&gt; queue = new ArrayDeque&lt;&gt;(); // queuePriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;&gt;(); // priority queue// SetHashSet&lt;String&gt; unordered_set = new HashSet&lt;&gt;(); // 乱序，底层使用散列函数LinkedHashSet&lt;String&gt; set = new LinkedHashSet&lt;&gt;(); // 以插入顺序排序TreeSet&lt;String&gt; set = new TreeSet&lt;&gt;(); // 以字典序排序，底层使用红黑树// MapHashMap&lt;String, Object&gt; unordered_map = new HashMap&lt;&gt;(); // 乱序LinkedHashMap&lt;Integer, Integer&gt; map = new LinkedHashMap&lt;&gt;(); // 以插入顺序排序TreeMap&lt;Integer, Integer&gt; map = new TreeMap&lt;&gt;(); // 以字典序排序TreeMap&lt;Integer, Integer&gt; map = new TreeMap&lt;Integer, Integer&gt;(); // 手动加泛型，多一些约束少一些出错。在运行期没有任何区别, java的泛型只在编译期有效。ArrayList:public static void main(String[] args) { ArrayList&lt;String&gt; sites = new ArrayList&lt;String&gt;(); sites.add(\"Google\"); sites.add(\"Runoob\"); sites.add(\"Taobao\"); sites.add(\"Weibo\"); System.out.println(sites.get(1)); // 访问第二个元素 sites.set(2, \"Wiki\"); // 第一个参数为索引位置，第二个为要修改的值 sites.remove(3); // 删除第四个元素 Collections.sort(sites); // 字母排序 System.out.println(sites.isEmpty()); // 空判断 System.out.println(sites); String[] arr = new String[sites.size()]; // 创建一个新的 String 类型的数组 sites.toArray(arr); // 将ArrayList对象转换成数组}LinkedList:HashSet:public static void main(String[] args) { HashSet&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); set.add(1); set.add(2); set.add(3); set.remove(2); System.out.println(set.contains(4)); for(int item: set){ System.out.println(item); }}HashMap:public static void main(String[] args) { Map&lt;String, Integer&gt; numbers = new HashMap&lt;&gt;(); numbers.put(\"One\", 1); numbers.put(\"Two\", 2); numbers.put(\"Three\", 3); numbers.put(\"Four\", 4); System.out.println(numbers.getOrDefault(\"Five\", 0)); numbers.remove(\"Two\"); numbers.replace(\"One\",111); System.out.println(numbers.containsKey(\"Four\")); System.out.println(numbers.containsValue(111)); // Method A(Recommended!) numbers.forEach((k,v) -&gt; System.out.println(\"Item: \" + k + \" Count: \" + v)); numbers.forEach((k,v) -&gt; { System.out.println(\"Item: \" + k + \" Count: \" + v); if(\"Four\".equals(k)){ System.out.println(\"Hello Four\"); } }); // Method B(Recommended!) for (Map.Entry&lt;String, Integer&gt; entry : numbers.entrySet()) { System.out.println(\"key:\" + entry.getKey() + \".value:\" + entry.getValue()); } // Method C(NOT Recommended!) for (String string : numbers.keySet()) { System.out.println(\"key:\" + string + \".value:\" + numbers.get(string)); } // Method D(Recommended When Deleting) Iterator&lt;String&gt; iterators = numbers.keySet().iterator(); while (iterators.hasNext()) { String key = iterators.next(); System.out.println(\"key:\" + key + \".value:\" + numbers.get(key)); }}ArrayDeque：在堆栈中，元素从栈顶插入，从栈顶弹出在队列中，元素从队尾插入，从队首弹出public static void main(String[] args) { ArrayDeque&lt;String&gt; animals= new ArrayDeque&lt;&gt;(); /* *****Stack***** */ animals.push(\"Pig\"); System.out.println(\"返回栈顶元素： \" + animals.peek()); System.out.println(\"返回栈顶元素并弹出： \" + animals.pop()); /* *****Queue***** */ animals.offer(\"Horse\"); System.out.println(\"返回队首元素： \" + animals.peek()); System.out.println(\"返回队首元素并弹出： \" + animals.poll()); /* *****Deque***** */ animals.push(\"Bird\"); // 队首 animals.offer(\"Dog\"); // 队尾 System.out.println(\"返回队首元素： \" + animals.peek()); System.out.println(\"返回队首元素并弹出： \" + animals.poll()); System.out.println(\"返回队尾元素： \" + animals.peekLast()); System.out.println(\"返回队尾元素并弹出： \" + animals.pollLast()); /* *****Common***** */ System.out.println(\"判断是否包含Dog： \" + (animals.contains(\"Dog\") ? \"是\" : \"否\")); System.out.println(\"转换成数组输出： \" + Arrays.toString(animals.toArray()));}赋值和new的区别赋值是创建常量，在编译期时就被确定了；new创建的对象不是常量，无法在编译期中确定。String s0 = \"aaa\" + \"bbb\"; // 常量，同\"aaabbb\"，放入常量池中。创建了1个对象String s1 = \"aaa\" + new String(\"bbb\"); // 非常量，因为new出来的字符串无法在编译期中确定。创建了4个对象String s2 = new String(\"aaabbb\"); // 同上。由于常量池中已经存在\"aaabbb\"，因此只创建了1个对象System.out.println(s1.intern() == s0); // true，intern()函数会在常量池里找是否相同的字符串，有则返回常量池的引用System.out.println(s2.intern() == s0); // true，同上System.out.println(s0 == s1); // false，虽然内容一样，但是new出来的地址肯定不一样System.out.println(s1 == s2); // false，同上Java只有值传递，没有引用传递SEE HERE赋值是给变量绑定一个新对象，而不是改变对象。举例：public static void main(String[] args) { String x = new String(\"沉默王二\"); change(x); System.out.println(x); // \"沉默王二\"}public static void change(String x) { x = \"沉默王三\";}直接改变对象内容。举例：public static void change(A a) { a.name = \"bbb\";}public static void main(String[] args) { A a = new A(); a.name = \"aaa\"; change(a); System.out.println(a.name); // \"bbb\"}length为属性，length()为方法 数组属性：length 字符串方法：length() 集合方法：size()红黑树的时间复杂度为: O(logn)一棵含有n个节点的红黑树的高度至多为2log(n+1).See Here.同步容器同步容器主要包括2类： Vector、Stack、HashTable Collections类中提供的静态工厂方法创建的类 同步容器的所有操作并不都是线程安全的。HERE所谓“线程安全”，并不包括多个操作之间的“原子性”支持。100%的情况下不要用 StringBuffer99% 的情况下不要用 Vector那么那剩下的 1% 用 Vector 的情况在哪呢？熟悉Swing的都知道： 现有的一些 model 的类里面用了 Vector，假如你去定制它们，有时不可避免要用到 Vector。StringBuilder与StringBuffer相比，StringBuilder不是线程安全，所以单线程情况下效率更高。两者除线程安全方面之外无差别。StringBuilder sb = new StringBuilder();sb.append(\"a\".repeat(100)); // repeat方法用于构造重复String" }, { "title": "Ubuntu中关闭摄像头的自动曝光", "url": "/posts/ubuntu-camera-setting/", "categories": "Ubuntu, Camera", "tags": "camera, auto exposure", "date": "2022-05-21 13:31:32 +0800", "snippet": "目的通过Python代码关闭杰锐微通摄像头的自动曝光功能。尝试查阅相关资料，有网友提出使用以下代码：capture.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)失败。解决方案先通过在终端输入v4l2-ctl --list-devices得到摄像头列表。接着输入v4l2-ctl -d /dev/video2 --all查看单个摄像头的参数。发现最后几行中的expo...", "content": "目的通过Python代码关闭杰锐微通摄像头的自动曝光功能。尝试查阅相关资料，有网友提出使用以下代码：capture.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)失败。解决方案先通过在终端输入v4l2-ctl --list-devices得到摄像头列表。接着输入v4l2-ctl -d /dev/video2 --all查看单个摄像头的参数。发现最后几行中的exposure_auto的默认值为3，正好代表着光圈优先。将其设置为1，代表手动模式因此在代码修改为capture.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1)capture.set(cv2.CAP_PROP_EXPOSURE, 50)即可。曝光值参数可根据环境自主调节。" }, { "title": "【解决方案】NUC11锁屏后无法唤醒", "url": "/posts/nuc11-wakeup/", "categories": "NUC11", "tags": "bug, windows 10", "date": "2022-05-01 17:20:20 +0800", "snippet": "设备配置 型号：NUC11PAHi5 硬盘：Samsung 970Pro 1TB 内存：Samsung 3200MHz 8GB * 2 操作系统：Windows10 Pro 问题描述：锁屏黑屏后有一定几率无法唤醒，右侧蓝色的电源灯常亮（非呼吸灯），左侧橙色的硬盘灯不亮（正常情况下会闪），只能通过长按电源键十秒左右才能关机。解决方案：显卡驱...", "content": "设备配置 型号：NUC11PAHi5 硬盘：Samsung 970Pro 1TB 内存：Samsung 3200MHz 8GB * 2 操作系统：Windows10 Pro 问题描述：锁屏黑屏后有一定几率无法唤醒，右侧蓝色的电源灯常亮（非呼吸灯），左侧橙色的硬盘灯不亮（正常情况下会闪），只能通过长按电源键十秒左右才能关机。解决方案：显卡驱动回滚至27版本。27版本的驱动" }, { "title": "Windows任务栏时间显示秒", "url": "/posts/show-seconds-in-taskbar/", "categories": "Tutorial, Windows 10", "tags": "skills, windows 10", "date": "2022-04-22 18:17:37 +0800", "snippet": " 使用 win + r 打开运行，再输入 regedit 在打开的注册表中定位至HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced 新建 DWORD(32位)值，命名为ShowSecondsInSystemClock，将其数值置为 1 并保存。 ...", "content": " 使用 win + r 打开运行，再输入 regedit 在打开的注册表中定位至HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced 新建 DWORD(32位)值，命名为ShowSecondsInSystemClock，将其数值置为 1 并保存。 打开任务管理器重新启动Windows资源管理器即可。 " }, { "title": "Dev-C++支持C++11的操作", "url": "/posts/dev-c++11/", "categories": "IDE Configuration, Dev-C++", "tags": "dev", "date": "2022-04-17 13:51:08 +0800", "snippet": " Click Tools and Complier Options Add -std=c++11 ", "content": " Click Tools and Complier Options Add -std=c++11 " }, { "title": "MathJax 数学公式语法", "url": "/posts/mathjax/", "categories": "Tutorial, Mathjax", "tags": "getting started, syntax", "date": "2022-04-11 16:09:20 +0800", "snippet": "MathJax中的公式排版有两种方式，inline和displayed。 inline表示公式嵌入到文本段中，也称为行模式。$ f(x) = 3 \\times x $这是一个inline公式 displayed表示公式独自成为一个段落，也成为块模式。下面则是一个displayed公式。 \\[f(x) = 3 \\times x\\]符号(Operators) ...", "content": "MathJax中的公式排版有两种方式，inline和displayed。 inline表示公式嵌入到文本段中，也称为行模式。$ f(x) = 3 \\times x $这是一个inline公式 displayed表示公式独自成为一个段落，也成为块模式。下面则是一个displayed公式。 \\[f(x) = 3 \\times x\\]符号(Operators) Symbol Command Symbol Command Symbol Command $\\pm$ \\pm $\\mp$ \\mp $\\times$ \\times $\\div$ \\div $\\cdot$ \\cdot $\\ast$ \\ast $\\star$ \\star $\\dagger$ \\dagger $\\ddagger$ \\ddagger $\\amalg$ \\amalg $\\cap$ \\cap $\\cup$ \\cup $\\uplus$ \\uplus $\\sqcap$ \\sqcap $\\sqcup$ \\sqcup $\\vee$ \\vee $\\wedge$ \\wedge $\\oplus$ \\oplus $\\ominus$ \\ominus $\\otimes$ \\otimes $\\circ$ \\circ $\\bullet$ \\bullet $\\diamond$ \\diamond $\\lhd$ \\lhd $\\rhd$ \\rhd $\\unlhd$ \\unlhd $\\unrhd$ \\unrhd $\\oslash$ \\oslash $\\odot$ \\odot $\\bigcirc$ \\bigcirc $\\triangleleft$ \\triangleleft $\\Diamond$ \\Diamond $\\bigtriangleup$ \\bigtriangleup $\\bigtriangledown$ \\bigtriangledown $\\Box$ \\Box $\\triangleright$ \\triangleright $\\setminus$ \\setminus $\\wr$ \\wr $\\sqrt{x}$ \\sqrt{x} $x^{\\circ}$ x^{\\circ} $\\triangledown$ \\triangledown $\\sqrt[n]{x}$ \\sqrt[n]{x} $a^x$ a^x $a^{xyz}$ a^{xyz} $\\frac{x}{y}$ \\frac{x}{y} $\\sin{x}$ \\sin{x} $\\cos{x}$ \\cos{x} $\\tan{x}$ \\tan{x} $\\log_xy$ \\log_xy $\\ln{x}$ \\ln{x} $\\max(x,y,z)$ \\max(x,y,z) 求和：\\sum\\limits_{i=0}^n{a_i} 显示为$\\sum\\limits_{i=0}^n{a_i}$ 求积：\\prod\\limits_{i=0}^n{\\frac{1}{i^2}} 显示为$\\prod\\limits_{i=0}^n{\\frac{1}{i^2}}$ 积分：\\int_0^xf(x)dx显示为$\\int_0^xf(x)dx$ 极限：\\lim\\limits_{x\\to 0}{x} 显示为$\\lim\\limits_{x\\to 0}{x}$ 自定义符号：\\mathop{SUPER}\\limits_{i=0}^n{i^2} 显示为$\\mathop{SUPER}\\limits_{i=0}^n{i^2}$关系(Relations) Symbol Command Symbol Command Symbol Command $\\le $ \\le $\\ge $ \\ge $\\neq $ \\neq $\\sim $ \\sim $\\ll $ \\ll $\\gg $ \\gg $\\doteq $ \\doteq $\\simeq $ \\simeq $\\subset $ \\subset $\\supset $ \\supset $\\approx $ \\approx $\\asymp $ \\asymp $\\subseteq $ \\subseteq $\\supseteq $ \\supseteq $\\cong $ \\cong $\\smile $ \\smile $\\sqsubset $ \\sqsubset $\\sqsupset $ \\sqsupset $\\equiv $ \\equiv $\\frown $ \\frown $\\sqsubseteq $ \\sqsubseteq $\\sqsupseteq$ \\sqsupseteq $\\propto $ \\propto $\\bowtie $ \\bowtie $\\in $ \\in $\\ni $ \\ni $\\prec $ \\prec $\\succ $ \\succ $\\vdash $ \\vdash $\\dashv $ \\dashv $\\preceq $ \\preceq $\\succeq $ \\succeq $\\models $ \\models $\\perp $ \\perp $\\parallel $ \\parallel     $\\mid $ \\mid $\\bumpeq $ \\bumpeq     上面这些关系符号的否定(反义)形式可以通过在原符号前添加 \\not 来进行实现，或者在 \\ 和符号单词之间添加 n 来实现。下面列出几个常用的否定形式，其他符号的否定形式规则基本类似。 Symbol Command Symbol Command Symbol Command $\\nmid $ \\nmid $\\nleq $ \\nleq $\\ngeq $ \\ngeq $\\nsim $ \\nsim $\\ncong $ \\ncong $\\nparallel $ \\nparallel $\\not&lt; $ \\not&lt; $\\not&gt; $ \\not&gt; $\\not= $ \\not= $\\not\\le $ \\not\\le $\\not\\ge $ \\not\\ge $\\not\\sim $ \\not\\sim $\\not\\approx $ \\not\\approx $\\not\\cong $ \\not\\cong $\\not\\equiv $ \\not\\equiv $\\not\\parallel $ \\not\\parallel $\\nless $ \\nless $\\ngtr $ \\ngtr $\\lneq $ \\lneq $\\gneq $ \\gneq $\\lnsim $ \\lnsim $\\lneqq $ \\lneqq $\\gneqq $ \\gneqq     像 =, &gt;, 和 &lt; 并没有列在上面的符号，可以直接字面输入，并不需要命令进行触发。希腊字母(Greek Letters)小写： Symbol Command Symbol Command Symbol Command $\\alpha $ \\alpha $ \\beta $ \\beta $\\gamma $ \\gamma $\\epsilon $ \\epsilon $ \\varepsilon $ \\varepsilon $\\zeta $ \\zeta $\\theta $ \\theta $ \\vartheta $ \\vartheta $\\iota $ \\iota $\\lambda $ \\lambda $ \\mu $ \\mu $\\nu $ \\nu $\\pi $ \\pi $ \\varpi $ \\varpi $\\rho $ \\rho $\\sigma $ \\sigma $ \\varsigma $ \\varsigma $\\tau $ \\tau $\\phi $ \\phi $ \\varphi $ \\varphi $\\chi $ \\chi $\\omega $ \\omega $ \\varrho $ \\varrho $\\kappa $ \\kappa $\\delta $ \\delta $ \\upsilon $ \\upsilon $\\xi $ \\xi $\\eta $ \\eta $ \\psi $ \\psi     大写： Symbol Command Symbol Command Symbol Command $\\Gamma $ \\Gamma $\\Delta $ \\Delta $ \\Theta $ \\Theta $\\Xi $ \\Xi $\\Pi $ \\Pi $ \\Sigma $ \\Sigma $\\Phi $ \\Phi $\\Psi $ \\Psi $ \\Omega $ \\Omega $\\Lambda $ \\Lambda $\\Upsilon $ \\Upsilon     斜体大写： Symbol Command Symbol Command Symbol Command $\\varGamma $ \\varGamma $\\varDelta $ \\varDelta $ \\varTheta $ \\varTheta $\\varXi $ \\varXi $\\varPi $ \\varPi $ \\varSigma $ \\varSigma $\\varPhi $ \\varPhi $\\varPsi $ \\varPsi $ \\varOmega $ \\varOmega $\\varLambda $ \\varLambda $\\varUpsilon $ \\varUpsilon     箭头(Arrors) Symbol Command Symbol Command $\\gets $ \\gets $\\to $ \\to $\\leftarrow $ \\leftarrow $\\Leftarrow $ \\Leftarrow $\\rightarrow $ \\rightarrow $\\Rightarrow $ \\Rightarrow $\\leftrightarrow $ \\leftrightarrow $\\Leftrightarrow $ \\Leftrightarrow $\\mapsto $ \\mapsto $\\hookleftarrow $ \\hookleftarrow $\\leftharpoonup $ \\leftharpoonup $\\leftharpoondown $ \\leftharpoondown $\\rightleftharpoons $ \\rightleftharpoons $\\longleftarrow $ \\longleftarrow $\\Longleftarrow $ \\Longleftarrow $\\longrightarrow $ \\longrightarrow $\\Longrightarrow $ \\Longrightarrow $\\longleftrightarrow$ \\longleftrightarrow $\\Longleftrightarrow $ \\Longleftrightarrow $\\longmapsto $ \\longmapsto $\\hookrightarrow $ \\hookrightarrow $\\rightharpoonup $ \\rightharpoonup $\\rightharpoondown $ \\rightharpoondown $\\leadsto $ \\leadsto $\\uparrow $ \\uparrow $\\Uparrow $ \\Uparrow $\\downarrow $ \\downarrow $\\Downarrow $ \\Downarrow $\\updownarrow $ \\updownarrow $\\Updownarrow $ \\Updownarrow $\\nearrow $ \\nearrow $\\searrow $ \\searrow $\\swarrow $ \\swarrow $\\nwarrow $ \\nwarrow 有些箭头指令, mathjax 提供了缩写指令, $\\iff$(\\iff) 和 $\\implies$(\\implies) 可以分别表示为 $\\Longleftrightarrow$(\\Longleftrightarrow) 和 $\\Longrightarrow$(\\Longrightarrow)重音(Accents) Symbol Command Symbol Command Symbol Command $\\hat{x} $ \\hat{x} $\\check{x} $ \\check{x} $\\dot{x} $ \\dot{x} $\\breve{x}$ \\breve{x} $\\acute{x} $ \\acute{x} $\\ddot{x} $ \\ddot{x} $\\grave{x}$ \\grave{x} $\\tilde{x} $ \\tilde{x} $\\mathring{x} $ \\mathring{x} $\\bar{x} $ \\bar{x} $\\vec{x} $ \\vec{x} $\\overline{x} $ \\overline{x} $\\widehat{7+x}$ \\widehat{7+x} $\\widetilde{abc}$ \\widetilde{abc}     \\tilde 和 \\hat 两个指令有宽符号的版本。上述表格最后一行，\\widetilde 和 \\widehat，通过这两个指令可以生成长版本的表达式结构的符号。方程组(Equation Sets)$$f(n) = \\tag{1}\\begin{cases}\\frac{a_n^3}{2}, &amp; \\text{if $n$ is even} \\\\ 3a_n^2+1, &amp; \\text{if $n$ is odd}\\end{cases}$$\\[f(n) = \\tag{1}\\begin{cases}\\frac{a_n^3}{2}, &amp; \\text{if $n$ is even} \\\\ 3a_n^2+1, &amp; \\text{if $n$ is odd}\\end{cases}\\]字体(Fonts) 打印机字体Typewriter：\\mathtt{R} 显示为$\\mathtt{R}$ 黑板粗体字Blackboard Bold：\\mathbb{R} 显示为$\\mathbb{R}$。表示实数集的意思。 无衬线字体Sans Serif：\\mathsf{R} 显示为$\\mathsf{R}$ 手写体Script：\\mathscr{R} 显示为$\\mathscr{R}$ 罗马字体Roman：\\mathrm{R} 显示为$\\mathrm{R}$点(Dots) Symbol Command Symbol Command $\\cdot $ \\cdot $\\vdots $ \\vdots $\\dots $ \\dots $\\ddots $ \\ddots $\\cdots$ \\cdots $\\ldots $ \\ldots \\ldots 和 \\cdots 是低位置省略号和中心位置省略号的 latex 命令, \\dots 是 amsmath 命令用来试图帮你在 \\ldots 和 \\cdots 中自动做决断的。通常来讲中心省略 \\cdots 一般用在数学模式的中心线上的符号后面，例如加号 + 或者右箭头 -&gt; , 而 \\ldots 一般用在标点符号的后面，例如句号“ . ” or逗号“ , ”。例如，$ a + b + \\cdots + z \\quad a_1, \\ldots, a_n $ 显示为$ a + b + \\cdots + z \\quad a_1, \\ldots, a_n $改为\\dots便可以根据实际情况自动地改变省略号的位置$ a + b + \\dots + z \\quad a_1, \\dots, a_n $ 显示为$ a + b + \\dots + z \\quad a_1, \\dots, a_n $使用\\dots基本可以满足要求。但是，\\dots 并不是每次都能正确自动改变省略号的位置，所以还是需要根据自己的实际情况选择不同的dots。矩阵(Matrices) 小括号边框：pmatrix 中括号边框：bmatrix 大括号边框：Bmatrix 单竖线边框：vmatrix 双竖线边框：Vmatrix$$\\begin{bmatrix}{a_{11}}&amp;{a_{12}}&amp;{\\cdots}&amp;{a_{1n}}\\\\{a_{21}}&amp;{a_{22}}&amp;{\\cdots}&amp;{a_{2n}}\\\\{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\{a_{m1}}&amp;{a_{m2}}&amp;{\\cdots}&amp;{a_{mn}}\\\\\\end{bmatrix}$$\\[\\begin{bmatrix}{a_{11}}&amp;{a_{12}}&amp;{\\cdots}&amp;{a_{1n}}\\\\{a_{21}}&amp;{a_{22}}&amp;{\\cdots}&amp;{a_{2n}}\\\\{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\{a_{m1}}&amp;{a_{m2}}&amp;{\\cdots}&amp;{a_{mn}}\\\\\\end{bmatrix}\\]界限符号(Bracketing Symbols)在数学公式里，有时我们会通过括号( (), [], {} )进行界线控制。这些符号有些是可以直接输入，比如 (), [], | 等，而有些符号是要经过转义的，下面列出了这些比较特殊的符号。 Symbol Command Symbol Command $\\lfloor $ \\lfloor $\\rfloor $ \\rfloor $\\lceil $ \\lceil $\\rceil $ \\rceil $\\langle $ \\langle $\\rangle $ \\rangle 上括号$ \\overbrace{a_0+a_1+a_2+\\cdots+a_n}^{x} $，显示为$ \\overbrace{a_0+a_1+a_2+\\cdots+a_n}^{x} $下括号$ \\underbrace{a_0+a_1+a_2+\\cdots+a_n}_{x} $，显示为$ \\underbrace{a_0+a_1+a_2+\\cdots+a_n}_{x} $但是有时候界限符号不够高，所以需要一些自适应括号，比如$ (\\frac{a}{x} )^2 $，显示为\\[(\\frac{a}{x} )^2\\]使用自适应括号的代码为$ \\left(\\frac{a}{x} \\right)^2 $，显示为\\[\\left(\\frac{a}{x} \\right)^2\\]但是也只有在块模式的时候会比较明显。其他(Others) Symbol Command Symbol Command Symbol Command $\\infty $ \\infty $ \\triangle $ \\triangle $\\angle $ \\angle $\\aleph $ \\aleph $ \\hbar $ \\hbar $\\imath $ \\imath $\\jmath $ \\jmath $ \\ell $ \\ell $\\wp $ \\wp $\\Re $ \\Re $ \\Im $ \\Im $\\mho $ \\mho $\\prime $ \\prime $ \\emptyset $ \\emptyset $\\nabla $ \\nabla $\\surd $ \\surd $ \\partial $ \\partial $\\top $ \\top $\\bot $ \\bot $ \\vdash $ \\vdash $\\dashv $ \\dashv $\\forall $ \\forall $ \\exists $ \\exists $\\neg $ \\neg $\\flat $ \\flat $ \\natural $ \\natural $\\sharp $ \\sharp $\\backslash$ \\backslash $ \\Box $ \\Box $\\Diamond $ \\Diamond $\\clubsuit $ \\clubsuit $ \\diamondsuit $ \\diamondsuit $\\heartsuit $ \\heartsuit $\\spadesuit$ \\spadesuit $ \\Join $ \\Join $\\blacksquare$ \\blacksquare $\\bigstar $ \\bigstar $ \\in $ \\in $\\cup $ \\cup $\\square $ \\square $ \\S $ \\S $\\checkmark $ \\checkmark $\\because $ \\because $ \\therefore $ \\therefore     " }, { "title": "Difference between NEW and MALLOC in C++", "url": "/posts/new-and-malloc/", "categories": "C++", "tags": "c++, new, malloc", "date": "2022-03-31 16:48:53 +0800", "snippet": "Difference1. 属性 new/delete是C++关键字，需要编译器支持。 malloc/free是库函数，需要头文件支持。 2. 参数 new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。 而malloc则需要显式地指出所需内存的尺寸。 3. 返回类型 new操作符内存分配成功时，返回的是对象...", "content": "Difference1. 属性 new/delete是C++关键字，需要编译器支持。 malloc/free是库函数，需要头文件支持。 2. 参数 new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。 而malloc则需要显式地指出所需内存的尺寸。 3. 返回类型 new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。 而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。 4. 分配失败 new内存分配失败时，会抛出bac_alloc异常。 malloc分配内存失败时返回NULL。 5. 自定义类型 new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。 malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。 6. 重载 C++允许重载new/delete操作符，特别的，布局new的就不需要为对象分配内存，而是指定了一个地址作为内存起始区域，new在这段内存上为对象调用构造函数完成初始化工作，并返回此地址。 而malloc不允许重载。 7. 内存区域 new操作符从自由存储区（free store）上为对象动态分配内存空间。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。 而malloc函数从堆上动态分配内存。堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区不等于堆，如上所述，布局new就可以不位于堆中。 8. 重新分配内存 new没有扩张内存的机制。 而malloc分配内存后，如果发现内存不够用，可以通过realloc函数来扩张内存大小，realloc会先判断当前申请的内存后面是否还有足够的内存空间进行扩张，如果有足够的空间，那么就会往后面继续申请空间，并返回原来的地址指针；否则realloc会在另外有足够大小的内存申请一块空间，并将当前内存空间里的内容拷贝到新的内存空间里，最后返回新的地址指针。 Code以下是 vector, vector with reserve, array, malloc, new 这几种不同创建并销毁数据的方法的运行时间对比代码。根据运行结果可以大致得到：$T_{array} \\approx T_{malloc} \\approx T_{new} &lt; T_{vector-with-reserve} &lt; T_{vector}$#include&lt;bits/stdc++.h&gt;#include &lt;windows.h&gt;using namespace std;int main(){\tcout&lt;&lt;\"=====Runing time of program=====\" &lt;&lt;endl;\t// vector\t\tDWORD start = GetTickCount();\tint t = 100;\tint n = 200000;\twhile (t)\t{\t\tvector&lt;int&gt; a;\t\tfor(int i=0;i&lt;n;i++) a.push_back(i);\t\tt--;\t}\tcout&lt;&lt;\"Vector: \"&lt;&lt;GetTickCount() - start&lt;&lt;endl;\t// vector with reserve\tstart = GetTickCount();\tt = 100;\tn = 200000;\twhile (t)\t{\t\tvector&lt;int&gt; b;\t\tb.reserve(n);\t\tfor(int i=0;i&lt;n;i++) b.push_back(i);\t\tt--;\t}\tcout&lt;&lt;\"Vector with reserve: \"&lt;&lt;GetTickCount() - start&lt;&lt;endl;\t// array\tstart = GetTickCount();\tt = 100;\tn = 200000;\twhile (t)\t{\t\tint a[200000];\t\tfor(int i=0;i&lt;n;i++) a[i]=i;\t\tt--;\t}\tcout&lt;&lt;\"Array: \"&lt;&lt;GetTickCount() - start&lt;&lt;endl;\t// malloc\tstart = GetTickCount();\tt = 100;\tn = 200000;\twhile (t)\t{\t\tint *p = (int *)malloc((n+1) * sizeof(int));\t\tfor(int i=0;i&lt;n;i++) p[i]=i;\t\tfree(p);\t\tt--;\t}\tcout&lt;&lt;\"Malloc: \"&lt;&lt;GetTickCount()-start&lt;&lt;endl;\t\t\t// new\tstart = GetTickCount();\tt = 100;\tn = 200000;\twhile (t)\t{\t\tint *p=new int[n+1];\t\tfor(int i=0;i&lt;n;i++) p[i]=i;\t\tdelete []p;\t\tt--;\t}\tcout&lt;&lt;\"New: \"&lt;&lt;GetTickCount() - start&lt;&lt;endl;\t}ConclusionReference new与malloc的10点区别 C++ 自由存储区是否等价于堆？" }, { "title": "C++中静态成员及静态成员函数详解", "url": "/posts/static/", "categories": "C++", "tags": "c++, static", "date": "2022-03-18 11:40:41 +0800", "snippet": "1. 局部静态变量局部静态变量用于函数体内部修饰变量，这种变量的生存期长于该函数。用法：局部变量前加static，修饰局部变量为静态局部变量。作用：改变局部变量的销毁时期。作用域：局部作用域，当定义它的函数或语句块结束的时候，作用域结束。与局部变量的区别： 静态局部变量在全局数据区（静态存储区）分配内存(局部变量在栈区分配内存)； 静态局部变量在程序执行到该对象的声明处时被首次初始化，即...", "content": "1. 局部静态变量局部静态变量用于函数体内部修饰变量，这种变量的生存期长于该函数。用法：局部变量前加static，修饰局部变量为静态局部变量。作用：改变局部变量的销毁时期。作用域：局部作用域，当定义它的函数或语句块结束的时候，作用域结束。与局部变量的区别： 静态局部变量在全局数据区（静态存储区）分配内存(局部变量在栈区分配内存)； 静态局部变量在程序执行到该对象的声明处时被首次初始化，即以后的函数调用不再进行初始化(局部变量每次函数调用都会被初始化)； 静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0(局部变量不会被初始化)； 它始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，也就是不能在函数体外面使用它(局部变量在栈区，在函数结束后立即释放内存)； 当静态局部变量离开作用域后，并没有被销毁。当该函数再次被调用的时候，该变量的值为上次函数调用结束时的值（局部变量离开作用域便被销毁，再次调用函数时，其值为初始值）。与全局变量的区别：同样是初始化一次，连续调用fun()的结果是一样的，但是，使用全局变量的话，变量就不属于函数本身了，不再仅受函数的控制，给程序的维护带来不便。静态局部变量正好可以解决这个问题。静态局部变量保存在全局数据区，而不是保存在栈中，每次的值保持到下一次调用，直到下次赋新值。Code:#include&lt;stdio.h&gt;int fun(void){\tstatic int count = 20; // 只能在该函数内修改静态局部变量的值\treturn count--;}int main() {\tprintf(\"global\\t\\tlocal static\\n\");\tint count = 1;\tfor(; count &lt;= 10; ++count) printf(\"%d\\t\\t%d\\n\", count, fun());}运行结果图2. 全局静态变量全局静态变量定义在函数体外，该变量只在本文件可见。用法：全局变量前加static，修饰全局变量为静态全局变量。作用：改变全局变量的可见性。静态全局变量的存储位置在静态存储区，未被初始化的静态全局变量会被自动初始化为0。作用域：全局静态变量在声明他的文件之外是不可见的，仅在从定义该变量的开始位置到文件结尾可见。特点： 静态全局变量不能被其它文件所用(全局变量可以)； 其它文件中可以定义相同名字的变量，不会发生冲突。Code:以下两个文件要放到项目工程里才有效果。//file a.cpp //static int n = 15; // ERROR!因为static隔离了文件。int n = 15;//file main.cpp#include &lt;iostream&gt;//#include\"a.cpp\" //不管有没有static，加include都不会报错using namespace std;extern int n;void fn(){\tn++;}int main() {\tcout&lt;&lt;\"Before:\" &lt;&lt;n&lt;&lt;endl;\tfn();\tcout&lt;&lt;\"After:\" &lt;&lt;n&lt;&lt;endl;\treturn 0;}运行结果图3. 静态函数静态函数的作用与2. 静态全局变量类似。特点也类似：不能被其他文件所用；其它文件中可以定义相同名字的变量，不会发生冲突。用法：函数返回类型前加static，修饰函数为静态函数。作用：改变函数的可见性。函数的定义和声明在默认情况下都是extern的，但静态函数只在声明它的文件中可见，不能被其他文件使用。4. 静态成员用法：类成员前加static，修饰类的成员为类的静态成员。作用：实现多个对象之间的数据共享，并且使用静态成员不会破坏封装性，也保证了安全性。Code:#include&lt;iostream&gt;using namespace std;class Rectangle{private: int m_w,m_h; static int s_sum;public: Rectangle(int w,int h) { this-&gt;m_w = w; this-&gt;m_h = h; s_sum += (this-&gt;m_w * this-&gt;m_h); } void GetSum() { cout&lt;&lt;\"sum = \"&lt;&lt;s_sum&lt;&lt;endl; }};int Rectangle::s_sum = 0; //静态成员类外初始化，因为其属于类，不属于类对象int main(){ cout&lt;&lt;\"sizeof(Rectangle)=\"&lt;&lt;sizeof(Rectangle)&lt;&lt;endl; Rectangle *rect1 = new Rectangle(3,4); rect1-&gt;GetSum(); cout&lt;&lt;\"sizeof(rect1)=\"&lt;&lt;sizeof(*rect1)&lt;&lt;endl; Rectangle rect2(2,3); rect2.GetSum(); cout&lt;&lt;\"sizeof(rect2)=\"&lt;&lt;sizeof(rect2)&lt;&lt;endl;}sizeof(Rectangle)=8sum = 12sizeof(rect1)=8sum = 12sizeof(rect1)=8由此可知：sizeof(Rectangle) = 8bytes = sizeof(m_w) + sizeof(m_h)。也就是说静态数据成员并不占用Rectangle的内存空间。因为静态数据成员在全局数据区(静态区)分配内存。再看看GetSum()，第一次12 = 3 * 4，第二次18 = 12 + 2 * 3。因此，静态数据成员只会被初始化一次，与对象无关。结论：静态数据成员被当作是类的成员，由该类型的所有对象共享访问，对该类的多个对象来说，静态数据成员只分配一次内存。静态数据成员存储在全局数据区。静态数据成员定义时要分配空间，所以不能在类声明中定义。从某种程度上来说，静态数据成员与静态变量相类似。5. 静态成员函数用法：类函数前加static，修饰类的函数为静态函数。作用：减少资源消耗，不需要实例化就可以使用Code:#include&lt;iostream&gt;using namespace std;class Rectangle{private: int m_w,m_h; static int s_sum;public: Rectangle(int w,int h) { this-&gt;m_w = w; this-&gt;m_h = h; s_sum += (this-&gt;m_w * this-&gt;m_h); } static void GetSum() // 此处为静态成员函数 { cout&lt;&lt;\"sum = \"&lt;&lt;s_sum&lt;&lt;endl; }};int Rectangle::s_sum = 0; //静态成员类外初始化，因为其属于类，不属于类对象int main(){ cout&lt;&lt;\"sizeof(Rectangle)=\"&lt;&lt;sizeof(Rectangle)&lt;&lt;endl; Rectangle *rect1 = new Rectangle(3,4); rect1-&gt;GetSum(); cout&lt;&lt;\"sizeof(rect1)=\"&lt;&lt;sizeof(*rect1)&lt;&lt;endl; Rectangle rect2(2,3); rect2.GetSum(); //可以用对象名.函数名访问 cout&lt;&lt;\"sizeof(rect2)=\"&lt;&lt;sizeof(rect2)&lt;&lt;endl; Rectangle::GetSum(); //也可以可以用类名::函数名访问}结论： 非静态成员函数可访问静态成员函数/成员； 静态成员函数不能访问非静态成员函数/成员，只能访问静态成员函数/变量； 调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指针调用静态成员函数，也可以用类名::函数名调用。 另外，既然是在类里操作，对类成员的访问还是要遵从public，protected，private访问规则。6. 静态变量内存分配和初始化全局变量、文件域的静态变量和类的静态成员变量在main执行之前的静态初始化过程中分配内存并初始化；局部静态变量（一般为函数内的静态变量）在第一次使用时分配内存并初始化。这里的变量包含内置数据类型和自定义类型的对象。7. static关键字的好处7.1 隐藏变量或函数、隔离错误，有利于模块化程序在编程中，难免会用到全局变量，全局变量的作用域是整个源程序，当一个源程序由多个源文件组成时，全局变量在所有的源文件中都是有效的。如果希望全局变量仅限于在本源文件中使用，在其他源文件中不能引用，也就是说限制其作用域只在定义该变量的源文件内有效，而在同一源程序的其他源文件中不能使用，这时，就可以通过在全局变量上加static来实现，使全局变量被定义成一个静态全局变量。这样就可以避免其他源文件使用该变量、避免其他源文件因为该变量引起的错误。起到了对其他源文件隐藏该变量和隔离错误的作用，有利于模块化程序。7.2 保持变量内容的持久性有时候，我们希望函数中局部变量的值在函数调用结束之后不会消失，仍然保留函数调用结束的值。即它所在的存储单元不释放。这时，应该将该局部变量用关关键字static声明为静态局部变量。当局部变量被声明为静态局部变量的时候，也就改变了局部变量的存储位置，从原来的栈中存放改为静态存储区存放，全局变量也存放在静态存储区，静态局部变量与全局变量的主要区别就在于可见性，静态局部变量只在其被声明的代码块中是可见的。" }, { "title": "C++中vector的初始化及赋值方式", "url": "/posts/c++-vector-init/", "categories": "C++", "tags": "c++, vector", "date": "2022-03-17 19:39:44 +0800", "snippet": "一维向量1. 不带参数的构造函数初始化//初始化一个size为0的vectorvector&lt;int&gt; abc;2. 带参数的构造函数初始化//初始化size,但每个元素值为默认值vector&lt;int&gt; abc(10); //初始化了10个默认值为0的元素//初始化size,并且设置初始值vector&lt;int&gt; cde(10, 1); /...", "content": "一维向量1. 不带参数的构造函数初始化//初始化一个size为0的vectorvector&lt;int&gt; abc;2. 带参数的构造函数初始化//初始化size,但每个元素值为默认值vector&lt;int&gt; abc(10); //初始化了10个默认值为0的元素//初始化size,并且设置初始值vector&lt;int&gt; cde(10, 1); //初始化了10个值为1的元素3. 通过数组地址初始化int a[5] = {1, 2, 3, 4, 5};//通过数组a的地址初始化，注意地址是从0到5（左闭右开区间）vector&lt;int&gt; b(a, a + 5);4. 通过同类型的vector初始化（深拷贝，即不共享数据）vector&lt;int&gt; a(5, 1);//通过a初始化vector&lt;int&gt; b(a);5. 通过insert初始化//insert初始化方式将同类型的迭代器对应的始末区间（左闭右开区间）内的值插入到vector中vector&lt;int&gt; a(6, 6);vecot&lt;int&gt; b;//将a[0]~a[2]插入到b中，b.size()由0变为3b.insert(b.begin(), a.begin(), a.begin() + 3);insert也可通过数组地址区间实现插入int a[6] = {6, 6, 6, 6, 6, 6};vector&lt;int&gt; b;//将a的所有元素插入到b中b.insert(b.begin(), a, a + 6);此外，insert还可以插入m个值为n的元素//在b开始位置处插入3个6b.insert(b.begin(), 3, 6);6. 通过copy函数赋值vector&lt;int&gt; a(5, 1);int a1[5] = {2, 2, 2, 2, 2};vector&lt;int&gt; b(10);/*将a中元素全部拷贝到b开始的位置中,注意拷贝的区间为a.begin() ~ a.end()的左闭右开的区间*/copy(a.begin(), a.end(), b.begin());//拷贝区间也可以是数组地址构成的区间copy(a1, a1 + 5, b.begin() + 5);二维向量1. 向量 + 向量（常用方法）vector&lt;vector&lt;int&gt; &gt; myv(row, vector&lt;int&gt;(column,0));vector&lt;vector&lt;int&gt; &gt; myv(5, vector&lt;int&gt;(10,0)); // 两个维度都是向量cout&lt;&lt;myv.size()&lt;&lt;endl; // 正确，因为向量有size()函数vector&lt;int&gt; temp(2);myv.push_back(temp); // 正确，可以将向量插入到向量中或者：vector&lt;vector&lt;int&gt; &gt; myv(5); // 两个维度都是向量，只是第二个维度的向量长度为0cout&lt;&lt;myv.size()&lt;&lt;endl; // 5cout&lt;&lt;myv[0].size()&lt;&lt;endl; // 0vector&lt;vector&lt;int&gt;&gt; v(5) 大于号之间没有空格的初始化方式在C++11之后也是正确的，即C++11以后允许两个大于号之间没有空格。C++11是一种标准。2. 数组 + 向量（不建议）vector&lt;int&gt; myv[n]; // 此时第一维是数组，第二维才是向量。// cout&lt;&lt;myv.size()&lt;&lt;endl; // 错误，因为数组没有size()函数vector&lt;int&gt; temp(2);myv.push_back(temp); // 错误，无法将向量插入到数组中" }, { "title": "C++知识点整理及常见STL函数的使用", "url": "/posts/C++Syntax/", "categories": "C++", "tags": "stl, c++, syntax", "date": "2022-03-13 17:33:45 +0800", "snippet": "本篇博客不阐述原理，只是记录一些知识点以及常用的C++函数代码。知识点整理点运算符和箭头运算符这两个符号都是C++成员运算符1，主要用于确定类对象和成员之间的关系，用于引用类、结构和共用体的成员。箭头运算符-&gt;与一个指针对象的指针一起使用。如果是指针访问数据成员或成员函数，用-&gt;;点运算符.与实际的对象一起使用。如果是某个数据类型的对象，访问自己的数据成员和成员函数用.;举个例子...", "content": "本篇博客不阐述原理，只是记录一些知识点以及常用的C++函数代码。知识点整理点运算符和箭头运算符这两个符号都是C++成员运算符1，主要用于确定类对象和成员之间的关系，用于引用类、结构和共用体的成员。箭头运算符-&gt;与一个指针对象的指针一起使用。如果是指针访问数据成员或成员函数，用-&gt;;点运算符.与实际的对象一起使用。如果是某个数据类型的对象，访问自己的数据成员和成员函数用.;举个例子：string s1 = \"a string\",*p = &amp;s1;int n = s1.size(); //运行string对象s1的size()成员n = (*p).size(); //运行p所指对象的size成员n = p-&gt;size(;) //等价于(*p).size左移右移运算符左移乘，右移除bitset.count()函数用于统计二进制数中1的数量。__builtin_popcount()函数也可以统计二进制中1的数量。#include&lt;bits/stdc++.h&gt;using namespace std;int main() { unsigned short short1 = 4; bitset&lt;16&gt; bitset1(short1); // the bitset representation of 4 cout &lt;&lt; bitset1 &lt;&lt; endl; // 0b00000000'00000100 unsigned short short2 = short1 &lt;&lt; 1; // 4 left-shifted by 1 = 8 bitset&lt;16&gt; bitset2(short2); cout &lt;&lt; bitset2 &lt;&lt; endl; // 0b00000000'00001000 unsigned short short3 = short1 &gt;&gt; 2; // 4 right-shifted by 2 = 1 bitset&lt;16&gt; bitset3(short3); cout &lt;&lt; bitset3 &lt;&lt; endl; // 0b00000000'00000001 int int1 = 5; bitset&lt;4&gt; bitset4(int1);\t\t\t// 0b1001 cout &lt;&lt; bitset4.count() &lt;&lt; endl;\t// number of set bits in bitset4 = 2 cout &lt;&lt; __builtin_popcount(5) &lt;&lt; endl;\t// same as above}前中后序遍历前序(preorder): 根结点 -&gt; 遍历左子树 -&gt; 遍历右子树 （首先访问根结点）中序(inorder): 遍历左子树 -&gt; 根结点 -&gt; 遍历右子树后序(postorder): 遍历左子树 -&gt; 遍历右子树 -&gt; 根结点 （最后访问根结点）约瑟夫环简介：n 个人围成一个圈，每次数 k 个数，被数到的那个人出局。数学解法：int findTheWinner(int n, int k) { int p = 0; for (int i = 2; i &lt;= n; i++) { p = (p + k) % i; } return p + 1;}队列：int findTheWinner(int n, int k) { queue&lt;int&gt; q; for(int i = 0; i &lt; n; i++) q.push(i + 1); while(q.size() != 1){ for(int i = 0; i &lt; k - 1; i++){ q.push(q.front()); q.pop(); } q.pop(); } return q.front();}常见STL函数的使用STL: Standard Template Librarylistemplace可以代替insert.emplace_back可以代替push_back.emplace_front可以代替push_front.mylist.front()mylist.back()mylist.begin()mylist.end()mylist.empty()mylist.erase()mylist.remove()mylist.insert()mylist.pop_back()mylist.pop_front()mylist.push_back()mylist.push_front()mylist.reverse()mylist.sort()mylist.unique()vectoremplace可以代替insert.emplace_back可以代替push_back.emplace_front可以代替push_front.myvector.front()myvector.back()myvector.size()myvector.begin()myvector.end()for(vector&lt;int&gt;::iterator it = myvector.begin();it!=myvector.end();it++){ cout&lt;&lt;*it&lt;&lt;endl;}myvector.clear()myvector.pop_back()myvector.push_back()myvector.empty()myvector.insert()queueemplace可以代替pushmyqueue.push()myqueue.pop()myqueue.empty()myqueue.size()myqueue.front()myqueue.back()stackemplace可以代替pushmystack.empty()mystack.pop()mystack.push()mystack.size()mystack.top() //栈顶，即出入口map &amp; unordered_mapemplace可以代替insert// 不需要对key进行排列或数据量不小于10000的时候，用unordered_map.unordered_map&lt;char,int&gt; mymap;mymap['a'] = 100;mymap['b'] = 200;for(map&lt;char,int&gt;::iterator it = mymap.begin();it != mymap.end(); it++){ cout&lt;&lt;it-&gt;first&lt;&lt;\" =&gt; \" &lt;&lt;it-&gt;second&lt;&lt;endl;}mymap.size()mymap.clear()mymap.count(k) //return 1 if found or 0 otherwisemymap.erase(key)mymap.erase(iterator first,iterator last)it = mymap.find('b')mymap.insert()set &amp; unordered_setemplace可以代替insertunordered_set&lt;int&gt; myset;unordered_set&lt;pair&lt;int, string&gt;&gt; myset;priority_queue优先队列与堆类似。默认大顶堆。 和队列基本操作相同: top() 访问队头元素 empty() 队列是否为空 size() 返回队列内元素个数 push() 插入元素到队尾 (并排序) emplace() 原地构造一个元素并插入队列 pop() 弹出队头元素 //大顶堆，即降序队列priority_queue&lt;int&gt; big_heap;priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt; &gt; big_heap2; //小顶堆，即升序队列priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt; small_heap; pair的比较，先比较第一个元素，第一个相等比较第二个//大顶堆，即降序队列priority_queue&lt;pair&lt;int, int&gt; &gt; big_pair_heap;//小顶堆，即升序队列priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;&gt;&gt; small_pair_heap;lower_boundlower_bound()和upper_bound()是利用二分查找的方法在一个排好序的容器中进行查找，比如set,vector,map容器。具体用法如下所示： lower_bound(value): 第一个大于等于（可以是字典序，也可以是值）value的下标或者指针 upper_bound(value): 第一个大于（可以是字典序，也可以是值）value的下标或者指针map:map&lt;char,int&gt; mymap;mymap['a']=20;mymap['b']=40;mymap['c']=60;mymap['d']=80;mymap['f']=100;map&lt;char,int&gt;::iterator itlow=mymap.lower_bound ('b'); // itlow points to bmap&lt;char,int&gt;::iterator temp=mymap.upper_bound ('d'); // temp points to f (not d!)map&lt;char,int&gt;::iterator itup=mymap.upper_bound ('e'); // there's no e, so itup points to fmymap.erase(itlow,itup); // erases [itlow,itup)set:set&lt;int&gt; myset;for (int i=1; i&lt;10; i++) myset.insert(i * 10); // 10 20 30 40 50 60 70 80 90set&lt;int&gt;::iterator temp1=myset.lower_bound (25); // 30 &gt;= 25,so temp1 points to 30set&lt;int&gt;::iterator temp2=myset.lower_bound (60); // 70 &gt; 60,so temp2 points to 70set&lt;int&gt;::iterator itlow=myset.lower_bound (30); // itlow points to 30set&lt;int&gt;::iterator itup=myset.upper_bound (65); // itup points to 70myset.erase(itlow,itup); // erases [itlow,itup)string::findint index = mystring.find(s, pos);其中 s 可以是字符也可以是字符串，pos 是寻找字符或字符串的起始位置。string str = \"abcdefgabc\";int index = str.find(\"abc\"); // index = 0int index = str.find(\"abc\", 3); // index = 7string::substrstring str = mystring.substr(pos, len);2Example// string::substr#include &lt;iostream&gt;#include &lt;string&gt;int main (){ std::string str=\"We think in generalities, but we live in details.\"; // (quoting Alfred N. Whitehead) std::string str2 = str.substr (3,5); // \"think\" std::size_t pos = str.find(\"live\"); // position of \"live\" in str std::string str3 = str.substr (pos); // get from \"live\" to the end std::cout &lt;&lt; str2 &lt;&lt; ' ' &lt;&lt; str3 &lt;&lt; '\\n'; return 0;}Output:think live in details.string::to_stringstring str = to_string(a); 3include&lt;bits/stdc++.h&gt;struct person{ // structure double a; double b;}temp[100];getline(cin,s);int a; // int to stringstring str = to_string(a); string b; // string to intint int1 = atoi(b.c_str()); //遇到字母会自动停下，如果没有数字，则定义为0 。b为string类型的情况下还需要使用c_str()函数int int2 = stoi(b); //遇到字母会自动停下，如果没有数字，运行会出错string str; // length(string)int res = str.length();char *test; // length(char)int res = strlen(test);int num = 3;temp = string(num, 'a'); // \"aaa\"int i = 1, j = 4;int res = (i + j)/2; // 向下取整，res = 2;cout&lt;&lt;res&lt;&lt;endl;malloc动态分配与释放内存。与vector相比，使用malloc的效率更高。分配一维与二维数组代码如下所示：#include&lt;bits/stdc++.h&gt;using namespace std;int main(){\t// 1-dimensional\tint len = 10;\tint *p;\tp = (int *)malloc(len * sizeof(int));\tfree(p);\t// 2-dimensional \tint **a; int row = 3; int col = 3; a = (int **)malloc(row * sizeof(int*)); for(int i = 0; i &lt; row; i++) { a[i] = (int *)malloc(col * sizeof(int)); } for(int i = 0; i &lt; row; i++) { free(a[i]); } free(a);}代码备忘录素数判断bool is_prime(int s){ if(s &lt;= 3) return s &gt; 1; int sqt = sqrt(s); for(int i = 2; i &lt;= sqt; i++) if(s % i == 0) return false; return true;}自定义排序bool cmp(string a, string b){ if(a.length() != b.length()) return a.length() &lt; b.length(); // 按长度升序：a的长度小于b的长度，所以从左到右长度变大。 return a &gt; b; // 按字典序降序：a的字典序大于b的字典序，所以从左到右字典序降低。}int main(){\tsort(temp1, temp1 + 4, cmp); // temp1为数组\tsort(temp2.begin(), temp2.end(), cmp); // temp2为向量} 最大最小值与sort()函数类似，可对数组、向量的任意区间求最大或最小值。#include&lt;bits/stdc++.h&gt;using namespace std;int main(){\tint temp_myv[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\tvector&lt;int&gt; myv(temp_myv, temp_myv + 10);\tcout&lt;&lt;*min_element(temp_myv, temp_myv + 10)&lt;&lt;endl;\tcout&lt;&lt;*max_element(myv.begin(), myv.end())&lt;&lt;endl;}所有元素求和int a[5] = {1, 2, 3, 4, 5};vector&lt;int&gt; v(a);int sum = accumulate(a, a + 5, 0);int sum2 = accumulate(v.begin(), v.end(), 0);输出标准化输出标准化参考此博客45。cout&lt;&lt;fixed&lt;&lt;setprecision(1)&lt;&lt;a&lt;&lt;endl; // accurate to 1 decimal placecout&lt;&lt;setw(3)&lt;&lt;setfill('0')&lt;&lt;a&lt;&lt;endl; // filled with '0'printf(\"%03d\",a); // if a=1; 输出001cout&lt;&lt;hex&lt;&lt;12&lt;&lt;endl; // 十六进制输出cout&lt;&lt;oct&lt;&lt;12&lt;&lt;endl; // 八进制输出 cout&lt;&lt;left&lt;&lt;setw(5)&lt;&lt;10&lt;&lt;endl; // 左对齐 cout&lt;&lt;right&lt;&lt;setw(5)&lt;&lt;10&lt;&lt;endl; // 右对齐string a; int b,c;scanf(\"%s : %d :%d\", &amp;a[0], &amp;b, &amp;c); //可以隔着冒号取值,记得引用符号&amp;printf(\"%s\\n\",a);回文判断用于判断字符串s中的任意子串是否回文。动态规划法：judge[start][end]表示字符串s中[start, end]的子串是否为回文串。int n = s.length();vector&lt;vector&lt;bool&gt; &gt; judge(n, vector&lt;bool&gt;(n, true));// 从后往前去遍历for (int i = n - 1; i &gt;= 0; --i){ for (int j = i + 1; j &lt; n; ++j) { // 判断i和j是否相等，相等则扩展 judge[i][j] = (s[i] == s[j]) &amp;&amp; judge[i + 1][j - 1]; }}双指针遍历法：描述同动态规划法，适用于单次简单判断。若要判断字符串s的每个子串是否为回文串，复杂度则为O(n^3)。bool judge(string s, int start, int end){ // 双指针遍历 for(int i = start; i &lt;= (start + end) / 2; i++){ if(s[i] != s[end + start - i]) return false; } return true;}二分查找详细的二分查找分析见此。int nums[5] = {10, 20, 30, 40, 50};int flag = -1, target = 16;int i = 0, j = n - 1; // 前闭后闭while(i &lt;= j){ // 因此i &gt; j(即i == j + 1)时退出循环 int mid = i + (j - i)/2; if(target == nums[mid]){ flag = mid; break; } else if(target &gt; nums[mid]) i = mid + 1; // mid已经遍历，所以新的区间为[i, mid - 1]或[mid + 1, j] else j = mid - 1;}排列组合排列(permutation)：\\[A_{n}^{m} = \\frac{n!}{(n - m)!} = (n - m + 1) * \\cdots * (n - 1) * n\\]int A(int n, int m) { int res = 1; for(int i = n - m + 1; i &lt;= n; i++){ res *= i; } return res;}组合(combination)：\\[C_{n}^{m} = \\frac{ A_{n}^{m} }{m!} = \\frac{n!}{(n - m)!m!} = C_{n}^{n-m}\\]int C(int n, int m) { m = min(m, n - m); int numerator = A(n, m);\t//分子 int denominator = A(m, m);\t//分母 return numerator / denominator;}字符串大小写判断及转换大小写判断：for (int i = 0; i &lt; str.size(); i++) if(islower(str[i])) return false; // bool islower(int c);for (int i = 0; i &lt; str.size(); i++) if(isupper(str[i])) return false; // bool isupper(int c);大小写转换：for (int i = 0; i &lt; str.size(); i++) str[i] = tolower(str[i]); // int tolower(int c);for (int i = 0; i &lt; str.size(); i++) str[i] = toupper(str[i]); // int toupper(int c);三个及以上的数字取最大最小值max()、min()函数中只有两个参数，意味着只能在两个数中取最大或者最小值。当需要对三个及以上的数字取最大或最小值时，可用以下方法。int x = 6, y = 2, z = 10;int m1 = max({x,y,z});int m2 = max&lt;int&gt;({x,y,z});int m3 = max({(int)x,y,z});double a = 9.2, b = 2.4, c = 5.5555;double n1 = min({a,b,c});double n2 = min&lt;double&gt;({a,b,c});double n3 = min({(double)a,b,c});或者：int maxn(int x, int y, int z){ return max(max(x, y), z);}随机数生成伪随机数： rand() / double(RAND_MAX) 产生随机数的范围是 [0, 1] rand() / double(RAND_MAX) * 2 * r 产生随机数范围为 [0, 2r] rand() / double(RAND_MAX) * 2 * r - r + x 产生随机数范围为 [x - r, x + r] 真随机数：#include &lt;random&gt;#include &lt;iostream&gt;int main(){ std::random_device rd; // random_device 是一个“真随机数”发生器，它的缺点就是耗能太大，所以尽量别奢侈地一直用它 std::mt19937 gen(rd()); // 用 random_device产生一个真随机数，用作“伪随机数发生器”的种子，此后就雪藏之 std::uniform_int_distribution&lt;&gt; dis(1, 6); // 一个正态“分布器”，高斯分布器是 std::normal_distribution for (int n=0; n&lt;10; ++n) // 用 dis 变换 gen 所生成的随机 unsigned int 到 [1, 6] 中的 int std::cout &lt;&lt; dis(gen) &lt;&lt; ' '; std::cout &lt;&lt; '\\n';}Reference C++ 成员运算符 &#8617; string::substr &#8617; string::to_string &#8617; C++ cout格式化输出（输出格式） &#8617; C++ 基本的输入输出 &#8617; " }, { "title": "申请软著的时间周期记录以及注意事项", "url": "/posts/software-copyright-timeline/", "categories": "Tutorial, Software Copyright", "tags": "copyright, timeline", "date": "2022-03-11 20:01:10 +0800", "snippet": "Introduction版权中心官网链接：https://www.ccopyright.com.cn/。在没有加急的情况下，申请一篇软著的总体周期大概需要三四个月左右。如果时间紧迫，可以去某宝找机构加急办理（不建议）。另外，申请软著可能用到的模板材料放到文末的附件中，有需要自取。Timeline2020-07-24：填写并提交两篇软著申请电子稿2020-07-28：EMS邮寄所需材料2020...", "content": "Introduction版权中心官网链接：https://www.ccopyright.com.cn/。在没有加急的情况下，申请一篇软著的总体周期大概需要三四个月左右。如果时间紧迫，可以去某宝找机构加急办理（不建议）。另外，申请软著可能用到的模板材料放到文末的附件中，有需要自取。Timeline2020-07-24：填写并提交两篇软著申请电子稿2020-07-28：EMS邮寄所需材料2020-07-29：北京登记部签收2020-09-03：一篇受理登记，邮箱收到受理通知书。同天，另一篇软著材料提交不规范，收到补正通知书。2020-09-04：再次EMS邮寄材料不规范的替代材料。2020-09-05：北京登记部签收2020-09-17：补正软著成功受理2020-10-29：收到第一件软著登记证书的挂号信（寄信日期为10月26日）2020-11-13：收到第二件软著登记证书的挂号信（寄信日期为11月9日）第一篇软著时间线第二篇软著时间线第三篇软件著作初次邮寄材料的时间点是2020年12月17日左右，其余时间点见下。从受理到邮寄发放间隔了一个半月，可见效率之低下！第三篇软著时间线Notice 身份证复印件复印到同一张A4纸上。 使用说明书里的图片要清晰。 在合作开发的情况下，合作开发合同的落款一定要早于开发完成时间。 副本不收费 Attachment 模板材料 外部链接 " }, { "title": "Github合并两个不同的仓库", "url": "/posts/merge-two-repos/", "categories": "Tutorial, Github", "tags": "github, branch, commits, git", "date": "2022-03-07 21:55:10 +0800", "snippet": "Description两个独立的仓库A、B，将仓库B合并至仓库A的分支，并保留A、B的所有commits例如：将dumped-CompetitiveLin.github.io中的所有提交内容合并至CompetitiveLin.github.io的another分支。Solution1. 克隆主仓库代码git clone git@github.com:CompetitiveLin/Compet...", "content": "Description两个独立的仓库A、B，将仓库B合并至仓库A的分支，并保留A、B的所有commits例如：将dumped-CompetitiveLin.github.io中的所有提交内容合并至CompetitiveLin.github.io的another分支。Solution1. 克隆主仓库代码git clone git@github.com:CompetitiveLin/CompetitiveLin.github.io2. 添加需要合并远程仓库git remote add base git@github.com:CompetitiveLin/dumped-CompetitiveLin.github.io此时查看remote: git remote -v，如下图所示：如果需要删除remote: git remote rm base3. 把base远程仓库中数据抓取到本仓库git fetch base4. 切换到base分支上，命名为dumpedgit checkout -b another base/dumped查看branch分支：git branch5. 切换到main分支git checkout main6. 合并两个分支git merge another此时可能出现类似下图fatal: refusing to merge unrelated histories的报错信息。解决方法：git merge another --allow-unrelated-histories在合并时有可能两个分支对同一个文件都做了修改，这时需要解决冲突1，在windows下可以使用Github Desktop解决冲突问题。7. 提交git push origin anotherProblemsA. Permission denied (publickey)原因：没有配置ssh-key，没有权限2解决方法： ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" clip &lt; ~/.ssh/id_rsa.pubSee here.Reference 在 GitHub 上解决合并冲突 &#8617; Permission denied (publickey) &#8617; " }, { "title": "Python实现点击图片获取HSV或BGR的值", "url": "/posts/get-hsv-and-bgr/", "categories": "Script, Python", "tags": "python, hsv, bgr, opencv", "date": "2022-03-04 13:35:49 +0800", "snippet": "单击图片即可得到HSV或BGR的值，代码如下：import cv2def getposHsv(event, x, y, flags, param): if event == cv2.EVENT_LBUTTONDOWN: print(\"HSV is\", HSV[y, x])def getposBgr(event, x, y, flags, param): if eve...", "content": "单击图片即可得到HSV或BGR的值，代码如下：import cv2def getposHsv(event, x, y, flags, param): if event == cv2.EVENT_LBUTTONDOWN: print(\"HSV is\", HSV[y, x])def getposBgr(event, x, y, flags, param): if event == cv2.EVENT_LBUTTONDOWN: print(\"BGR is\", image[y, x])image = cv2.imread('frame_B.jpg')HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)cv2.imshow(\"imageHSV\", HSV)cv2.imshow('image', image)cv2.setMouseCallback(\"imageHSV\", getposHsv)cv2.setMouseCallback(\"image\", getposBgr)cv2.waitKey(0)" }, { "title": "Python脚本制作coco格式的实例分割数据集", "url": "/posts/make-coco-dataset/", "categories": "Script, Python", "tags": "mmdetection, labelme, coco, python", "date": "2022-03-04 01:42:07 +0800", "snippet": "Introdution利用labelme制作coco格式的实例分割数据集，该数据集适用于mmdetection2.0中的mask部分。在mmdetection2.0框架下，利用coco格式的数据集进行实例分割默认只需要train2017和val2017两部分（当然也可以将test中的目录修改成test2017，但没必要）。mmdetection2.0框架下coco格式数据集文件如下图放置：（...", "content": "Introdution利用labelme制作coco格式的实例分割数据集，该数据集适用于mmdetection2.0中的mask部分。在mmdetection2.0框架下，利用coco格式的数据集进行实例分割默认只需要train2017和val2017两部分（当然也可以将test中的目录修改成test2017，但没必要）。mmdetection2.0框架下coco格式数据集文件如下图放置：（运行完本文的.py文件后即可生成以下文件夹）数据集标注方式：当一张图片里没有多个同类别的物体，使用car,computer,bottle等标签直接进行标注；当一张图片里同个类别有多个物体时，标签采用sofa-1,sofa-2,desk-1,desk-2等标签-数字的格式进行标注；如果同一物体在遮挡情况下被分为多个部分，则不同部分都用同一个标签（具体如下图所示，牙膏的三个部分标签均为toothpaste）。最后得到的json文件里的segmentation是分为三部分，bbox只存在一个（在笔者找的其他资料里，都是分为三个独立的牙膏部分，得到三个segmentation以及三个相应的bbox，显然不符合实际情况）。建议在使用labelme进行对数据集标注时，将生成的.json文件放置在与数据集相同的路径下以避免一些不必要的麻烦。即下图：否则，生成的json文件里的imagePath可能出现下图所示的情况：如果实在是没办法，没有在同一路径下，imagePath会比较复杂（可能是windows系统用\\分隔号，ubuntu系统则会是/分隔号，这一点是笔者的猜测），根据不同的情况修改后文代码。Solution各文件夹布局如下所示：所有的.jpg文件放在images文件夹下，所有的.json文件（labelme标注完成后生成的文件）放在labelme/total2017文件夹下。creat_txt.py# !/usr/bin/python# -*- coding: utf-8 -*-import osimport randomtrainval_percent = 1 # No test sampletrain_percent = 0.9jsonfilepath = 'labelme/total2017'txtsavepath = './'total_xml = os.listdir(jsonfilepath)num = len(total_xml)list = range(num)tv = int(num * trainval_percent)tr = int(tv * train_percent)trainval = random.sample(list, tv)train = random.sample(trainval, tr)ftrainval = open('./trainval2017.txt', 'w')ftrain = open('./train2017.txt', 'w')fval = open('./val2017.txt', 'w')ftest = open('./test2017.txt', 'w') #Still create test2017.txtfor i in list: name = total_xml[i][:-5] + '\\n' if i in trainval: ftrainval.write(name) if i in train: ftrain.write(name) else: fval.write(name) else: ftest.write(name)ftrainval.close()ftrain.close()fval.close()ftest.close()print('Create_txt Done')classify.pyimport shutilimport osimport os.path as ospsets=['train2017', 'val2017', 'test2017']for image_set in sets: if osp.exists(image_set): shutil.rmtree(image_set) print('Deleted previous %s file and created a new one'%(image_set)) os.makedirs(image_set) json_path = 'labelme/%s'%(image_set) if osp.exists(json_path): shutil.rmtree(json_path) print('Deleted previous %s file and created a new one' % (json_path)) os.makedirs(json_path) image_ids = open('./%s.txt'%(image_set)).read().strip().split() for image_id in image_ids: img = 'images/%s.jpg' % (image_id) json = 'labelme/total2017/%s.json'% (image_id) shutil.copy(img,image_set) shutil.copy(json,'labelme/%s/'% (image_set))print(\"Done\")labelme2coco.py#!/usr/bin/env pythonimport collectionsimport datetimeimport globimport jsonimport osimport os.path as ospimport sysimport numpy as npimport PIL.Imageimport labelmeimport shutiltry: import pycocotools.maskexcept ImportError: print('Please install pycocotools:\\n\\n pip install pycocotools\\n') sys.exit(1)def main(): sets = ['train2017','val2017','test2017'] output_dir = './annotations' if osp.exists(output_dir): print('Output directory already exists:', output_dir) shutil.rmtree(output_dir) os.makedirs(output_dir) print('Creating dataset:', output_dir) for set in sets: input_dir = './labelme/%s'%(set) filename = 'instances_%s'%(set) now = datetime.datetime.now() data = dict( info=dict( description=None, version=None, contributor=None, date_created=now.strftime('%Y-%m-%d %H:%M:%S.%f'), ), licenses=[dict( id=0, name=None, )], images=[ # license, url, file_name, height, width, date_captured, id ], type='instances', annotations=[ # segmentation, area, iscrowd, image_id, bbox, category_id, id ], categories=[ # supercategory, id, name ], ) class_name_to_id = {} for i, line in enumerate(open('labels.txt').readlines()): class_id = i - 1 # starts with -1 class_name = line.strip() if class_id == -1: assert class_name == '__ignore__' continue class_name_to_id[class_name] = class_id data['categories'].append(dict( supercategory=None, id=class_id, name=class_name, )) out_ann_file = osp.join(output_dir, filename+'.json') label_files = glob.glob(osp.join(input_dir, '*.json')) for image_id, label_file in enumerate(label_files): with open(label_file) as f: label_data = json.load(f) path=label_data['imagePath'].split(\"\\\\\") # 可能因为windows或ubuntu不同的系统用\\\\或/划分,详见前言三 img_file = './%s/'%(set) + path[-1] img = np.asarray(PIL.Image.open(img_file)) data['images'].append(dict( license=0, url=None, file_name=label_file.split('/')[-1].split('.')[0] + '.jpg', height=img.shape[0], width=img.shape[1], date_captured=None, id=image_id, )) masks = {} # for area segmentations = collections.defaultdict(list) # for segmentation for shape in label_data['shapes']: points = shape['points'] label = shape['label'] shape_type = shape.get('shape_type', None) mask = labelme.utils.shape_to_mask( img.shape[:2], points, shape_type ) if label in masks: masks[label] = masks[label] | mask else: masks[label] = mask points = np.asarray(points).flatten().tolist() segmentations[label].append(points) for label, mask in masks.items(): cls_name = label.split('-')[0] if cls_name not in class_name_to_id: continue cls_id = class_name_to_id[cls_name] mask = np.asfortranarray(mask.astype(np.uint8)) mask = pycocotools.mask.encode(mask) area = float(pycocotools.mask.area(mask)) bbox = pycocotools.mask.toBbox(mask).flatten().tolist() data['annotations'].append(dict( id=len(data['annotations']), image_id=image_id, category_id=cls_id, segmentation=segmentations[label], area=area, bbox=bbox, iscrowd=0, )) with open(out_ann_file, 'w') as f: json.dump(data, f,indent=4) print(set + ' is done')if __name__ == '__main__': main()上述三个文件按顺序执行即可。最后所有的文件夹如下图所示，如前文所提到的，在mmdetection中被利用到的只有annotations,train2017,val2017三个文件夹。本文的代码可以反复运行，因为代码中包含一些旧文件夹的删除以及新建，不会报错。Reference prepare_detection_dataset" }, { "title": "Github删除Commits记录", "url": "/posts/use-branch-to-rollback/", "categories": "Tutorial, Github", "tags": "github, branch, commits", "date": "2022-03-02 13:00:12 +0800", "snippet": "众所周知，已经Push到Github的Commits是不能撤销的。但是，我们可以通过创建分支并修改默认分支的方法让Repo回退至某个版本并删除该版本后的所有Commits记录。1. Description删除已Push的Commits并回退至旧版本。如下图所示，删除红框中的Commits记录并回退至箭头所指的版本。Revert Commits也能回退版本。但是其不同之处在于，Revert C...", "content": "众所周知，已经Push到Github的Commits是不能撤销的。但是，我们可以通过创建分支并修改默认分支的方法让Repo回退至某个版本并删除该版本后的所有Commits记录。1. Description删除已Push的Commits并回退至旧版本。如下图所示，删除红框中的Commits记录并回退至箭头所指的版本。Revert Commits也能回退版本。但是其不同之处在于，Revert Commits会保留所有的Commits。2. Solution本方法是在Windows的Github Desktop中操作的。但不管在哪个操作系统，解决该问题的思路是类似的。首先选择要回退到的Commit并Create branch, Name branch, Publish branch. 如下三图所示：接着，在Github上设置默认分支1，删除原分支，修改新建的分支名即可，如下三图所示：但是这样有个缺点：因为在Github主页上修改分支名并不会实时同步到Github Desktop，因此GitHub Desktop中会出现“混乱”，此时建议删除本地代码并重新Clone至本地。Reference GitHub Docs:更改默认分支 &#8617; " }, { "title": "Windows配置Jekyll相关环境", "url": "/posts/install-jekyll/", "categories": "Tutorial, Jekyll", "tags": "getting started, windows 10, installation", "date": "2022-03-01 21:40:53 +0800", "snippet": "1. Install Ruby在Windows上使用RubyInstaller安装比较方便，在Ruby官网下载最新版本的RubyInstaller WITH DEVKIT。注意32位和64位版本的区分。安装：使用默认路径即可，避免出错；勾选添加到PATH，就不用手动添加环境变量了安装完成如图：这里需要勾选Run 'ridk install'，在弹出来的安装界面中选择3，安装MSYS2 and...", "content": "1. Install Ruby在Windows上使用RubyInstaller安装比较方便，在Ruby官网下载最新版本的RubyInstaller WITH DEVKIT。注意32位和64位版本的区分。安装：使用默认路径即可，避免出错；勾选添加到PATH，就不用手动添加环境变量了安装完成如图：这里需要勾选Run 'ridk install'，在弹出来的安装界面中选择3，安装MSYS2 and MINGW development toolchain：2. Install RubyGems在RubyGems官网下载ZIP格式的安装包，下载后解压到任意路径。进入解压目录，在终端输入命令：ruby setup.rb 或者直接双击setup.rb文件即可。3. Install Jekyll打开cmd输入以下命令并等待安装完成即可。gem install jekyllgem install jekyll-paginategem install bundler4. Check installationjekyll -vbundle -v输出版本信息则代表安装没问题。5. Create a repo安装完成，我们可以用jekyll命令创建一个博客模板，进入一个目录，打开命令行执行：jekyll new testblogcd testblogbundle exec jekyll serve大功告成！PS：遇到的问题A. cannot load such file – webrick (LoadError)问题描述：执行 bundle exec jekyll serve 时出现 cannot load such file -- webrick (LoadError) 错误，如下图所示解决方法：终端输入bundle add webrick.See here.Reference windows安装jekyll 搭建个人博客：Jekyll + Github Pages + VSCode" }, { "title": "It's a Long Story", "url": "/posts/it's-a-long-story/", "categories": "Tutorial, Jekyll", "tags": "getting started, syntax", "date": "1999-05-25 10:00:00 +0800", "snippet": "This post is to show Markdown syntax rendering on Chirpy, you can also use it as an example of writing. Now, let’s start looking at text and typography.ParagraphI wandered lonely as a cloudThat flo...", "content": "This post is to show Markdown syntax rendering on Chirpy, you can also use it as an example of writing. Now, let’s start looking at text and typography.ParagraphI wandered lonely as a cloudThat floats on high o’er vales and hills,When all at once I saw a crowd,A host, of golden daffodils;Beside the lake, beneath the trees,Fluttering and dancing in the breeze.Nested and mixed listsNested and mixed lists are an interesting beast1. It’s a corner case to make sure that Lists within lists do not break the ordered list numbering order Your list styles go deep enough.Ordered list Firstly Firstly Secondly Thirdly Secondly Firstly Secondly Thirdly Thirdly Firstly Secondly Thirdly Unordered list Chapter Section Paragraph Task Lists Finish my changes Push my commits to GitHub Open a pull requestDescription list Sun the star around which the earth orbits Moon the natural satellite of the earth, visible by reflected light from the sunQuote Only one thing is impossible for God: To find any sense in any copyright law on the planet. Mark TwainPrompts An example showing the tip type prompt. An example showing the info type prompt. An example showing the warning type prompt. An example showing the danger type prompt.Twitter embedded🎨 Finally got around to adding all my @procreateapp creations with time lapse videos https://t.co/1nNbkefC3L pic.twitter.com/gcNLJoJ0Gn&mdash; Michael Rose (@mmistakes) November 6, 2015This post tests Twitter Embeds.Video embeddedYouTube video embedded below.ENGLISH SPEECH | MUNIBA MAZARI - We all are Perfectly Imperfect (English Subtitles)Here is the code:&lt;iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/fBnAMUkNM2k\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;Tables Header1 Header2 Header3 left center right left center right left center right left center right Image alignmentWelcome to image alignment! The best way to demonstrate the ebb and flow of the various image positioning options is to nestle them snuggly among an ocean of words. Grab a paddle and let’s get started.]The image above happens to be centered. The rest of this paragraph is filler for the sake of seeing the text wrap around the 150×150 image, which is left aligned.As you can see there should be some space above, below, and to the right of the image. The text should not be creeping on the image. Creeping is just not right. Images need breathing room too. Let them speak like you words. Let them do their jobs without any hassle from the text. In about one more sentence here, we’ll see that the text moves from the right of the image down below the image in seamless transition. Again, letting the do it’s thing. Mission accomplished!And now for a massively large image. It also has no alignment.The image above, though 1200px wide, should not overflow the content area. It should remain contained with no visible disruption to the flow of content.And now we’re going to shift things to the right align. Again, there should be plenty of room above, below, and to the left of the image. Just look at him there — Hey guy! Way to rock that right side. I don’t care what the left aligned image says, you look great. Don’t let anyone else tell you differently.In just a bit here, you should see the text start to wrap below the right aligned image and settle in nicely. There should still be plenty of room and everything should be sitting pretty. Yeah — Just like that. It never felt so good to be right.And just when you thought we were done, we’re going to do them all over again with captions! Once the position is specified, the image caption should not be added.With caption Default (with caption)Full screen width and center alignment Shadowshadow effect (visible in light mode) Left aligned Float to left “A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space.” Float to right “A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space.” Mermaid SVG gantt title Adding GANTT diagram functionality to mermaid apple :a, 2017-07-20, 1w banana :crit, b, 2017-07-23, 1d cherry :active, c, after b a, 1dMathematicsThe mathematics powered by MathJax:\\[\\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6}\\]When $a \\ne 0$, there are two solutions to $ax^2 + bx + c = 0$ and they are\\[x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}\\]FilepathHere is the /path/to/the/file.extend.Code blockCommonThis is a common code snippet, without syntax highlight and line number.Specific LanguagesUsing ```{language} you will get a code block with syntax highlight:```yamlkey: value```Console$ env |grep SHELLSHELL=/usr/local/bin/bashPYENV_SHELL=bashShellif [ $? -ne 0 ]; then echo \"The command was not successful.\"; #do the needful / exitfi;Specific filename@import \"colors/light-typography\", \"colors/dark-typography\"Line NumberBy default, all languages except plaintext, console, and terminal will display line numbers. When you want to hide the line number of a code block, add the class nolineno to it:```shellecho 'No more line numbers!'```{: .nolineno }Learn MoreFor more knowledge about Jekyll posts, visit the Jekyll Docs: Posts.Date modifiedThis post has been updated and show a modified date.Reference Texture image courtesty of Lovetextures &#8617; " } ]
